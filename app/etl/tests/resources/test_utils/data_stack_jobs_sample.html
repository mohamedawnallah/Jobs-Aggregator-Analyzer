<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="manifest" href="/site.webmanifest"/><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"/><meta name="apple-mobile-web-app-title" content="Data Stack Jobs"/><meta name="application-name" content="Data Stack Jobs"/><meta name="msapplication-TileColor" content="#2b5797"/><meta name="theme-color" content="#ffffff"/><title>Data Stack Jobs ‚Äî Work with the modern data stack</title><meta name="title" content="Data Stack Jobs ‚Äî Work with the modern data stack"/><meta name="description" content="Discover jobs in ML, Data Science, Data Engineering and everything in between."/><meta property="og:type" content="website"/><meta property="og:url" content="https://datastackjobs.com/"/><meta property="og:title" content="Data Stack Jobs ‚Äî Work with the modern data stack"/><meta property="og:description" content="Discover jobs in ML, Data Science, Data Engineering and everything in between."/><meta property="og:image" content="https://datastackjobs.com/thumbnail.webp"/><meta property="twitter:card" content="summary_large_image"/><meta property="twitter:url" content="https://datastackjobs.com/"/><meta property="twitter:title" content="Data Stack Jobs ‚Äî Work with the modern data stack"/><meta property="twitter:description" content="Discover jobs in ML, Data Science, Data Engineering and everything in between."/><meta property="twitter:image" content="https://datastackjobs.com/thumbnail.webp"/><meta name="next-head-count" content="24"/><link rel="preload" href="/_next/static/css/6418435b704f34df57a2.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6418435b704f34df57a2.css" data-n-g=""/><noscript data-n-css=""></noscript><link rel="preload" href="/_next/static/chunks/main-37a0a2fb90fe69f579f6.js" as="script"/><link rel="preload" href="/_next/static/chunks/webpack-7c235c8ce7ccfa45f08f.js" as="script"/><link rel="preload" href="/_next/static/chunks/framework.b65b242e921c3051fc8d.js" as="script"/><link rel="preload" href="/_next/static/chunks/05d954cf.a3f8b867f1dbe44b7882.js" as="script"/><link rel="preload" href="/_next/static/chunks/4296f879d6b162ad77a114aee20f2c73f8dc7680.653f9837c77c5e3b046b.js" as="script"/><link rel="preload" href="/_next/static/chunks/f9a9a75c5535d85502ab3f331daa705d124c96c6.68b683f2c546ffb2b0d8.js" as="script"/><link rel="preload" href="/_next/static/chunks/d0c17572a3857dce9cf74013cc89c84125388fe3.82188d4076cfb3b74167.js" as="script"/><link rel="preload" href="/_next/static/chunks/03ec6ed75970ab1694e01a1a684a9ea9e9646f9b.5233c31b312fc59f720f.js" as="script"/><link rel="preload" href="/_next/static/chunks/595d727c72955f0f005e25ae2b877b935dbda26c.cf9726d83c89faf02456.js" as="script"/><link rel="preload" href="/_next/static/chunks/8814d774837182f5c1c54848fa045f1174ac4c9d.349409635e9e8c2b394e.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/_app-0f4c5fbaf03871fb8f24.js" as="script"/><link rel="preload" href="/_next/static/chunks/0241f7f89381f731fab5b7171dd2b104ca613c07.f559ffbe49985b322adc.js" as="script"/><link rel="preload" href="/_next/static/chunks/b1fb4e262511cc3c03ae0b9b0b1e8f1fd2cee287.24676c3ea77d1431450a.js" as="script"/><link rel="preload" href="/_next/static/chunks/c9f5bf9e85f5de6ea89f38460a9150a45b3bb2fc.fa497414ff23c3c76a97.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/index-15728d2ef6fc668f0aac.js" as="script"/></head><body><div id="__next"><style data-emotion="css-global 1syi0wy">html{line-height:1.5;-webkit-text-size-adjust:100%;font-family:system-ui,sans-serif;-webkit-font-smoothing:antialiased;text-rendering:optimizeLegibility;-moz-osx-font-smoothing:grayscale;touch-action:manipulation;}body{position:relative;min-height:100%;font-feature-settings:'kern';}*,*::before,*::after{border-width:0;border-style:solid;box-sizing:border-box;}main{display:block;}hr{border-top-width:1px;box-sizing:content-box;height:0;overflow:visible;}pre,code,kbd,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,monospace;font-size:1em;}a{background-color:transparent;color:inherit;-webkit-text-decoration:inherit;text-decoration:inherit;}abbr[title]{border-bottom:none;-webkit-text-decoration:underline;text-decoration:underline;-webkit-text-decoration:underline dotted;-webkit-text-decoration:underline dotted;text-decoration:underline dotted;}b,strong{font-weight:bold;}small{font-size:80%;}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline;}sub{bottom:-0.25em;}sup{top:-0.5em;}img{border-style:none;}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0;}button,input{overflow:visible;}button,select{text-transform:none;}button::-moz-focus-inner,[type="button"]::-moz-focus-inner,[type="reset"]::-moz-focus-inner,[type="submit"]::-moz-focus-inner{border-style:none;padding:0;}fieldset{padding:0.35em 0.75em 0.625em;}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal;}progress{vertical-align:baseline;}textarea{overflow:auto;}[type="checkbox"],[type="radio"]{box-sizing:border-box;padding:0;}[type="number"]::-webkit-inner-spin-button,[type="number"]::-webkit-outer-spin-button{-webkit-appearance:none!important;}input[type="number"]{-moz-appearance:textfield;}[type="search"]{-webkit-appearance:textfield;outline-offset:-2px;}[type="search"]::-webkit-search-decoration{-webkit-appearance:none!important;}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit;}details{display:block;}summary{display:-webkit-box;display:-webkit-list-item;display:-ms-list-itembox;display:list-item;}template{display:none;}[hidden]{display:none!important;}body,blockquote,dl,dd,h1,h2,h3,h4,h5,h6,hr,figure,p,pre{margin:0;}button{background:transparent;padding:0;}fieldset{margin:0;padding:0;}ol,ul{margin:0;padding:0;}textarea{resize:vertical;}button,[role="button"]{cursor:pointer;}button::-moz-focus-inner{border:0!important;}table{border-collapse:collapse;}h1,h2,h3,h4,h5,h6{font-size:inherit;font-weight:inherit;}button,input,optgroup,select,textarea{padding:0;line-height:inherit;color:inherit;}img,svg,video,canvas,audio,iframe,embed,object{display:block;vertical-align:middle;}img,video{max-width:100%;height:auto;}[data-js-focus-visible] :focus:not([data-focus-visible-added]){outline:none;box-shadow:none;}select::-ms-expand{display:none;}</style><style data-emotion="css-global srcafr">body{font-family:Inter;color:#1A202C;background:#FFFFFF;-webkit-transition:background-color 0.2s;transition:background-color 0.2s;line-height:1.5;}*::-webkit-input-placeholder{color:#A0AEC0;}*::-moz-placeholder{color:#A0AEC0;}*:-ms-input-placeholder{color:#A0AEC0;}*::placeholder{color:#A0AEC0;}*,*::before,::after{border-color:#E2E8F0;word-wrap:break-word;}</style><style data-emotion="css-global qv6n72">@font-face{font-family:'Inter';font-style:normal;font-weight:100;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F;}@font-face{font-family:'Inter';font-style:normal;font-weight:100;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116;}@font-face{font-family:'Inter';font-style:normal;font-weight:100;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF;}@font-face{font-family:'Inter';font-style:normal;font-weight:100;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF;}@font-face{font-family:'Inter';font-style:normal;font-weight:100;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB;}@font-face{font-family:'Inter';font-style:normal;font-weight:100;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF;}@font-face{font-family:'Inter';font-style:normal;font-weight:100;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD;}@font-face{font-family:'Inter';font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F;}@font-face{font-family:'Inter';font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116;}@font-face{font-family:'Inter';font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF;}@font-face{font-family:'Inter';font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF;}@font-face{font-family:'Inter';font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB;}@font-face{font-family:'Inter';font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF;}@font-face{font-family:'Inter';font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD;}@font-face{font-family:'Inter';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F;}@font-face{font-family:'Inter';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116;}@font-face{font-family:'Inter';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF;}@font-face{font-family:'Inter';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF;}@font-face{font-family:'Inter';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB;}@font-face{font-family:'Inter';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF;}@font-face{font-family:'Inter';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD;}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F;}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116;}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF;}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF;}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB;}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF;}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD;}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F;}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116;}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF;}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF;}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB;}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF;}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD;}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F;}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116;}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF;}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF;}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB;}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF;}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD;}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F;}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116;}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF;}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF;}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB;}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF;}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD;}@font-face{font-family:'Inter';font-style:normal;font-weight:800;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F;}@font-face{font-family:'Inter';font-style:normal;font-weight:800;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116;}@font-face{font-family:'Inter';font-style:normal;font-weight:800;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF;}@font-face{font-family:'Inter';font-style:normal;font-weight:800;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF;}@font-face{font-family:'Inter';font-style:normal;font-weight:800;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB;}@font-face{font-family:'Inter';font-style:normal;font-weight:800;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF;}@font-face{font-family:'Inter';font-style:normal;font-weight:800;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD;}@font-face{font-family:'Inter';font-style:normal;font-weight:900;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F;}@font-face{font-family:'Inter';font-style:normal;font-weight:900;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116;}@font-face{font-family:'Inter';font-style:normal;font-weight:900;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF;}@font-face{font-family:'Inter';font-style:normal;font-weight:900;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF;}@font-face{font-family:'Inter';font-style:normal;font-weight:900;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB;}@font-face{font-family:'Inter';font-style:normal;font-weight:900;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF;}@font-face{font-family:'Inter';font-style:normal;font-weight:900;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD;}</style><style data-emotion="css vooagt">.css-vooagt{min-height:100vh;}</style><div class="css-vooagt"><style data-emotion="css 1mck22w">.css-1mck22w{width:100%;margin-left:auto;margin-right:auto;max-width:56rem;padding-left:1rem;padding-right:1rem;padding-bottom:20rem;}@media screen and (min-width: 30em){.css-1mck22w{padding-bottom:16rem;}}</style><div class="chakra-container css-1mck22w"><style data-emotion="css 6jyp5f">.css-6jyp5f{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;justify-content:space-between;padding-top:1rem;padding-bottom:1rem;padding-right:0;}@media screen and (min-width: 30em){.css-6jyp5f{padding-top:2rem;padding-bottom:2rem;padding-right:0.5rem;}}</style><div class="css-6jyp5f"><style data-emotion="css loe1j3">.css-loe1j3{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;}.css-loe1j3>*:not(style)~*:not(style){-webkit-margin-start:0.5rem;margin-inline-start:0.5rem;margin-top:0;}</style><div class="chakra-stack css-loe1j3"><style data-emotion="css 1ewc7op">.css-1ewc7op{-webkit-transition:all 0.15s ease-out;transition:all 0.15s ease-out;cursor:pointer;-webkit-text-decoration:none;text-decoration:none;outline:none;color:inherit;}.css-1ewc7op:hover,.css-1ewc7op[data-hover]{-webkit-text-decoration:none;text-decoration:none;}.css-1ewc7op:focus,.css-1ewc7op[data-focus]{box-shadow:0 0 0 3px rgba(183, 148, 244, 0.6);}</style><a class="chakra-link css-1ewc7op" href="/"><style data-emotion="css 1fzkik5">.css-1fzkik5{height:36px;}</style><img alt="DataStack Jobs logo" class="chakra-image__placeholder css-1fzkik5"/></a><style data-emotion="css ut3d2a">.css-ut3d2a{display:inline-block;white-space:nowrap;vertical-align:middle;padding-left:0.25rem;padding-right:0.25rem;text-transform:uppercase;font-size:0.75rem;border-radius:0.125rem;font-weight:700;background:#FEFCBF;color:#744210;-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;}</style><span class="chakra-badge css-ut3d2a">Beta</span></div><a class="chakra-link css-1ewc7op" href="/post-job"><style data-emotion="css taj1a">.css-taj1a{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-appearance:none;-moz-appearance:none;-ms-appearance:none;appearance:none;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;-webkit-transition:all 250ms;transition:all 250ms;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:relative;white-space:nowrap;vertical-align:middle;outline:none;width:auto;line-height:1.2;border-radius:0.375rem;font-weight:600;height:2.5rem;font-size:1rem;padding-left:1rem;padding-right:1rem;background:#E53E3E;color:#FFFFFF;}.css-taj1a:focus,.css-taj1a[data-focus]{box-shadow:0 0 0 3px rgba(183, 148, 244, 0.6);}.css-taj1a[disabled],.css-taj1a[disabled]:focus,.css-taj1a[disabled]:hover,.css-taj1a[aria-disabled=true],.css-taj1a[aria-disabled=true]:focus,.css-taj1a[aria-disabled=true]:hover,.css-taj1a[data-disabled],.css-taj1a[data-disabled]:focus,.css-taj1a[data-disabled]:hover{opacity:0.4;cursor:not-allowed;box-shadow:none;}.css-taj1a:hover,.css-taj1a[data-hover]{background:#C53030;}.css-taj1a:hover[disabled],.css-taj1a[data-hover][disabled],.css-taj1a:hover[disabled]:focus,.css-taj1a[data-hover][disabled]:focus,.css-taj1a:hover[disabled]:hover,.css-taj1a[data-hover][disabled]:hover,.css-taj1a:hover[aria-disabled=true],.css-taj1a[data-hover][aria-disabled=true],.css-taj1a:hover[aria-disabled=true]:focus,.css-taj1a[data-hover][aria-disabled=true]:focus,.css-taj1a:hover[aria-disabled=true]:hover,.css-taj1a[data-hover][aria-disabled=true]:hover,.css-taj1a:hover[data-disabled],.css-taj1a[data-hover][data-disabled],.css-taj1a:hover[data-disabled]:focus,.css-taj1a[data-hover][data-disabled]:focus,.css-taj1a:hover[data-disabled]:hover,.css-taj1a[data-hover][data-disabled]:hover{background:#E53E3E;}@media screen and (min-width: 30em){.css-taj1a{min-width:120px;}}.css-taj1a:active,.css-taj1a[data-active]{background:#9B2C2C;}</style><button type="button" class="chakra-button css-taj1a">Post a Job</button></a></div><style data-emotion="css o2lc4k">.css-o2lc4k{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;padding-top:1rem;padding-bottom:1rem;}.css-o2lc4k>*:not(style)~*:not(style){margin-top:0.75rem;-webkit-margin-start:0;margin-inline-start:0;}@media screen and (min-width: 30em){.css-o2lc4k>*:not(style)~*:not(style){margin-top:1rem;}}@media screen and (min-width: 48em){.css-o2lc4k>*:not(style)~*:not(style){margin-top:1.25rem;}}@media screen and (min-width: 30em){.css-o2lc4k{padding-top:1.5rem;padding-bottom:1.5rem;}}@media screen and (min-width: 48em){.css-o2lc4k{padding-top:2rem;padding-bottom:2rem;}}</style><div class="chakra-stack css-o2lc4k"><style data-emotion="css 1gzrc12">.css-1gzrc12{font-size:1.875rem;font-weight:900;color:#FFFFFF;padding:0.75rem;border-radius:0.5rem;line-height:0.8;width:-webkit-fit-content;width:-moz-fit-content;width:fit-content;background-color:#565cd8;}@media screen and (min-width: 30em){.css-1gzrc12{font-size:2.25rem;}}@media screen and (min-width: 48em){.css-1gzrc12{font-size:2.25rem;}}</style><p class="chakra-text css-1gzrc12">Work with the modern data stack</p><style data-emotion="css e8k6lu">.css-e8k6lu{font-size:1rem;}@media screen and (min-width: 30em){.css-e8k6lu{font-size:1.125rem;}}@media screen and (min-width: 48em){.css-e8k6lu{font-size:1.25rem;}}</style><p class="chakra-text css-e8k6lu">Discover jobs in ML, Data Science, Data Engineering and everything in between.</p></div><style data-emotion="css 129vczt">.css-129vczt{font-family:Inter;font-weight:700;font-size:1.5rem;line-height:1.33;margin-top:1rem;margin-bottom:1rem;}@media screen and (min-width: 48em){.css-129vczt{font-size:1.875rem;line-height:1.2;}}</style><h2 class="chakra-heading css-129vczt">Latest jobs</h2><style data-emotion="css 1pifhv5">.css-1pifhv5{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.css-1pifhv5>*:not(style)~*:not(style){margin-top:0.5rem;-webkit-margin-start:0;margin-inline-start:0;}</style><div class="chakra-stack css-1pifhv5"><style data-emotion="css pqtihb">.css-pqtihb{position:relative;padding-top:0.25rem;padding-bottom:0.25rem;padding-left:0;padding-right:0;}.css-pqtihb a[href]:not(.chakra-linkbox__overlay),.css-pqtihb abbr[title]{position:relative;z-index:1;}@media screen and (min-width: 30em){.css-pqtihb{padding-top:0.5rem;padding-bottom:0.5rem;padding-left:0.5rem;padding-right:0.5rem;}}.css-pqtihb:hover,.css-pqtihb[data-hover]{cursor:pointer;background:#FFFFF0;}</style><div class="chakra-linkbox css-pqtihb"><style data-emotion="css 8x8lqq">.css-8x8lqq{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:start;-webkit-box-align:start;-ms-flex-align:start;align-items:start;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.css-8x8lqq>*:not(style)~*:not(style){margin-top:0.25rem;-webkit-margin-start:0;margin-inline-start:0;}@media screen and (min-width: 30em){.css-8x8lqq>*:not(style)~*:not(style){margin-top:0.5rem;}}@media screen and (min-width: 48em){.css-8x8lqq>*:not(style)~*:not(style){margin-top:0.75rem;}}@media screen and (min-width: 48em){.css-8x8lqq{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;}.css-8x8lqq>*:not(style)~*:not(style){-webkit-margin-start:0.25rem;margin-inline-start:0.25rem;margin-top:0;}@media screen and (min-width: 30em){.css-8x8lqq>*:not(style)~*:not(style){-webkit-margin-start:0.5rem;margin-inline-start:0.5rem;}}@media screen and (min-width: 48em){.css-8x8lqq>*:not(style)~*:not(style){-webkit-margin-start:0.75rem;margin-inline-start:0.75rem;}}}</style><div class="chakra-stack css-8x8lqq"><style data-emotion="css ct8ots">.css-ct8ots{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;}.css-ct8ots>*:not(style)~*:not(style){-webkit-margin-start:0.75rem;margin-inline-start:0.75rem;margin-top:0;}</style><div class="chakra-stack css-ct8ots"><style data-emotion="css t3d50n">.css-t3d50n{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;width:50px;height:50px;border:1px solid;border-radius:0.375rem;border-color:#EDF2F7;}@media screen and (min-width: 30em){.css-t3d50n{width:60px;height:60px;}}</style><div class="css-t3d50n">B</div><div class="css-0"><style data-emotion="css n6y9a7">.css-n6y9a7{font-size:0.875rem;}</style><p class="chakra-text css-n6y9a7">Boulevard</p><style data-emotion="css nzdyzb">.css-nzdyzb{position:static;}.css-nzdyzb::before{content:'';cursor:inherit;display:block;position:absolute;top:0;left:0;z-index:0;width:100%;height:100%;}</style><a href="/jobs/yifxlruwe2-sr-product-analyst" class="chakra-linkbox__overlay css-nzdyzb"><style data-emotion="css 11xthxf">.css-11xthxf{font-size:1rem;font-weight:600;}@media screen and (min-width: 30em){.css-11xthxf{font-size:1.125rem;}}</style><p class="chakra-text css-11xthxf">Sr. Product Analyst</p></a><style data-emotion="css gpp40n">.css-gpp40n{text-transform:capitalize;font-size:0.875rem;}</style><p class="chakra-text css-gpp40n"><style data-emotion="css 12w8fd6">.css-12w8fd6{font-size:0.75rem;}</style><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>United States<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><style data-emotion="css 17xejub">.css-17xejub{-webkit-flex:1;-ms-flex:1;flex:1;justify-self:stretch;-webkit-align-self:stretch;-ms-flex-item-align:stretch;align-self:stretch;}</style><div class="css-17xejub"></div><style data-emotion="css 1fb0hqa">.css-1fb0hqa{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:start;-ms-flex-pack:start;-webkit-justify-content:flex-start;justify-content:flex-start;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;}@media screen and (min-width: 48em){.css-1fb0hqa{-webkit-box-pack:end;-ms-flex-pack:end;-webkit-justify-content:flex-end;justify-content:flex-end;}}</style><div class="css-1fb0hqa"><style data-emotion="css 1fogp5u">.css-1fogp5u{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;vertical-align:top;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;max-width:100%;font-weight:500;line-height:1.2;outline:0;min-height:1.5rem;min-width:1.5rem;font-size:0.875rem;border-radius:0.375rem;padding-left:0.5rem;padding-right:0.5rem;background:#EDF2F7;color:#1A202C;margin-bottom:0.25rem;margin-right:0.25rem;}.css-1fogp5u:focus,.css-1fogp5u[data-focus]{box-shadow:0 0 0 3px rgba(183, 148, 244, 0.6);}</style><span class="css-1fogp5u">Amplitude</span><span class="css-1fogp5u">Mixpanel</span><span class="css-1fogp5u">SQL</span></div><style data-emotion="css 1fwadej">.css-1fwadej{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:end;-ms-flex-pack:end;-webkit-justify-content:flex-end;justify-content:flex-end;min-width:120px;}</style><div class="css-1fwadej"><style data-emotion="css 11ie2kc">.css-11ie2kc{width:100%;font-size:0.875rem;color:#38A169;text-align:center;font-weight:600;}</style><p class="chakra-text css-11ie2kc">2 months ago</p></div></div></div><style data-emotion="css svjswr">.css-svjswr{opacity:0.6;border:0;border-color:inherit;border-style:solid;border-bottom-width:1px;width:100%;}</style><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">B</div><div class="css-0"><p class="chakra-text css-n6y9a7">Bitquery</p><a href="/jobs/ixumzawhqq-data-engineer-data-ops" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Data Engineer / Data Ops</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>Worldwide<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Airflow</span><span class="css-1fogp5u">Clickhouse</span><span class="css-1fogp5u">Apache Spark</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">4 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">C</div><div class="css-0"><p class="chakra-text css-n6y9a7">Corestream</p><a href="/jobs/o6okkm0d0f-data-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Data Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>Worldwide<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Azure</span><span class="css-1fogp5u">Data pipelines</span><span class="css-1fogp5u">ETL</span><span class="css-1fogp5u">Power BI</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">4 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">W</div><div class="css-0"><p class="chakra-text css-n6y9a7">Wavicle Data Solutions</p><a href="/jobs/spxkdouo5t-senior-ml-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Senior ML Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>Canada<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">AWS</span><span class="css-1fogp5u">Azure</span><span class="css-1fogp5u">Big Data</span><span class="css-1fogp5u">Consulting</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">4 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">I</div><div class="css-0"><p class="chakra-text css-n6y9a7">Innovaccer</p><a href="/jobs/okmf74i1ul-staff-data-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Staff Data Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>USA<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">AWS</span><span class="css-1fogp5u">Data Analytics</span><span class="css-1fogp5u">EC2</span><span class="css-1fogp5u">Engineering</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">4 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">Y</div><div class="css-0"><p class="chakra-text css-n6y9a7">YData.ai</p><a href="/jobs/p1azjgcujr-marketing-manager" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Marketing Manager</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>Europe, Africa, North America, South America, Central America<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Sales</span><span class="css-1fogp5u">Marketing</span><span class="css-1fogp5u">Analytics</span><span class="css-1fogp5u">Digital Marketing</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">4 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">Y</div><div class="css-0"><p class="chakra-text css-n6y9a7">YData.ai</p><a href="/jobs/ojswkhzzy6-data-science-advocate" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Data Science Advocate</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>Europe, Africa, North America, South America, Central America<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">AI</span><span class="css-1fogp5u">ML</span><span class="css-1fogp5u">Data Quality</span><span class="css-1fogp5u">Copywriting</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">4 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">Y</div><div class="css-0"><p class="chakra-text css-n6y9a7">YData.ai</p><a href="/jobs/w45xlizshh-senior-data-scientist-product" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Senior Data Scientist (Product)</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>Europe, Africa, North America, South America, Central America<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Python</span><span class="css-1fogp5u">Statistics</span><span class="css-1fogp5u">SDK</span><span class="css-1fogp5u">Data Quality</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">4 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">Y</div><div class="css-0"><p class="chakra-text css-n6y9a7">YData.ai</p><a href="/jobs/q4cjm1n6fm-senior-data-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Senior Data Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>Europe, Africa, North America, South America, Central America<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Python</span><span class="css-1fogp5u">Spark</span><span class="css-1fogp5u">Dask</span><span class="css-1fogp5u">Kubernetes</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">4 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">Y</div><div class="css-0"><p class="chakra-text css-n6y9a7">YData.ai</p><a href="/jobs/vc3ynqb6l9-mlops-back-end-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">MLOps / Back-End Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>Europe, Africa, North America, South America, Central America<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Go</span><span class="css-1fogp5u">Python</span><span class="css-1fogp5u">Kubernetes</span><span class="css-1fogp5u">Docker</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">4 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">Y</div><div class="css-0"><p class="chakra-text css-n6y9a7">YData.ai</p><a href="/jobs/ni0frws4gc-cloud-infrastructure-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Cloud infrastructure Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>Europe, Africa, North America, South America, Central America<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Terraform</span><span class="css-1fogp5u">Kubernetes</span><span class="css-1fogp5u">Kustomize</span><span class="css-1fogp5u">Docker</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">4 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">F</div><div class="css-0"><p class="chakra-text css-n6y9a7">Faire Wholesale</p><a href="/jobs/edyq9egblg-senior-machine-learning-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Senior Machine Learning Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>North America<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Engineering</span><span class="css-1fogp5u">Java</span><span class="css-1fogp5u">Machine Learning</span><span class="css-1fogp5u">Python</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">5 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">F</div><div class="css-0"><p class="chakra-text css-n6y9a7">Faire Wholesale</p><a href="/jobs/0pv3qxqcrp-senior-data-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Senior Data Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>North America<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Airflow</span><span class="css-1fogp5u">BigQuery</span><span class="css-1fogp5u">Engineering</span><span class="css-1fogp5u">ETL</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">5 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">N</div><div class="css-0"><p class="chakra-text css-n6y9a7">Nostos Genomics</p><a href="/jobs/mbxbnw261d-data-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Data Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>Worldwide<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Airflow</span><span class="css-1fogp5u">AWS</span><span class="css-1fogp5u">Engineering</span><span class="css-1fogp5u">ETL</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">5 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">A</div><div class="css-0"><p class="chakra-text css-n6y9a7">Angi</p><a href="/jobs/vm5kgrooo4-data-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Data Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>Worldwide<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">AWS</span><span class="css-1fogp5u">Data Warehousing</span><span class="css-1fogp5u">Engineering</span><span class="css-1fogp5u">GitLab</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">5 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">M</div><div class="css-0"><p class="chakra-text css-n6y9a7">Mattermost</p><a href="/jobs/qofsrtw71b-data-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Data Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>Worldwide<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Airflow</span><span class="css-1fogp5u">Data Analytics</span><span class="css-1fogp5u">Data pipelines</span><span class="css-1fogp5u">Engineering</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">5 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">G</div><div class="css-0"><p class="chakra-text css-n6y9a7">Glide</p><a href="/jobs/gfbanjlu0r-data-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Data Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>Worldwide<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Airflow</span><span class="css-1fogp5u">AWS</span><span class="css-1fogp5u">Business Intelligence</span><span class="css-1fogp5u">Data pipelines</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">5 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">O</div><div class="css-0"><p class="chakra-text css-n6y9a7">Opendoor</p><a href="/jobs/vhafue1wpc-sr-machine-learning-platform-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Sr Machine Learning Platform Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>Worldwide<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Airflow</span><span class="css-1fogp5u">AWS</span><span class="css-1fogp5u">Deep Learning</span><span class="css-1fogp5u">Distributed Systems</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">5 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">D</div><div class="css-0"><p class="chakra-text css-n6y9a7">Doma</p><a href="/jobs/akmffrpcy4-founding-staff-data-scientist" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Founding Staff Data Scientist</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>USA<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Airflow</span><span class="css-1fogp5u">AWS</span><span class="css-1fogp5u">Azure</span><span class="css-1fogp5u">Big Data</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">5 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">J</div><div class="css-0"><p class="chakra-text css-n6y9a7">Jane Technologies</p><a href="/jobs/swcngss38o-senior-data-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Senior Data Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>Worldwide<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Airflow</span><span class="css-1fogp5u">AWS</span><span class="css-1fogp5u">Classification</span><span class="css-1fogp5u">Data pipelines</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">5 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">B</div><div class="css-0"><p class="chakra-text css-n6y9a7">BrainPOP</p><a href="/jobs/1ljwy3gxbl-senior-data-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Senior Data Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>United States<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Airflow</span><span class="css-1fogp5u">AWS</span><span class="css-1fogp5u">Data pipelines</span><span class="css-1fogp5u">Engineering</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">5 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">S</div><div class="css-0"><p class="chakra-text css-n6y9a7">Samsara</p><a href="/jobs/fchbtuibaq-senior-data-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Senior Data Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>USA<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Data pipelines</span><span class="css-1fogp5u">Engineering</span><span class="css-1fogp5u">ETL</span><span class="css-1fogp5u">Finance</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">5 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">S</div><div class="css-0"><p class="chakra-text css-n6y9a7">Samsara</p><a href="/jobs/tcqcxesng3-marketing-data-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Marketing Data Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>USA<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Data pipelines</span><span class="css-1fogp5u">Engineering</span><span class="css-1fogp5u">ETL</span><span class="css-1fogp5u">Healthcare</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">5 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">E</div><div class="css-0"><p class="chakra-text css-n6y9a7">EVERFI</p><a href="/jobs/v9ixdf791s-senior-data-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Senior Data Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>USA<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Airflow</span><span class="css-1fogp5u">Big Data</span><span class="css-1fogp5u">Data pipelines</span><span class="css-1fogp5u">Engineering</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">5 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">A</div><div class="css-0"><p class="chakra-text css-n6y9a7">Aquicore</p><a href="/jobs/nbocqtriis-data-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Data Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>USA<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Airflow</span><span class="css-1fogp5u">AWS</span><span class="css-1fogp5u">Data pipelines</span><span class="css-1fogp5u">Data Warehousing</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">6 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">F</div><div class="css-0"><p class="chakra-text css-n6y9a7">Flock Safety</p><a href="/jobs/2ol4g0m97m-data-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Data Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>Worldwide<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Airflow</span><span class="css-1fogp5u">AWS</span><span class="css-1fogp5u">Cassandra</span><span class="css-1fogp5u">Engineering</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">6 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">P</div><div class="css-0"><p class="chakra-text css-n6y9a7">Paddle</p><a href="/jobs/ky7mcc3xto-staff-data-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Staff Data Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>London or Remote<!-- --> ‚Ä¢ <!-- -->flexible</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Airflow</span><span class="css-1fogp5u">AWS</span><span class="css-1fogp5u">Data pipelines</span><span class="css-1fogp5u">Engineering</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">6 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">J</div><div class="css-0"><p class="chakra-text css-n6y9a7">Jasper</p><a href="/jobs/ioxpumdpes-sr-data-architect" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Sr. Data Architect</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>Worldwide<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Big Data</span><span class="css-1fogp5u">BigQuery</span><span class="css-1fogp5u">Dataflow</span><span class="css-1fogp5u">Data pipelines</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">6 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">G</div><div class="css-0"><p class="chakra-text css-n6y9a7">Glooko</p><a href="/jobs/mvu6rpdqac-software-architect-data-engineering" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Software Architect (Data Engineering)</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>USA<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">AWS</span><span class="css-1fogp5u">Cassandra</span><span class="css-1fogp5u">Engineering</span><span class="css-1fogp5u">Healthcare</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">6 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">B</div><div class="css-0"><p class="chakra-text css-n6y9a7">Beat</p><a href="/jobs/6buhpdbybz-senior-machine-learning-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Senior Machine Learning Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>Worldwide<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Matching</span><span class="css-1fogp5u">Azure</span><span class="css-1fogp5u">Data Mining</span><span class="css-1fogp5u">Kubernetes</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">6 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">A</div><div class="css-0"><p class="chakra-text css-n6y9a7">AppDirect</p><a href="/jobs/koiidhcdzb-data-engineering-team-lead" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Data Engineering Team Lead</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>Canada<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Avro</span><span class="css-1fogp5u">AWS</span><span class="css-1fogp5u">Azure</span><span class="css-1fogp5u">Data pipelines</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">6 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">L</div><div class="css-0"><p class="chakra-text css-n6y9a7">Life360</p><a href="/jobs/dbkesybeg4-senior-data-engineer-data-partnerships" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Senior Data Engineer, Data Partnerships</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>USA<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">AWS</span><span class="css-1fogp5u">Big Data</span><span class="css-1fogp5u">Data pipelines</span><span class="css-1fogp5u">Engineering</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">6 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">C</div><div class="css-0"><p class="chakra-text css-n6y9a7">Celonis</p><a href="/jobs/xcveig27jo-senior-software-engineer-machine-learning" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Senior Software Engineer (Machine Learning)</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>Munich based OR remote in Germany<!-- --> ‚Ä¢ <!-- -->flexible</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Engineering</span><span class="css-1fogp5u">Java</span><span class="css-1fogp5u">Kubernetes</span><span class="css-1fogp5u">Machine Learning</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">6 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">A</div><div class="css-0"><p class="chakra-text css-n6y9a7">App Annie</p><a href="/jobs/llojfrughh-big-data-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Big Data Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>AMER Region<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">AWS</span><span class="css-1fogp5u">Azure</span><span class="css-1fogp5u">Big Data</span><span class="css-1fogp5u">Business Intelligence</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">6 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">T</div><div class="css-0"><p class="chakra-text css-n6y9a7">Treasure Data</p><a href="/jobs/aszhdkcr50-senior-data-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Senior Data Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>North America<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">AWS</span><span class="css-1fogp5u">Data pipelines</span><span class="css-1fogp5u">Data Warehousing</span><span class="css-1fogp5u">Engineering</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">6 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">R</div><div class="css-0"><p class="chakra-text css-n6y9a7">RECUR</p><a href="/jobs/mnay3mmpla-senior-data-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Senior Data Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>North America<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">AWS</span><span class="css-1fogp5u">Blockchain</span><span class="css-1fogp5u">Business Intelligence</span><span class="css-1fogp5u">Data pipelines</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">6 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">B</div><div class="css-0"><p class="chakra-text css-n6y9a7">Beat</p><a href="/jobs/di5wu0xfxn-machine-learning-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Machine Learning Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>Worldwide<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Azure</span><span class="css-1fogp5u">Data Mining</span><span class="css-1fogp5u">Engineering</span><span class="css-1fogp5u">Kubernetes</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">6 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">S</div><div class="css-0"><p class="chakra-text css-n6y9a7">Sensor Tower</p><a href="/jobs/j3bdjnckkd-senior-data-scientist" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Senior Data Scientist</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>Europe<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Business Intelligence</span><span class="css-1fogp5u">Data Mining</span><span class="css-1fogp5u">Data pipelines</span><span class="css-1fogp5u">Finance</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">6 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">D</div><div class="css-0"><p class="chakra-text css-n6y9a7">Digit</p><a href="/jobs/fviqfy4gvp-senior-data-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Senior Data Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>USA<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Airflow</span><span class="css-1fogp5u">AWS</span><span class="css-1fogp5u">Data pipelines</span><span class="css-1fogp5u">Engineering</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">6 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">F</div><div class="css-0"><p class="chakra-text css-n6y9a7">Figure</p><a href="/jobs/x2rlhlnxdn-machine-learning-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Machine Learning Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>United States<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Airflow</span><span class="css-1fogp5u">AWS</span><span class="css-1fogp5u">Banking</span><span class="css-1fogp5u">Big Data</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">6 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">N</div><div class="css-0"><p class="chakra-text css-n6y9a7">Netguru</p><a href="/jobs/65mhjxbhkk-data-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Data Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>Worldwide<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Airflow</span><span class="css-1fogp5u">Avro</span><span class="css-1fogp5u">AWS</span><span class="css-1fogp5u">Azure</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">6 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">D</div><div class="css-0"><p class="chakra-text css-n6y9a7">Demandbase</p><a href="/jobs/trz1dxqeps-senior-data-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Senior Data Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>US<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Data Platform</span><span class="css-1fogp5u">Airflow</span><span class="css-1fogp5u">AWS</span><span class="css-1fogp5u">Data Warehousing</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">6 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">Y</div><div class="css-0"><p class="chakra-text css-n6y9a7">YData.ai</p><a href="/jobs/nzziqxbdfc-mlops-back-end-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">MLOps / Back-End Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>Europe, Africa, North America, South America, Central America<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Go</span><span class="css-1fogp5u">Python</span><span class="css-1fogp5u">Kubernetes</span><span class="css-1fogp5u">Docker</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">6 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">A</div><div class="css-0"><p class="chakra-text css-n6y9a7">Affirm</p><a href="/jobs/ecdbh7e98x-staff-data-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Staff Data Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>US<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Big Data</span><span class="css-1fogp5u">Engineering</span><span class="css-1fogp5u">ETL</span><span class="css-1fogp5u">Hadoop</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">6 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">D</div><div class="css-0"><p class="chakra-text css-n6y9a7">Dataminr</p><a href="/jobs/cj2izg5kel-senior-data-analytics-developer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Senior Data Analytics Developer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>Dublin, Ireland<!-- --> ‚Ä¢ <!-- -->onsite</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">AWS</span><span class="css-1fogp5u">Business Intelligence</span><span class="css-1fogp5u">Data Analytics</span><span class="css-1fogp5u">Engineering</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">6 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">W</div><div class="css-0"><p class="chakra-text css-n6y9a7">Wise</p><a href="/jobs/r98pqk6xmc-data-science-internship" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Data Science Internship</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>Tallinn or London<!-- --> ‚Ä¢ <!-- -->onsite</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Banking</span><span class="css-1fogp5u">Engineering</span><span class="css-1fogp5u">Machine Learning</span><span class="css-1fogp5u">ML</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">6 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">D</div><div class="css-0"><p class="chakra-text css-n6y9a7">Discord</p><a href="/jobs/eyiizrzf6l-software-engineer-machine-learning" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Software Engineer, Machine Learning</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>San Francisco, CA or Remote<!-- --> ‚Ä¢ <!-- -->flexible</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Search</span><span class="css-1fogp5u">Recommendations</span><span class="css-1fogp5u">Notifications</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">6 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">S</div><div class="css-0"><p class="chakra-text css-n6y9a7">Safe Security</p><a href="/jobs/tbt87dznfc-senior-ml-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Senior ML Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>Worldwide<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">ML</span><span class="css-1fogp5u">MLOps</span><span class="css-1fogp5u">Python</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">6 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">A</div><div class="css-0"><p class="chakra-text css-n6y9a7">Andela</p><a href="/jobs/wnnyq2wi9m-data-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Data Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>Worldwide<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">Engineering</span><span class="css-1fogp5u">GCP</span><span class="css-1fogp5u">Kubernetes</span><span class="css-1fogp5u">Python</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">6 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><div class="chakra-linkbox css-pqtihb"><div class="chakra-stack css-8x8lqq"><div class="chakra-stack css-ct8ots"><div class="css-t3d50n">E</div><div class="css-0"><p class="chakra-text css-n6y9a7">Even</p><a href="/jobs/h10gyqtkka-senior-data-engineer" class="chakra-linkbox__overlay css-nzdyzb"><p class="chakra-text css-11xthxf">Senior Data Engineer</p></a><p class="chakra-text css-gpp40n"><span class="chakra-text css-12w8fd6" role="img" aria-label="location">üìç </span>USA<!-- --> ‚Ä¢ <!-- -->remote</p></div></div><div class="css-17xejub"></div><div class="css-1fb0hqa"><span class="css-1fogp5u">FiveTran</span><span class="css-1fogp5u">Healthcare</span><span class="css-1fogp5u">PostgreSQL</span><span class="css-1fogp5u">Python</span></div><div class="css-1fwadej"><p class="chakra-text css-11ie2kc">6 months ago</p></div></div></div><hr role="separator" aria-orientation="horizontal" class="chakra-divider css-svjswr"/><style data-emotion="css h6a79t">.css-h6a79t{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-appearance:none;-moz-appearance:none;-ms-appearance:none;appearance:none;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;-webkit-transition:all 250ms;transition:all 250ms;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:relative;white-space:nowrap;vertical-align:middle;outline:none;width:auto;line-height:1.2;border-radius:0.375rem;font-weight:600;height:2.5rem;min-width:2.5rem;font-size:1rem;padding-left:1rem;padding-right:1rem;background:#EDF2F7;}.css-h6a79t:focus,.css-h6a79t[data-focus]{box-shadow:0 0 0 3px rgba(183, 148, 244, 0.6);}.css-h6a79t[disabled],.css-h6a79t[disabled]:focus,.css-h6a79t[disabled]:hover,.css-h6a79t[aria-disabled=true],.css-h6a79t[aria-disabled=true]:focus,.css-h6a79t[aria-disabled=true]:hover,.css-h6a79t[data-disabled],.css-h6a79t[data-disabled]:focus,.css-h6a79t[data-disabled]:hover{opacity:0.4;cursor:not-allowed;box-shadow:none;}.css-h6a79t:hover,.css-h6a79t[data-hover]{background:#E2E8F0;}.css-h6a79t:hover[disabled],.css-h6a79t[data-hover][disabled],.css-h6a79t:hover[disabled]:focus,.css-h6a79t[data-hover][disabled]:focus,.css-h6a79t:hover[disabled]:hover,.css-h6a79t[data-hover][disabled]:hover,.css-h6a79t:hover[aria-disabled=true],.css-h6a79t[data-hover][aria-disabled=true],.css-h6a79t:hover[aria-disabled=true]:focus,.css-h6a79t[data-hover][aria-disabled=true]:focus,.css-h6a79t:hover[aria-disabled=true]:hover,.css-h6a79t[data-hover][aria-disabled=true]:hover,.css-h6a79t:hover[data-disabled],.css-h6a79t[data-hover][data-disabled],.css-h6a79t:hover[data-disabled]:focus,.css-h6a79t[data-hover][data-disabled]:focus,.css-h6a79t:hover[data-disabled]:hover,.css-h6a79t[data-hover][data-disabled]:hover{background:#EDF2F7;}.css-h6a79t:active,.css-h6a79t[data-active]{background:#CBD5E0;}</style><button type="button" class="chakra-button css-h6a79t">Load More</button></div></div><style data-emotion="css 1liao56">.css-1liao56{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;position:absolute;bottom:0;left:0;right:0;background-color:#171923;}</style><div class="css-1liao56"><style data-emotion="css 1jys9sb">.css-1jys9sb{width:100%;margin-left:auto;margin-right:auto;max-width:56rem;padding-left:1rem;padding-right:1rem;}</style><div class="chakra-container css-1jys9sb"><style data-emotion="css sl2kon">.css-sl2kon{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:baseline;-webkit-box-align:baseline;-ms-flex-align:baseline;align-items:baseline;-webkit-box-pack:justify;-webkit-justify-content:space-between;justify-content:space-between;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;padding-left:1rem;padding-right:1rem;padding-top:2rem;padding-bottom:2rem;}.css-sl2kon>*:not(style)~*:not(style){margin-top:1rem;-webkit-margin-start:0;margin-inline-start:0;}@media screen and (min-width: 30em){.css-sl2kon>*:not(style)~*:not(style){margin-top:1.5rem;}}@media screen and (min-width: 30em){.css-sl2kon{-webkit-align-items:baseline;-webkit-box-align:baseline;-ms-flex-align:baseline;align-items:baseline;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;padding-top:4rem;padding-bottom:4rem;}.css-sl2kon>*:not(style)~*:not(style){margin-top:1rem;-webkit-margin-start:0;margin-inline-start:0;}@media screen and (min-width: 30em){.css-sl2kon>*:not(style)~*:not(style){margin-top:1.5rem;}}}@media screen and (min-width: 48em){.css-sl2kon{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;padding-top:5rem;padding-bottom:5rem;}.css-sl2kon>*:not(style)~*:not(style){-webkit-margin-start:1rem;margin-inline-start:1rem;margin-top:0;}@media screen and (min-width: 30em){.css-sl2kon>*:not(style)~*:not(style){-webkit-margin-start:1.5rem;margin-inline-start:1.5rem;}}}</style><div class="chakra-stack css-sl2kon"><a class="chakra-link css-1ewc7op" href="/"><img alt="DataStack Jobs logo" class="chakra-image__placeholder css-1fzkik5"/></a><style data-emotion="css 1mgsfrj">.css-1mgsfrj{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.css-1mgsfrj>*:not(style)~*:not(style){margin-top:1rem;-webkit-margin-start:0;margin-inline-start:0;}@media screen and (min-width: 30em){.css-1mgsfrj>*:not(style)~*:not(style){margin-top:1.5rem;}}@media screen and (min-width: 30em){.css-1mgsfrj{-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;}.css-1mgsfrj>*:not(style)~*:not(style){-webkit-margin-start:1rem;margin-inline-start:1rem;margin-top:0;}@media screen and (min-width: 30em){.css-1mgsfrj>*:not(style)~*:not(style){-webkit-margin-start:1.5rem;margin-inline-start:1.5rem;}}}</style><div class="chakra-stack css-1mgsfrj"><style data-emotion="css wc5du9">.css-wc5du9{color:#F7FAFC;}</style><p class="chakra-text css-wc5du9">Copyright ¬© 2021</p><style data-emotion="css 9q6f6u">.css-9q6f6u{-webkit-transition:all 0.15s ease-out;transition:all 0.15s ease-out;cursor:pointer;-webkit-text-decoration:none;text-decoration:none;outline:none;color:#D6BCFA;}.css-9q6f6u:hover,.css-9q6f6u[data-hover]{-webkit-text-decoration:underline;text-decoration:underline;}.css-9q6f6u:focus,.css-9q6f6u[data-focus]{box-shadow:0 0 0 3px rgba(183, 148, 244, 0.6);}</style><a class="chakra-link css-9q6f6u" href="/privacy">Privacy</a><a class="chakra-link css-9q6f6u" href="/terms">Terms</a><a class="chakra-link css-9q6f6u" href="mailto:alexa@datastackjobs.com">Get in touch</a></div></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"jobs":[{"application_url_or_email":"https://jobs.lever.co/boulevard/155cb811-c2d1-4759-8c03-9dd11068df45","category":"product","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/yifxlruwe2.webp","company_name":"Boulevard","company_slug":"boulevard","company_twitter":null,"description":"\u003cp\u003eAs the Senior Product Analyst you will be the foundational team member for our Product Analytics team and create a robust self-service product analytics program from the ground up. You will work across our Product Operations, Analytics Engineering, and Engineering organization to understand the product data gaps and develop a plan to instrument the necessary tracking to power analytics and KPI‚Äôs. You will support the design, development, and administration of advanced analytics dashboards for reporting on our product health and performance. You will play a key role starting from requirements gathering, to delivery of an analytics solution, and continuous support of a self service dash-boarding and reporting.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eYou will work with product managers, engineers, and our analytics engineering team, to ensure our product organization has access to the data they need to answer critical questions. If you‚Äôre interested in building something from the ground up, having a high sense of ownership, and learning with a growth mindset, and have a passion for data informed decision making, this is the role for you.\u003c/p\u003e\u003ch3\u003e\u003cbr /\u003e\u003c/h3\u003e\u003ch3\u003e\u003cstrong\u003eWhat you'll do here:\u003c/strong\u003e\u003c/h3\u003e\u003cul\u003e\u003cli\u003eProduct Event Tracking:¬†Work across Analytics Engineering and Product to define and own product event tracking schema and select and implement a reporting tool such as Amplitude / Mixpanel.\u003c/li\u003e\u003cli\u003eProduct KPIs:¬†Work closely with product to define and track product metrics and KPIs related to our North Star Metric and its input metrics.\u003c/li\u003e\u003cli\u003eProduct Dashboards:¬†Support the design and development of product dashboards within an event tracking and reporting tool\u003c/li\u003e\u003cli\u003eProduct Strategy / Roadmap:¬†Provide analysis and/ market studies to support strategic initiatives related to product strategy and roadmap\u003c/li\u003e\u003cli\u003eProduct A/B Testing: Create a system and visibility for future A/B testing of new features within the product analytics reporting tool, so success criteria for A/B testing can be quickly identified and understood.\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003e\u003cbr /\u003e\u003c/h3\u003e\u003ch3\u003e\u003cstrong\u003eWhat you'll need to thrive:\u003c/strong\u003e\u003c/h3\u003e\u003cul\u003e\u003cli\u003eStrong Proficiency in an event reporting tool such as Amplitude / Mixpanel\u003c/li\u003e\u003cli\u003eExperience working with BI or Data engineers\u003c/li\u003e\u003cli\u003eStrong Intuition for data and basic statistical concepts\u003c/li\u003e\u003cli\u003eEffective communicator who can successfully operate in a cross-functional role (Product / Analytics Engineering / Eng)\u003c/li\u003e\u003cli\u003eAbility to communicate technical concepts to both technical and non-technical audiences through visualizations and studies\u003c/li\u003e\u003cli\u003eStrong intuition for product and user journeys and common SaaS KPIs\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e","id":21948,"location":"United States","location_type":"remote","position":"Sr. Product Analyst","published_at":"2022-05-04T16:13:28Z","slug":"yifxlruwe2-sr-product-analyst","status":"approved","tags":["Amplitude","Mixpanel","SQL"],"type":"fulltime"},{"application_url_or_email":"hr@bitquery.io","category":"dataengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/ixumzawhqq.webp","company_name":"Bitquery","company_slug":"bitquery","company_twitter":"Bitquery_io","description":"\u003cp\u003eWe have a distributed team, we are looking for programmers to further develop and support a data collection and processing system.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eResponsibilities:\u003c/p\u003e\u003cul\u003e\u003cli\u003eBuilding scalable infrastructure\u003c/li\u003e\u003cli\u003eEffective data storage\u003c/li\u003e\u003cli\u003eData quality control, monitoring, and ensuring data quality\u003c/li\u003e\u003cli\u003eDatabase administration\u003c/li\u003e\u003cli\u003eMessage queue administration\u003c/li\u003e\u003cli\u003eUnderstanding blockchain data (blocks, transfers, transactions, smart contracts, etc.)\u003c/li\u003e\u003cli\u003eAdding data quality checker/alert/metrics to monitoring systems\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eRequirements:\u003c/p\u003e\u003cul\u003e\u003cli\u003eKnowledge of database technologies\u003c/li\u003e\u003cli\u003eHight SQL language skill\u003c/li\u003e\u003cli\u003eProgramming skill (Ruby or Python or Java or Golang)\u003c/li\u003e\u003cli\u003eExperience to work with data\u003c/li\u003e\u003cli\u003eThe desire to understand a variety of systems and projects\u003c/li\u003e\u003cli\u003e3 years IT experience\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eStack: Ubuntu, Ansible, Jenkins, Clickhouse, Mysql, Kafka, Ruby, Python, Go, Java, Docker, Grafana, Prometheus\u003c/p\u003e\u003cp\u003eKeywords: Unix, Database, DBA, SQL, Go, Python, Blockchain\u003c/p\u003e","id":20251,"location":"Worldwide","location_type":"remote","position":"Data Engineer / Data Ops","published_at":"2022-03-21T12:18:22Z","slug":"ixumzawhqq-data-engineer-data-ops","status":"approved","tags":["Airflow","Clickhouse","Apache Spark"],"type":"fulltime"},{"application_url_or_email":"https://jobs.lever.co/corestream/0fc8cc4f-306d-41ce-9a6f-5cb638bd27e0?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"dataengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/o6okkm0d0f.webp","company_name":"Corestream","company_slug":"corestream","company_twitter":"CorestreamInc","description":"\u003cp\u003eWe‚Äôre looking for a data engineer with analytics experience to join a small data team and spearhead development on our cloud data lakehouse. The ideal candidate will be adept at working cross-functionally to elicit design requirements from business and technology teams, building robust data pipelines, curating meaningful datasets, and provisioning data for end-users, integrations, and other services.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eKey Responsibilities\u003c/h3\u003e\u003cul\u003e\u003cli\u003eWork with business teams to understand current and future data needs and provide mechanisms for constructing and storing datasets to support those requirements.\u003c/li\u003e\u003cli\u003eWork with the R\u0026amp;D teams to influence the design and implementation of new data models.\u003c/li\u003e\u003cli\u003eProvide expertise in data movement and storage best practices in support of downstream reporting, analytics, and data science initiatives.\u003c/li\u003e\u003cli\u003eHelp design and optimize the business‚Äô database and table schemas for existing applications and future product development.\u003c/li\u003e\u003cli\u003eDesign, implement, and optimize robust ELT pipelines.\u003c/li\u003e\u003cli\u003ePopulate a cloud data lakehouse utilized by data analysts, data scientists, and BI developers.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eSkills and Expertise\u003c/h3\u003e\u003cul\u003e\u003cli\u003e4+ Years designing data models, building ETL pipelines, and wrangling data to solve business problems.\u003c/li\u003e\u003cli\u003e2+ Years developing in Spark, with Databricks experience strongly preferred.\u003c/li\u003e\u003cli\u003eWorking experience within the Azure ecosystem.\u003c/li\u003e\u003cli\u003eAdvanced SQL experience working with relational databases.\u003c/li\u003e\u003cli\u003eExperience building data pipelines, architectures, and datasets, with preference for Delta Lake multi-hop architecture development experience.\u003c/li\u003e\u003cli\u003eKnowledge of database and data warehouse design best practices for read/write performance.\u003c/li\u003e\u003cli\u003eDevelopment experience with either Python or Scala.\u003c/li\u003e\u003cli\u003eDemonstrated understanding of common BI patterns and tabular modeling, with preference for Microsoft Power BI experience.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eCorestream is a fast-growing, cutting-edge financial and benefits technology company. We are an industry leader in the delivery of Voluntary Benefits; our proprietary software is the engine for large, Fortune-500 companies to easily and cost-effectively offer unlimited Voluntary Benefits to its employees through payroll deduction.¬†We have a driven, flexible, and fun team and offer competitive compensation and benefit packages. Although we are over ten years old, we still have a ‚Äústart-up‚Äù culture and when we are in the office we have a casual dress code, weekly yoga, free snacks and beverages, and Friday lunches are on the house.¬†We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\u003c/p\u003e","id":20240,"location":"Worldwide","location_type":"remote","position":"Data Engineer","published_at":"2022-03-21T12:20:00Z","slug":"o6okkm0d0f-data-engineer","status":"approved","tags":["Azure","Data pipelines","ETL","Power BI"],"type":"fulltime"},{"application_url_or_email":"https://apply.workable.com/j/9FE469A6B8/apply?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"machinelearning","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/spxkdouo5t.webp","company_name":"Wavicle Data Solutions","company_slug":"wavicle-data-solutions","company_twitter":"WavicleDataLLC","description":"\u003cp\u003e\u003cstrong\u003eWavicle Data Solutions\u003c/strong\u003e designs and delivers data and analytics solutions to reduce time, cost, and risk of companies‚Äô data projects, improving the quality of their analytics and decisions now and into the future\u003cstrong\u003e. \u003c/strong\u003eAs a privately-held consulting service organization with popular, name brand clients across multiple industries, Wavicle offers exciting opportunities for data scientists, solutions architects, developers, and consultants to jump right in and contribute to meaningful, innovative solutions.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eOur 300+ local, nearshore and offshore consultants, data architects, cloud engineers, and developers build cost-effective, right-fit solutions leveraging our team‚Äôs deep business acumen and knowledge of cutting-edge data and analytics technology and frameworks.\u003c/p\u003e\u003cp\u003eAt Wavicle, you‚Äôll find a challenging and rewarding work environment where we enjoy working as a team to exceed client expectations. Employees appreciate being part of something meaningful at Wavicle. Wavicle has been recognized by industry leaders as follows:\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eChicago Tribune‚Äôs Top Workplaces\u003c/li\u003e\u003cli\u003eInc 500 Fastest Growing Private Companies in the US\u003c/li\u003e\u003cli\u003eCrain‚Äôs Fast 50 fastest growing companies in the Chicago area\u003c/li\u003e\u003cli\u003eTalend Expert Partner recognition\u003c/li\u003e\u003cli\u003eMicrosoft Gold Data Platform competency\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWatch here to learn \u003c/strong\u003e\u003ca href=\"https://vimeo.com/654661550\"\u003e\u003cstrong\u003eWhy Wavicle\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e \u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eAs a ML Engineer you will be responsible for the end-to-end a development of machine learning solutions that solve some of our client's most complex business problems.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat You Will Get To Do:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eIdentify scalable ML solutions to solve business problems that addresses client need.\u003c/li\u003e\u003cli\u003eUnderstanding on ML pipeline (feature engineering, scoring, signal processing).\u003c/li\u003e\u003cli\u003eUnderstand Data Engineering and its mechanism, whether its real time or batch.\u003c/li\u003e\u003cli\u003eWork with Data Scientists on how models are being built and used against different data inputs.\u003c/li\u003e\u003cli\u003eProvide a platform for Data Scientist to access data and processes to allow them to fine tune the models.\u003c/li\u003e\u003cli\u003eBuild a system that can provide capabilities for Data Scientists to be contributors.\u003c/li\u003e\u003cli\u003eLeverage cloud compute to build solutions.\u003c/li\u003e\u003cli\u003eUnderstand Data science needs and translate them into workable solutions.\u003c/li\u003e\u003cli\u003eMentor and guide other ML engineers, scientists and senior leaders. Be a continuous learner and invest in the learning and development of ML engineers.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eRequirements\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e5+ years of data \u0026amp; analytics professional work experience.\u003c/li\u003e\u003cli\u003ePrior experience working as a management/strategic consultant is highly desirable.\u003c/li\u003e\u003cli\u003e3+ years of developing and deploying machine learning systems into a production environment.\u003c/li\u003e\u003cli\u003eExperience working with big data tools (i.e. Hadoop, Spark, Kafka, etc.) to extract data.\u003c/li\u003e\u003cli\u003eFamiliarity with ML modeling frameworks (i.e. Tensorflow, Keras, Pytorch).\u003c/li\u003e\u003cli\u003eExpertise with key cloud services (VM, Storage, etc...) - AWS, Azure or GCP.\u003c/li\u003e\u003cli\u003eExperience with object-oriented/object function scripting languages: Python, Java, C++, Scala , etc.\u003c/li\u003e\u003cli\u003eExperience working with distributed systems, service oriented architectures and designing APIs.\u003c/li\u003e\u003cli\u003eExpert knowledge of SQL.\u003c/li\u003e\u003cli\u003eStrong written and verbal communication skills.\u003c/li\u003e\u003cli\u003eExcellent analytical and problem solving skills.\u003c/li\u003e\u003cli\u003eFamiliar with project management methodologies.\u003c/li\u003e\u003cli\u003eBachelor or Master's degree in Computer Science, Statistics, Mathematics, Analytics or related degree.\u003c/li\u003e\u003cli\u003eHybrid work schedule (onsite/remote).\u003c/li\u003e\u003cli\u003eAbility to travel to client locations up to 25% (Canadian and U.S. based customers).\u003c/li\u003e\u003cli\u003eMust reside in the Quebec providence; Montreal preferred. Wavicle's Canadian office is located in Montreal.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eEqual Opportunity Employer \u003c/strong\u003e\u003c/p\u003e\u003cp\u003eWavicle is an Equal Opportunity Employer and committed to creating an inclusive environment for all employees. We welcome and encourage diversity in the workplace regardless of race, color, religion, national origin, gender, pregnancy, sexual orientation, gender identity, age, physical or mental disability, genetic information or veteran status.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eBenefits\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eHealth Care Plan (Medical, Dental \u0026amp; Vision)\u003c/li\u003e\u003cli\u003eLife Insurance (Basic, Voluntary \u0026amp; AD\u0026amp;D)\u003c/li\u003e\u003cli\u003eUnlimited Paid Time Off (Vacation, Sick \u0026amp; Public Holidays)\u003c/li\u003e\u003cli\u003eShort Term \u0026amp; Long Term Disability\u003c/li\u003e\u003cli\u003eTraining \u0026amp; Development\u003c/li\u003e\u003cli\u003eFlexible Work Schedule\u003c/li\u003e\u003cli\u003eBonus Program\u003c/li\u003e\u003cli\u003eWellness Program\u003c/li\u003e\u003c/ul\u003e","id":19439,"location":"Canada","location_type":"remote","position":"Senior ML Engineer","published_at":"2022-03-06T12:26:22Z","slug":"spxkdouo5t-senior-ml-engineer","status":"approved","tags":["AWS","Azure","Big Data","Consulting"],"type":"fulltime"},{"application_url_or_email":"https://boards.greenhouse.io/innovaccer/jobs/5954305002?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"dataengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/okmf74i1ul.webp","company_name":"Innovaccer","company_slug":"innovaccer","company_twitter":"innovaccer","description":"\u003ch3\u003eYour Role\u003c/h3\u003e\u003cp\u003eWe are looking for a \u003cstrong\u003e\u003cem\u003eStaff Data Engineer \u003c/em\u003e\u003c/strong\u003eto join the Customer Innovation team, who will be responsible for acquiring, transforming, and integrating customer data onto our Data Activation Platform from customers‚Äô clinical, claims, and other data sources. You will work closely with customers to build data and analytics solutions to support their business needs, and be the engine that powers the partnership that we build with them by delivering high-fidelity data assets.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eIn this role, you will work closely with our Product Managers, Data Scientists, and Software Engineers to build the solution architecture that will support customer objectives. You'll work with some of the brightest minds in the industry, work with one of the richest healthcare data sets in the world, use cutting-edge technology, and see your efforts affect products and people on a regular basis. The ideal candidate is someone that¬†\u003c/p\u003e\u003cul\u003e\u003cli\u003eHas healthcare experience and is passionate about helping heal people,\u003c/li\u003e\u003cli\u003eLoves working with data,¬†\u003c/li\u003e\u003cli\u003eHas an obsessive focus on data quality,\u003c/li\u003e\u003cli\u003eIs comfortable with ambiguity and making decisions based on available data and reasonable assumptions,\u003c/li\u003e\u003cli\u003eHas strong data interrogation and analysis skills,\u003c/li\u003e\u003cli\u003eDefaults to written communication and delivers clean documentation, and,\u003c/li\u003e\u003cli\u003eEnjoys working with customers and problem solving for them.\u003c/li\u003e\u003c/ul\u003e\u003ch4\u003e\u003cbr /\u003e\u003c/h4\u003e\u003ch3\u003eA Day in the Life\u003c/h3\u003e\u003cp\u003e‚ñ∂ \u003cstrong\u003e\u003cem\u003eEnabling customers for success¬†\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eDefine the end-to-end solution architecture for projects by mapping customers‚Äô business and technical requirements against the suite of Innovaccer products and solutions.¬†\u003c/li\u003e\u003cli\u003eMeasure and communicate impact to our customers.\u003c/li\u003e\u003cli\u003eEnabling customers on how to activate data themselves using SQL, BI tools, or APIs to solve for questions they have at speed.\u003c/li\u003e\u003cli\u003eIdentify risks to customer success and communicate to leadership.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e‚ñ∂ \u003cstrong\u003e\u003cem\u003ePlaying with data and delivering insights\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eDesign, implement, and document data integration pipelines.\u003c/li\u003e\u003cli\u003eAutomate and orchestrate data flows.\u003c/li\u003e\u003cli\u003eBuild and unit testing of data ingestion pipelines.\u003c/li\u003e\u003cli\u003eBuilding actionable dashboards and reports for customers.\u003c/li\u003e\u003cli\u003eTake part in software engineering lifecycle activities including sprint planning, backlog grooming, code reviews etc.\u003c/li\u003e\u003cli\u003eAnalyze data and present data quality reports and insights to internal and external audiences.¬†\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e‚ñ∂ \u003cstrong\u003e\u003cem\u003eFinally, shaping the healthcare data platform for customer needs\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eCrafting data models visible to the customers\u003c/li\u003e\u003cli\u003eCreating analytical views that drive new insights customers need.\u003c/li\u003e\u003c/ul\u003e\u003ch4\u003e\u003cbr /\u003e\u003c/h4\u003e\u003ch3\u003eWhat You Need\u003c/h3\u003e\u003cul\u003e\u003cli\u003e8+ years of experience in a Data Engineering role, Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.¬†\u003c/li\u003e\u003cli\u003eExperience working with relational databases like Snowflake, Redshift or Postgres. Familiarity with NoSQL databases like MongoDB and ElasticSearch will be an added advantage.\u003c/li\u003e\u003cli\u003eProficiency in SQL programming\u003c/li\u003e\u003cli\u003eProficiency in at least one programming language (like Python, R, Scala) and experience writing code to handle data manipulation, scheduling, event-based triggering and automation tasks\u003c/li\u003e\u003cli\u003eExperience working with AWS including services like EC2, EMR, RDS, Redshift, S3 and more\u003c/li\u003e\u003cli\u003eUS Healthcare Data experience preferably in Value-Based Care and¬†strong healthcare data background - clinical, claims, FHIR, HL7, X12, CCDA etc.\u003c/li\u003e\u003cli\u003eData Analytics and Visualization (using tools like PowerBI)\u003c/li\u003e\u003cli\u003eThe ability to engage with both the business and technical teams of a client - to document and explain technical problems or concepts in a clear and concise way\u003c/li\u003e\u003cli\u003eAbility to work in a fast-paced and agile environment.\u003c/li\u003e\u003cli\u003eEasily adapt and learn new things whether it‚Äôs a new library, framework, process, or a visual design concept.\u003c/li\u003e\u003cli\u003ePassion for being the technology ambassador and coaching engineering excellence to junior engineers.\u003c/li\u003e\u003cli\u003eExperience supporting customer incidents to resolution\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e¬†\u003c/p\u003e\u003ch3\u003ePreferred Skills\u003c/h3\u003e\u003cul\u003e\u003cli\u003eMulti Cloud experience\u003c/li\u003e\u003cli\u003eFamiliarity with Agile methodologies\u003c/li\u003e\u003c/ul\u003e","id":19429,"location":"USA","location_type":"remote","position":"Staff Data Engineer","published_at":"2022-03-06T12:24:39Z","slug":"okmf74i1ul-staff-data-engineer","status":"approved","tags":["AWS","Data Analytics","EC2","Engineering"],"type":"fulltime"},{"application_url_or_email":"https://angel.co/company/ydata/jobs/1541372-marketing-manager","category":"salesmarketing","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/p1azjgcujr.webp","company_name":"YData.ai","company_slug":"ydata-ai","company_twitter":"YData_ai","description":"\u003cp\u003eWe're looking for a Marketing Manager who will help us shape our team, drive the company to the next level, and have the most direct influence on our success.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch2\u003e\u003cstrong\u003eYour Profile\u003c/strong\u003e\u003c/h2\u003e\u003cul\u003e\u003cli\u003eExperience working in small startups with limited resources\u003c/li\u003e\u003cli\u003eStrong communication skills to internal and external audiences\u003c/li\u003e\u003cli\u003eCreativity is something you leverage to get to talk with someone\u003c/li\u003e\u003cli\u003eExperience or interest to work with Sales, Marketing, and Analytics tools\u003c/li\u003e\u003cli\u003eWillingness to communicate and share your knowledge with other team members\u003c/li\u003e\u003cli\u003eSince our team is currently being developed from scratch, we need pragmatic people\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch2\u003e\u003cstrong\u003eYour Responsibilities\u003c/strong\u003e\u003c/h2\u003e\u003cul\u003e\u003cli\u003eCreate a marketing strategy for YData's product, building out differentiated technical content and demonstration scenarios that enable thought leadership\u003c/li\u003e\u003cli\u003eLead efforts to market to technical practitioners by deeply understanding their needs and use cases\u003c/li\u003e\u003cli\u003eCreate messaging and user experiences that drive engagement, product usage, and retention\u003c/li\u003e\u003cli\u003eCreate content to support marketing campaigns, website pages, and in-product experiences for YData users\u003c/li\u003e\u003cli\u003eDevelop and test product positioning and messaging informed by user research, market and competitive insights, and product understanding\u003c/li\u003e\u003cli\u003eCollaborate with Product, Marketing, and Data Science teams to track product awareness, adoption, and engagement\u003c/li\u003e\u003cli\u003eYou will be part of a self-organized team\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch2\u003e\u003cstrong\u003eOur Perks ‚Äì More than just a job\u003c/strong\u003e\u003c/h2\u003e\u003cul\u003e\u003cli\u003eHave an impact. With innovation and smart technology, we are changing the way organizations use and share data.\u003c/li\u003e\u003cli\u003eTrust-based working. We don't punch the clock ‚Äì organize your own schedule. We trust in what you do!\u003c/li\u003e\u003cli\u003eImprove yourself. You can have fun at work at the same time you learn and improve yourself. We only hire the best and make them even better.\u003c/li\u003e\u003cli\u003ePush boundaries. Everyone is equally important and works together on uncharted challenges alongside inspiring colleagues from all over the world.\u003c/li\u003e\u003cli\u003eFeel at home. Literally! We are remote work enthusiasts!\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWant to write the history of artificial intelligence with us? Submit your application. We're excited to hear from you!\u003c/p\u003e","id":18891,"location":"Europe, Africa, North America, South America, Central America","location_type":"remote","position":"Marketing Manager","published_at":"2022-03-06T12:27:55Z","slug":"p1azjgcujr-marketing-manager","status":"approved","tags":["Sales","Marketing","Analytics","Digital Marketing"],"type":"fulltime"},{"application_url_or_email":"https://angel.co/company/ydata/jobs/1452245-data-science-advocate","category":"datascience","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/ojswkhzzy6.webp","company_name":"YData.ai","company_slug":"ydata-ai","company_twitter":"YData_ai","description":"\u003cp\u003eWe're looking for a Data Science Advocate who will help us shape the way data scientists understand the preparation step, including privacy, explainability, and causality of their datasets.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch2\u003e\u003cstrong\u003eYour Responsibilities\u003c/strong\u003e\u003c/h2\u003e\u003cul\u003e\u003cli\u003eYou will be the owner of the documentation\u003c/li\u003e\u003cli\u003eYou will create processes for content creation \u0026amp; delivery\u003c/li\u003e\u003cli\u003eYou will write blog posts, social media posts, white papers, and other materials\u003c/li\u003e\u003cli\u003eYou take initiative to write about tools, frameworks, processes, or AI in general\u003c/li\u003e\u003cli\u003eYou are curious about how things work and write about it\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch2\u003e\u003cstrong\u003eYour Profile\u003c/strong\u003e\u003c/h2\u003e\u003cul\u003e\u003cli\u003eExperience writing for a technical audience (data scientists, developers, programmers, system architects, or similar)\u003c/li\u003e\u003cli\u003eData Science / AI knowledge and/or willingness to learn\u003c/li\u003e\u003cli\u003eInterested in being part of a promising startup\u003c/li\u003e\u003cli\u003ePassionate about learning new tools and keeping yourself up-to-date\u003c/li\u003e\u003cli\u003eWillingness to communicate and share your knowledge with others\u003c/li\u003e\u003cli\u003eFluent in English\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch2\u003e\u003cstrong\u003eOur Perks ‚Äì More than just a job\u003c/strong\u003e\u003c/h2\u003e\u003cul\u003e\u003cli\u003eHave an impact. With innovation and smart technology, we are changing the way organizations use and share data\u003c/li\u003e\u003cli\u003eTrust-based working. We don't punch the clock ‚Äì organize your own schedule. We trust in what you do!\u003c/li\u003e\u003cli\u003ePush boundaries. Everyone is equally important and works together on uncharted challenges alongside inspiring colleagues from all over the world.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWant to write the history of data science and artificial intelligence with us? Apply now!\u003c/p\u003e","id":18890,"location":"Europe, Africa, North America, South America, Central America","location_type":"remote","position":"Data Science Advocate","published_at":"2022-03-06T12:27:48Z","slug":"ojswkhzzy6-data-science-advocate","status":"approved","tags":["AI","ML","Data Quality","Copywriting"],"type":"fulltime"},{"application_url_or_email":"https://angel.co/company/ydata/jobs/1453984-senior-data-scientist-product","category":"datascience","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/w45xlizshh.webp","company_name":"YData.ai","company_slug":"ydata-ai","company_twitter":"YData_ai","description":"\u003cp\u003eWe're looking for a Senior Data Scientist (Product) who will help us shape our team, drive the company to the next level, and have the most direct influence on our success.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch2\u003e\u003cstrong\u003eYour Responsibilities\u003c/strong\u003e\u003c/h2\u003e\u003cul\u003e\u003cli\u003eYou'll be working with the newest data science Python library for data quality\u003c/li\u003e\u003cli\u003eYou will be part of a self-organized, cross-functional team while working on defining metrics, reports and helping to improve current models' functionalities at scale.\u003c/li\u003e\u003cli\u003eSince our team is still growing, we need pragmatic scientists\u003c/li\u003e\u003cli\u003eYou take responsibility for the whole product your team delivers\u003c/li\u003e\u003cli\u003eYou are curious and figure out how things work and how they should work for your product\u003c/li\u003e\u003cli\u003eYou bring your core expertise but are open to getting your hands dirty with data architecture and data engineering\u003c/li\u003e\u003cli\u003eYou have a problem-solving attitude\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch2\u003e\u003cstrong\u003eYour Profile\u003c/strong\u003e\u003c/h2\u003e\u003cul\u003e\u003cli\u003eML/DL models knowledge and statistics\u003c/li\u003e\u003cli\u003eExperience working with Python\u003c/li\u003e\u003cli\u003eInterested in data explainability and causality\u003c/li\u003e\u003cli\u003eInterested in creating the best tools for data scientists to use on their daily tasks\u003c/li\u003e\u003cli\u003eInterested in working together with the Founders\u003c/li\u003e\u003cli\u003ePassionate about learning new tools and keeping yourself up-to-date\u003c/li\u003e\u003cli\u003eWillingness to communicate and share your knowledge with other team members\u003c/li\u003e\u003cli\u003eWillingness to work in agile processes\u003c/li\u003e\u003cli\u003eFluent in English\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch2\u003e\u003cstrong\u003eOur Perks ‚Äì More than just a job\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eHave an impact. With innovation and smart technology, we are changing the way organizations use and share data\u003c/p\u003e\u003cp\u003e Trust-based working. We don't punch the clock ‚Äì organize your own schedule. We trust in what you do!\u003c/p\u003e\u003cp\u003e Feel at home. Literally! We are remote work enthusiasts!\u003c/p\u003e\u003cp\u003e Feel it‚Äôs your own company. Check our stock options plan. We want to have you onboard and be part of YData.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWant to write the history of data science and artificial intelligence with us? Submit your application today. We're excited to hear from you!\u003c/p\u003e","id":18889,"location":"Europe, Africa, North America, South America, Central America","location_type":"remote","position":"Senior Data Scientist (Product)","published_at":"2022-03-06T12:27:43Z","slug":"w45xlizshh-senior-data-scientist-product","status":"approved","tags":["Python","Statistics","SDK","Data Quality"],"type":"fulltime"},{"application_url_or_email":"https://angel.co/company/ydata/jobs/1280007-senior-data-engineer","category":"dataengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/q4cjm1n6fm.webp","company_name":"YData.ai","company_slug":"ydata-ai","company_twitter":"YData_ai","description":"\u003cp\u003eWe are currently looking for a Senior Data Engineer to join our team. Our product has built-in data pipelines that require scale to cope with high volumes of data. You will be working on a highly motivated team that is responsible for productizing ML solutions.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch2\u003e\u003cstrong\u003eYour Tasks\u003c/strong\u003e\u003c/h2\u003e\u003cul\u003e\u003cli\u003eDevelop highly scalable integrations with different data-sources\u003c/li\u003e\u003cli\u003eDesign and scale research pipelines\u003c/li\u003e\u003cli\u003eDrive decisions on data processing\u003c/li\u003e\u003cli\u003eAbility to define your priorities\u003c/li\u003e\u003cli\u003eOwnership and accountability for your tasks\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch2\u003e\u003cstrong\u003eYour Profile\u003c/strong\u003e\u003c/h2\u003e\u003cul\u003e\u003cli\u003eStrong algorithmic thinking and programming skills (Python)\u003c/li\u003e\u003cli\u003eExperience with distributed data processing (Spark, Dask, etc.)\u003c/li\u003e\u003cli\u003eGood understanding of Data Science workflows/pipelines (Data Cleaning and Data Processing)\u003c/li\u003e\u003cli\u003eUnderstanding of tools such as Kubernetes, Airflow or Kubeflow is a plus\u003c/li\u003e\u003cli\u003ePassionate about learning new tools and keeping yourself up-to-date\u003c/li\u003e\u003cli\u003eWillingness to communicate and share your knowledge with other team members\u003c/li\u003e\u003cli\u003eWillingness to work in agile processes\u003c/li\u003e\u003cli\u003eFluent in English\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch2\u003e\u003cstrong\u003eOur Perks ‚Äì More than just a job\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eHave an impact. With innovation and smart technology, we are changing the way organizations use and share data\u003c/p\u003e\u003cp\u003e Trust-based working. We don't punch the clock ‚Äì organize your own schedule. We trust in what you do!\u003c/p\u003e\u003cp\u003e Improve yourself. You can have fun at work at the same time you learn and improve yourself. We only hire the best and make them even better.\u003c/p\u003e\u003cp\u003e Push boundaries. Everyone is equally important and works together on uncharted challenges alongside inspiring colleagues from all over the world.\u003c/p\u003e\u003cp\u003e Feel at home. Literally! We are remote work enthusiasts!\u003c/p\u003e\u003cp\u003e Feel it‚Äôs your own company. Check our stock options plan. We want to have you onboard and be part of YData.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWant to write the history of data science and artificial intelligence with us? Submit your application now. We're excited to hear from you!\u003c/p\u003e","id":18888,"location":"Europe, Africa, North America, South America, Central America","location_type":"remote","position":"Senior Data Engineer","published_at":"2022-03-06T12:27:36Z","slug":"q4cjm1n6fm-senior-data-engineer","status":"approved","tags":["Python","Spark","Dask","Kubernetes"],"type":"fulltime"},{"application_url_or_email":"https://angel.co/company/ydata/jobs/683530-mlops-back-end-engineer","category":"softwareengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/vc3ynqb6l9.webp","company_name":"YData.ai","company_slug":"ydata-ai","company_twitter":"YData_ai","description":"\u003cp\u003eWe're looking for an MLOps / Back-End Engineer who will help us shape our team, drive the company to the next level, and have the most direct influence on our success.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch2\u003e\u003cstrong\u003eYour Profile\u003c/strong\u003e\u003c/h2\u003e\u003cul\u003e\u003cli\u003eExperience or interest to work with Go and/or Python languages\u003c/li\u003e\u003cli\u003eExperience with infrastructure technologies (Kubernetes and Docker)\u003c/li\u003e\u003cli\u003eExperience developing distributed systems and microservice architectures\u003c/li\u003e\u003cli\u003eUnit, integration, and end-to-end tests are an essential part of your coding style\u003c/li\u003e\u003cli\u003ePassionate about learning new tools and keeping yourself up-to-date\u003c/li\u003e\u003cli\u003eWillingness to communicate and share your knowledge with other team members\u003c/li\u003e\u003cli\u003eWillingness to work in agile processes, like Scrum or Kanban\u003c/li\u003e\u003cli\u003eFluent in English\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch2\u003e\u003cstrong\u003eYour Responsibilities\u003c/strong\u003e\u003c/h2\u003e\u003cul\u003e\u003cli\u003eYou will be part of a self-organized, cross-functional team building a data platform\u003c/li\u003e\u003cli\u003eSince our team is currently being developed from scratch, we need pragmatic engineers\u003c/li\u003e\u003cli\u003eYou are not only our 'code', you take responsibility for the whole product your team delivers\u003c/li\u003e\u003cli\u003eYou are curious and figure out how things work and how they should work for your product\u003c/li\u003e\u003cli\u003eYou bring your core expertise but are open to getting your hands dirty with back-end, DevOps, QA, and customer success\u003c/li\u003e\u003cli\u003eYou have a problem-solving attitude\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch2\u003e\u003cstrong\u003eOur Perks ‚Äì More than just a job\u003c/strong\u003e\u003c/h2\u003e\u003cul\u003e\u003cli\u003eHave an impact. With innovation and smart technology, we are changing the way organizations use and share data.\u003c/li\u003e\u003cli\u003eTrust-based working. We don't punch the clock ‚Äì organize your own schedule. We trust in what you do!\u003c/li\u003e\u003cli\u003eImprove yourself. We only hire the best and make them even better.\u003c/li\u003e\u003cli\u003eFeel at home. Literally! We are remote work enthusiasts!\u003c/li\u003e\u003cli\u003eFeel it‚Äôs your own company. Besides salary, we offer stock options because we want you to be part of YData.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWant to write the history of artificial intelligence with us? Submit your application now. We're excited to hear from you!\u003c/p\u003e","id":18887,"location":"Europe, Africa, North America, South America, Central America","location_type":"remote","position":"MLOps / Back-End Engineer","published_at":"2022-03-06T12:27:30Z","slug":"vc3ynqb6l9-mlops-back-end-engineer","status":"approved","tags":["Go","Python","Kubernetes","Docker"],"type":"fulltime"},{"application_url_or_email":"https://angel.co/company/ydata/jobs/918696-cloud-infrastructure-engineer","category":"softwareengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/ni0frws4gc.webp","company_name":"YData.ai","company_slug":"ydata-ai","company_twitter":"YData_ai","description":"\u003cp\u003eWe're looking for a Cloud Infrastructure Engineer who will help us shape our team, drive the company to the next level, and have the most direct influence on our success.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch2\u003e\u003cstrong\u003eYour Profile\u003c/strong\u003e\u003c/h2\u003e\u003cul\u003e\u003cli\u003eExperience with infrastructure technologies (Terraform, Cloud Formation, Kubernetes, Kustomize, and Docker)\u003c/li\u003e\u003cli\u003eExperience with cloud providers (AWS, Azure, GCP)\u003c/li\u003e\u003cli\u003eInterested in working together with the Founders\u003c/li\u003e\u003cli\u003ePassionate about learning new tools and keeping yourself up-to-date\u003c/li\u003e\u003cli\u003eWillingness to communicate and share your knowledge with other team members\u003c/li\u003e\u003cli\u003eWillingness to work in agile processes, like Scrum or Kanban\u003c/li\u003e\u003cli\u003eFluent in English\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch2\u003e\u003cstrong\u003eYour Responsibilities\u003c/strong\u003e\u003c/h2\u003e\u003cul\u003e\u003cli\u003eYou will be part of a self-organized, cross-functional team building a software platform\u003c/li\u003e\u003cli\u003eSince our team is currently being developed from scratch, we need pragmatic engineers\u003c/li\u003e\u003cli\u003eYou are not only our 'code', you take responsibility for the whole product your team delivers\u003c/li\u003e\u003cli\u003eYou are curious and figure out how things work and how they should work for your product\u003c/li\u003e\u003cli\u003eYou bring your core expertise but are open to getting your hands dirty with different cloud infrastructure, on-prem or virtualized, DevOps, QA, and software architecture\u003c/li\u003e\u003cli\u003eYou have a problem-solving attitude\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch2\u003e\u003cstrong\u003eOur Perks ‚Äì More than just a job\u003c/strong\u003e\u003c/h2\u003e\u003cul\u003e\u003cli\u003eHave an impact. With innovation and smart technology, we are changing the way organizations use and share data.\u003c/li\u003e\u003cli\u003eTrust-based working. We don't punch the clock ‚Äì organize your own schedule. We trust in what you do!\u003c/li\u003e\u003cli\u003eFeel at home. Literally! We are remote work enthusiasts!\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWant to write the history of artificial intelligence with us? Send us your application. We're excited to hear from you!\u003c/p\u003e","id":18886,"location":"Europe, Africa, North America, South America, Central America","location_type":"remote","position":"Cloud infrastructure Engineer","published_at":"2022-03-06T12:27:20Z","slug":"ni0frws4gc-cloud-infrastructure-engineer","status":"approved","tags":["Terraform","Kubernetes","Kustomize","Docker"],"type":"fulltime"},{"application_url_or_email":"https://boards.greenhouse.io/faire/jobs/5893190002?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"machinelearning","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/edyq9egblg.webp","company_name":"Faire Wholesale","company_slug":"faire-wholesale","company_twitter":"faire_wholesale","description":"\u003cp\u003e\u003cstrong\u003eAbout Faire\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eFaire is an online wholesale marketplace built on the belief that the future is local ‚Äî there are over 2 million independent retailers in North America and Europe doing more than $2 trillion in revenue. At Faire, we're using the power of tech, data, and machine learning to connect this thriving community of entrepreneurs across the globe. Picture your favorite boutique in town ‚Äî we help them discover the best products from around the world to sell in their stores. With the right tools and insights, we believe that we can level the playing field so that small businesses everywhere can compete with these big box and e-commerce giants.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eBy supporting the growth of independent businesses, Faire is driving positive economic impact in local communities, globally. We‚Äôre looking for smart, resourceful and passionate people to join us as we power the shop local movement. If you believe in community, come join ours.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eJob Description\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eAt Faire we build elegant and efficient products to deliver superior customer experiences and enhance marketplace efficiency at the same time. From the mobile checkout process, to personalized search ranking, to the intelligent underwriting engine that determines credit limits for retailers --- we are constantly iterating and innovating our product offering to create more value for the ecosystem.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eYou will be working closely with other data scientists, engineers, and product managers to drive projects that derive value from our unique, rich, and rapidly growing data on two sided marketplace. You will lead projects that enable software driven machine learning deployment to improve Faire‚Äôs core metrics.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat you will be doing:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eLeverage machine learning to optimize Faire‚Äôs two-sided marketplace dynamics\u003c/li\u003e\u003cli\u003eDesign, build and scale Real-Time and Batch processing pipelines to compute features, perform inference, and make decisions\u003c/li\u003e\u003cli\u003eImprove Faire‚Äôs credit portfolio by evaluating creditworthiness of retailers on Faire‚Äôs platform; use predictive modeling to dynamically assign credit limits that minimize default risk and maximize growth.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat it takes:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eAn advanced degree (MS or PhD) in a relevant discipline such as Computer Science, Machine Learning, or another similar field.\u003c/li\u003e\u003cli\u003e3+ years of experience in software engineering or building and deploying machine learning models with large datasets\u003c/li\u003e\u003cli\u003eStrong coding skills in Python/Java/Scala or equivalent\u003c/li\u003e\u003cli\u003eSolid understanding of engineering and infrastructure best practices, general software development principles with a machine learning software development life-cycle orientation\u003c/li\u003e\u003cli\u003eResourcefulness and proactiveness: track record for executing independent projects and leading complex, multi-functional projects with several dependencies.\u003c/li\u003e\u003cli\u003eStrong communication skills and the ability to work with others in a closely collaborative team environment.\u003c/li\u003e\u003cli\u003ePrior experience solving data problems in two-sided marketplaces is a big plus.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy you‚Äôll love working at Faire\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eWe are entrepreneurs: \u003c/strong\u003eFaire is being built for entrepreneurs, by entrepreneurs. We believe entrepreneurship is a calling and our mission is to empower entrepreneurs to chase their dreams. Every member of our team is an owner of the business and taking part in the founding process.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eWe are using technology and data to level the playing field:\u003c/strong\u003e We are leveraging the power of product innovation and machine learning to connect brands and boutiques from all over the world, building a growing community of more than 350,000 small business owners.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eWe build products our customers love:\u003c/strong\u003e Everything we do is ultimately in the service of helping our customers grow their business because our goal is to grow the pie - not steal a piece from it. Running a small business is hard work, but using Faire makes it easy.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eWe are curious and resourceful:\u003c/strong\u003e Inquisitive by default, we explore every possibility, test every assumption, and develop creative solutions to the challenges at hand. We lead with curiosity and data in our decision making, and reason from a first principles mentality.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eFaire was founded in 2017 by a team of early product and engineering leads from Square. We‚Äôre backed by some of the top investors in retail and tech including: Y Combinator, Lightspeed Venture Partners, Forerunner Ventures, Khosla Ventures, Sequoia Capital, Founders Fund, and DST Global. We have headquarters in San Francisco and Kitchener-Waterloo, and a global employee presence across offices in Salt Lake City, Atlanta, Toronto, London, New York, LA, and Sao Paulo. To learn more about Faire and our customers, you can read more on our\u003ca href=\"https://blog.faire.com/\"\u003e blog\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eFaire provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity or gender expression.\u003c/p\u003e","id":17712,"location":"North America","location_type":"remote","position":"Senior Machine Learning Engineer","published_at":"2022-02-08T21:19:53Z","slug":"edyq9egblg-senior-machine-learning-engineer","status":"approved","tags":["Engineering","Java","Machine Learning","Python"],"type":"fulltime"},{"application_url_or_email":"https://boards.greenhouse.io/faire/jobs/5893238002?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"dataengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/0pv3qxqcrp.webp","company_name":"Faire Wholesale","company_slug":"faire-wholesale","company_twitter":"faire_wholesale","description":"\u003cp\u003e\u003cstrong\u003eAbout Faire\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eFaire is an online wholesale marketplace built on the belief that the future is local ‚Äî there are over 2 million independent retailers in North America and Europe doing more than $2 trillion in revenue. At Faire, we're using the power of tech, data, and machine learning to connect this thriving community of entrepreneurs across the globe. Picture your favorite boutique in town ‚Äî we help them discover the best products from around the world to sell in their stores. With the right tools and insights, we believe that we can level the playing field so that small businesses everywhere can compete with these big box and e-commerce giants.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eBy supporting the growth of independent businesses, Faire is driving positive economic impact in local communities, globally. We‚Äôre looking for smart, resourceful and passionate people to join us as we power the shop local movement. If you believe in community, come join ours.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eJob Description\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eThe Data Engineering team is the backbone of all data-related processes and enables the Data Science team to develop and deploy a wide variety of algorithms and models that power the marketplace. Our infrastructure is used by the whole company for analytics, reporting, forecasting and research. We care about having a reliable infrastructure with quality data and building machine learning models that help our customers thrive.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eAs a Senior Data Engineer you‚Äôll be responsible for developing and automating large scale, high-performance data storage and processing systems.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eOur team already includes experienced Data Scientists and Engineers from Airbnb, Facebook, Quora, Square, Uber, Pinterest, and Stitch Fix. Faire will soon be known as a top destination for data science and machine learning, and you will help take us there!\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat you will be doing:¬†\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eDevelop our machine learning infrastructure to help us scale for where we‚Äôre going over the next several years\u003c/li\u003e\u003cli\u003eManage our data infrastructure and ETL platform\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat it takes:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e3+ years experience in a Data Engineering role with an emphasis on managing data warehouses\u003c/li\u003e\u003cli\u003eStrong skills in Python, Git, Docker, SQL, Airflow, ETL pipelines\u003c/li\u003e\u003cli\u003eFamiliarity with Snowflake or BigQuery\u003c/li\u003e\u003cli\u003eA passion for programming and solving problems with code\u003c/li\u003e\u003cli\u003eA bachelor's degree in Computer Science/Software Engineering or equivalent industry experience\u003c/li\u003e\u003cli\u003eA love for technology, and an insatiable curiosity for new tools to tackle real problems¬†\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eFaire provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity or gender expression.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy you‚Äôll love working at Faire\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eWe are entrepreneurs: \u003c/strong\u003eFaire is being built for entrepreneurs, by entrepreneurs. We believe entrepreneurship is a calling and our mission is to empower entrepreneurs to chase their dreams. Every member of our team is an owner of the business and taking part in the founding process.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eWe are using technology and data to level the playing field:\u003c/strong\u003e We are leveraging the power of product innovation and machine learning to connect brands and boutiques from all over the world, building a growing community of more than 350,000 small business owners.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eWe build products our customers love:\u003c/strong\u003e Everything we do is ultimately in the service of helping our customers grow their business because our goal is to grow the pie - not steal a piece from it. Running a small business is hard work, but using Faire makes it easy.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eWe are curious and resourceful:\u003c/strong\u003e Inquisitive by default, we explore every possibility, test every assumption, and develop creative solutions to the challenges at hand. We lead with curiosity and data in our decision making, and reason from a first principles mentality.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eFaire was founded in 2017 by a team of early product and engineering leads from Square. We‚Äôre backed by some of the top investors in retail and tech including: Y Combinator, Lightspeed Venture Partners, Forerunner Ventures, Khosla Ventures, Sequoia Capital, Founders Fund, and DST Global. We have headquarters in San Francisco and Kitchener-Waterloo, and a global employee presence across offices in Salt Lake City, Atlanta, Toronto, London, New York, LA, and Sao Paulo. To learn more about Faire and our customers, you can read more on our\u003ca href=\"https://blog.faire.com/\"\u003e blog\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eFaire provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity or gender expression.\u003c/p\u003e","id":17707,"location":"North America","location_type":"remote","position":"Senior Data Engineer","published_at":"2022-02-08T21:17:59Z","slug":"0pv3qxqcrp-senior-data-engineer","status":"approved","tags":["Airflow","BigQuery","Engineering","ETL"],"type":"fulltime"},{"application_url_or_email":"https://nostosgenomics.recruitee.com/o/data-engineer?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"dataengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/mbxbnw261d.webp","company_name":"Nostos Genomics","company_slug":"nostos-genomics","company_twitter":"nostosgenomics","description":"\u003cp\u003eWe are a venture-backed health tech startup supported by leading investors and scientists on a mission to improve the lives of the 400 million people around the world who suffer from genetic diseases. The platform we have developed uses artificial intelligence and synthetic biology to decipher how changes in the DNA of humans lead to disease. Through this platform, we enable genetic testing labs to provide clear and fast diagnoses to more patients.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eFor this, we've gathered one of the best teams of experts in genetic data, machine learning, and business development. Our people aren't just part of a team, they're part of something bigger. As a community of creative thinkers and doers, we're paving the way for a new generation of genetic healthcare. Our people are what make us great. So, finding the best people is everything to us.\u003c/p\u003e\u003cp\u003e¬†\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eYour role\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eWe are looking for a Data Engineer to lead the improvement of our data infrastructure and take ownership of our data management. You will be responsible for setting up a data lakehouse infrastructure integrating ETL processes and workflows for different scientific and business applications.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eYou will be embedded in our Artificial Intelligence team and work closely together with our Computational Genomics, Software and Product teams, creating innovative solutions to handle large datasets with applications in data science pipelines and machine learning analytics. The ability to think strategically and work collaboratively with hands-on mentality are expected from this role.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eWe foster a flexible work environment and encourage applications from candidates that are either based in Berlin or would work remotely with a willingness to travel to Berlin occasionally. \u003c/em\u003e¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eRequirements\u003c/h3\u003e\u003cp\u003e\u003cem\u003eEssential\u003c/em\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eDegree in a quantitative subject such as computer science, engineering, physics, mathematics or a related discipline\u003c/li\u003e\u003cli\u003eCompetent Python experience (2+ years of experience)\u003c/li\u003e\u003cli\u003eExperience with software engineering best practices, such as version control (e.g. Git) and test-driven development\u003c/li\u003e\u003cli\u003eComfortable working with relational databases such as Postgres\u003c/li\u003e\u003cli\u003eAble to write complex SQL queries (e.g. using efficient joins, aggregations and window functions)\u003c/li\u003e\u003cli\u003eExperience handling large volumes of data within computational workflows\u003c/li\u003e\u003cli\u003eExperience using workflow orchestration tools such as Apache Airflow\u003c/li\u003e\u003cli\u003eExperience with AWS services such as S3, Athena, RDS and DMS\u003c/li\u003e\u003cli\u003eExperience building end to end data lakehouse style pipelines in AWS\u003c/li\u003e\u003cli\u003eExposure to the 'PyData stack' (e.g. Pandas, NumPy, SciKit-Learn, MatPlotLib and/or Seaborn)\u003c/li\u003e\u003cli\u003eAbility to take ownership and responsibility as well as find pragmatic solutions to potentially complex problems\u003c/li\u003e\u003cli\u003eSkills in verbal and written communication\u003c/li\u003e\u003cli\u003eHighly motivated and able to work in a fast-paced, multidisciplinary and collaborative environment\u003c/li\u003e\u003cli\u003eWillingness to learn and openness to feedback\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cem\u003eNice-to-have\u003c/em\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eInterest in data science and machine learning\u003c/li\u003e\u003cli\u003eHands-on experience using Docker and Kubernetes\u003c/li\u003e\u003cli\u003eKnowledge on how to manage data and compute services on AWS using infrastructure-as-code (e.g. AWS CloudFormation templates and/or Terraform)\u003c/li\u003e\u003cli\u003eStart-up experience\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat we value in our team\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eOur team reflects the interdisciplinary collaboration required to solve this big challenge ‚Äì ranging from software and data science to genetics and healthcare. We are a proudly diverse, international group of creative problem-solvers and humble learners that care about having a positive impact on society and are also aware of the trust placed in us. This is why we value transparency and kindness, taking ownership and encouraging your personal growth:\u003c/p\u003e\u003cul\u003e\u003cli\u003eDevelop your personal skills and knowledge with resources like books and courses to learn continuously\u003c/li\u003e\u003cli\u003eDynamic and flexible work environment that you can design (incl. remote work options)\u003c/li\u003e\u003cli\u003eParticipate in our success with equity options\u003c/li\u003e\u003cli\u003ePossibility to grow with the company and influence our direction\u003c/li\u003e\u003cli\u003eRegular social activities: participate only if you feel like it\u003c/li\u003e\u003cli\u003eAdditionally, we offer good coffee, a selection of healthy snacks and company-subsidized public transport in our Berlin-based offices\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWe see diversity as a core feature of our team and we encourage you to apply especially if you are from an underrepresented group.\u003c/p\u003e","id":17690,"location":"Worldwide","location_type":"remote","position":"Data Engineer","published_at":"2022-02-08T21:08:50Z","slug":"mbxbnw261d-data-engineer","status":"approved","tags":["Airflow","AWS","Engineering","ETL"],"type":"fulltime"},{"application_url_or_email":"https://boards.greenhouse.io/angi/jobs/5892336002?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"dataengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/vm5kgrooo4.webp","company_name":"Angi","company_slug":"angi","company_twitter":"angi_home","description":"\u003cp\u003eAngi¬Æ is the home for everything home. From repairs and renovations to products and financing, Angi is transforming every touch point in home services. With over 25 years of experience and a network of nearly 250,000 pros, we have helped more than 150 million people with their home needs. Our products and technology help our customers love where they live while helping small businesses grow and thrive. We believe the home is the most important place on earth and we are at the beginning of our ambitious journey to redefine how people care for their homes - join us!\u003c/p\u003e\u003cp\u003e¬†\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eThe Team and Role\u003c/strong\u003e¬†\u003c/p\u003e\u003cp\u003eAngi is looking for a Data Engineer to play a key role on the Data Engineering team. The successful candidate will develop and maintain strong relationships with teammates while ensuring delivery of high quality Engineering solutions.¬†The ideal candidate will have outstanding communication skills, proven data infrastructure design and implementation capabilities, strong business acumen, and an innate drive to deliver results. He/she will be a self-starter, comfortable with ambiguity and will enjoy working in a fast-paced dynamic environment.\u003c/p\u003e\u003cp\u003e¬†\u003c/p\u003e\u003cp\u003eAs a Data Engineer, you will be responsible for:\u003c/p\u003e\u003cul\u003e\u003cli\u003eEstablishing and instilling innovative practices, patterns, and toolkits to deliver enterprise-grade data assets.\u003c/li\u003e\u003cli\u003eInteract closely with stakeholders to determine analytics needs and translate those into efficient and scalable data processes\u003c/li\u003e\u003cli\u003ePartnering with passionate counterparts to deliver awesomeness and continuously evaluate the best way to deliver short-term and long-term solutions\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e¬†\u003c/p\u003e\u003cp\u003eThe folks in this role are usually successful when they have experience in:\u003c/p\u003e\u003cul\u003e\u003cli\u003eExtensive hands on experience in developing reusable data integration and streaming platforms using Python or another comparable language\u003c/li\u003e\u003cli\u003eBroad knowledge of data infrastructure ecosystem\u003c/li\u003e\u003cli\u003eExperience with modern cloud database platforms, such as Snowflake or Redshift\u003c/li\u003e\u003cli\u003eStrong Analytical and SQL skills with demonstrated strength in data modeling, ELT development, and data warehousing\u003c/li\u003e\u003cli\u003eExperience with GitLab, CI/CD workflows, AWS services, containerization (Docker), Grafana, and orchestration tools\u003c/li\u003e\u003cli\u003eProven track record of sharing outcomes through written communication, including an ability to effectively communicate with both business and technical teams\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e¬†\u003c/p\u003e\u003cp\u003eCompensation \u0026amp; Benefits:\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe salary band for this position ranges from 70k-170k, commensurate with experience and performance. Compensation may vary based on factors such as cost of living.\u003c/li\u003e\u003cli\u003eThis position will be eligible for a competitive year end performance bonus \u0026amp; equity package.\u003c/li\u003e\u003cli\u003eFull medical, dental, vision package to fit your needs\u003c/li\u003e\u003cli\u003eFlexible vacation policy: work hard and take time when you need it\u003c/li\u003e\u003cli\u003ePet discount plans \u0026amp; retirement plan with company match (401K)\u003c/li\u003e\u003cli\u003eThe rare opportunity to work with sharp, motivated teammates solving some of the most unique challenges and changing the world\u003c/li\u003e\u003c/ul\u003e","id":17683,"location":"Worldwide","location_type":"remote","position":"Data Engineer","published_at":"2022-02-08T21:07:37Z","slug":"vm5kgrooo4-data-engineer","status":"approved","tags":["AWS","Data Warehousing","Engineering","GitLab"],"type":"fulltime"},{"application_url_or_email":"https://jobs.lever.co/mattermost/3a85123c-b46d-4ab8-a97e-7049885d3649?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"dataengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/qofsrtw71b.webp","company_name":"Mattermost","company_slug":"mattermost","company_twitter":"Mattermost","description":"\u003cp\u003eMattermost is an open source platform for secure collaboration across the entire software development lifecycle. Hundreds of thousands of developers around the globe trust Mattermost to increase their productivity by bringing together team communication, task and project management, and workflow orchestration into a unified platform for agile software development.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eFounded in 2016, Mattermost‚Äôs open source platform powers over 800,000 workspaces worldwide with the support of over 4,000 contributors from across the developer community. The company serves over 800 customers, including European Parliament, NASA, Nasdaq, Samsung, SAP, United States Air Force and Wealthfront, and is backed by world-class investors including Battery Ventures, Redpoint, S28 Capital, YC Continuity. To learn more, visit \u003ca href=\"http://www.mattermost.com\"\u003ewww.mattermost.com\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWe value high impact work, ownership, self-awareness and being focused on customer success. If these values match who you are, we hope you'll learn more about \u003ca href=\"https://handbook.mattermost.com/company/about-mattermost\"\u003eworking at Mattermost\u003c/a\u003e and apply!\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eMattermost is a data-driven organization, and we are looking for a best-in-class Data Analytics Engineer to operate, maintain and enhance our internal self-service data warehouse. You will be responsible for managing our Snowflake data warehouse, building and maintaining ETL and data ingestion processes, and providing assistance to other teams within the company who input data into the warehouse and carry out analytics with the data it holds.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eResponsibilities:\u003c/h3\u003e\u003cul\u003e\u003cli\u003eDesign, deploy, own and maintain best-in-class data infrastructure (Snowflake, Airflow, dbt, EKS, etc.)\u003c/li\u003e\u003cli\u003eManage the development and operation of high-volume data pipelines to enable the business to make data-driven decisions.\u003c/li\u003e\u003cli\u003ePartner with the Analytics team to build data models that are actionable for the business\u003c/li\u003e\u003cli\u003eDrive strategic and architectural decisions around the evolution of our data warehouse and pipelines.\u003c/li\u003e\u003cli\u003eWrite complex SQL queries and ETL pipelines.\u003c/li\u003e\u003cli\u003eCollaborate with Product and Engineering teams to ensure that new products and features are instrumented to capture product usage data/telemetry\u003c/li\u003e\u003cli\u003eProvide assistance to other teams within the company supplying data to the warehouse or consuming it for analytics.\u003c/li\u003e\u003cli\u003eDesign schemas and guide usage of the data warehouse to maintain it as a high quality source of insights.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eRequired Background/Skills:\u003c/h3\u003e\u003cul\u003e\u003cli\u003e3+ years experience as a Data Engineer\u003c/li\u003e\u003cli\u003e3+ years experience using Python\u003c/li\u003e\u003cli\u003eStrong SQL SkillsExperience building and managing a data lake in an enterprise setting\u003c/li\u003e\u003cli\u003eExperience applying Software Engineering best practices to Data Analytics, including CI/CD, version control, infrastructure as code, etc.\u003c/li\u003e\u003cli\u003eExperience in Schema Design, Data Modelling and Metadata management\u003c/li\u003e\u003cli\u003eComfortable working with a variety of different tools and scripting languages and flexible in your choice of key technologies in the data analytics stack.\u003c/li\u003e\u003cli\u003eAbility to work independently in a small, globally-distributed remote team.\u003c/li\u003e\u003cli\u003eStrong written and verbal communication skills and a proven ability to work with engineers, data analysts and non-technical stakeholders across all departments of an organization.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eNice to haves:\u003c/h3\u003e\u003cul\u003e\u003cli\u003eExperience developing software and scripts in Go and Javascript.\u003c/li\u003e\u003cli\u003eExperience with Snowflake, Apache Airflow, dbt and Rudderstack.\u003c/li\u003e\u003cli\u003eExperience with data visualisation tools such as Looker.\u003c/li\u003e\u003cli\u003eExperience working in open source communities.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eMattermost is a remote-first company with staff living and working across the globe.¬†We are currently hiring staff in these countries/regions:\u003c/p\u003e\u003cp\u003eAustralia - Brazil - Canada - Chile - Colombia - Finland - Georgia - Germany - Greece - India - Ireland - Mauritius - Mexico - Pakistan - Philippines - Poland - Portugal - South Africa - Spain - Turkey - Uganda - United Kingdom - United States\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWe are constantly working towards adding more countries/regions to this list, but first we need to make sure we are compliant with local laws and regulations, which takes time.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eMattermost is made up of people from a wide variety of backgrounds and lifestyles. We embrace diversity and invite applications from people from all walks of life. We don't discriminate against staff or applicants based on gender identity or expression, sexual orientation, race, religion, age, national origin, citizenship, disability, pregnancy status, veteran status, or any other differences. Also, if you have a disability, please let us know if there's any way we can make the interview process better for you; we're happy to accommodate!\u003c/p\u003e","id":17676,"location":"Worldwide","location_type":"remote","position":"Data Engineer","published_at":"2022-02-08T21:06:05Z","slug":"qofsrtw71b-data-engineer","status":"approved","tags":["Airflow","Data Analytics","Data pipelines","Engineering"],"type":"fulltime"},{"application_url_or_email":"https://glide.recruitee.com/o/data-engineer?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"dataengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/gfbanjlu0r.webp","company_name":"Glide","company_slug":"glide","company_twitter":"glidedotcom","description":"\u003cp\u003e\u003cstrong\u003eAbout Us\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eGlide‚Äôs mission is to make the process of buying and selling homes faster, simpler, and safer for real estate agents and their clients. We serve an industry larger than any other, streamlining the most important financial transaction of a consumer‚Äôs lifetime.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eOur platform is used by more than 50,000 real estate agents on over $100B worth of home sale transactions each year. Agents choose Glide because we focus on making their lives simpler, helping them deliver outstanding customer service, stay compliant and grow their businesses.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eOur culture is based on moving fast, putting customer needs first and supporting one another to accomplish incredible results. We operate as an independent subsidiary of Compass (NYSE: COMP), allowing us to combine the agility of a startup with the resources of a public company.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eJoin Glide because you want to do your best work, to collaborate with amazing people and to make a lasting impact at a pivotal moment in people‚Äôs lives.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAbout this Role\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eAs a Data Engineer at Glide you will support and build data pipelines that enable stakeholders to do their jobs effectively and answer their own questions. You will be working hands on with the latest modern data stack, making sure the models are correct and on time.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAt Glide You Will\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eSupport the management of our data lake/warehouse infrastructure\u003c/li\u003e\u003cli\u003eWrite and Maintain dbt models, with proper documentation and testing\u003c/li\u003e\u003cli\u003eTranslate complex business requirements and raw data into transformed tables to support analysis across all areas of the business\u003c/li\u003e\u003cli\u003eDevising architectural solutions that are performant, scalable, well-tested, and maintainable\u003c/li\u003e\u003cli\u003eEfficiently handle vast amounts of data from multiple sources and destinations, including relational databases as well as external systems\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eRequirements\u003c/h3\u003e\u003cp\u003e\u003cstrong\u003eWhat We Look For\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e2+ years of experience working in data engineering.\u003c/li\u003e\u003cli\u003eProven experience in Business Intelligence\u003c/li\u003e\u003cli\u003eStrong skills in Python and SQL\u003c/li\u003e\u003cli\u003eExpert in data modelling, extra points if you know your way around dbt\u003c/li\u003e\u003cli\u003eExperience with AWS Ecosystem (Redshift, S3, EMR, ECS)\u003c/li\u003e\u003cli\u003eExperience using orchestration tools like Airflow\u003c/li\u003e\u003cli\u003eExperience in distributed systems (Spark, Hudi, Hadoop, Hive)\u003c/li\u003e\u003cli\u003eDeep interest in learning about and keeping up with quickly evolving industry trends around the modern data stack and data best practices\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat we offer\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eAbove the average salary \u003c/strong\u003e(base salary in USD, paid in Pesos with a highly competitive exchange rate)\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eHealth insurance stipend.\u003c/strong\u003e We will cover the health insurance for you and your family via a stipend.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003e15 working days of paid vacations\u003c/strong\u003e\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eTraining Budget.\u003c/strong\u003e We like to be updated and encourge you to learn new things.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eGreat equipment\u003c/strong\u003e. Each employee gets a brand new Macbook.\u003c/li\u003e\u003c/ul\u003e","id":17352,"location":"Worldwide","location_type":"remote","position":"Data Engineer","published_at":"2022-02-04T18:55:27Z","slug":"gfbanjlu0r-data-engineer","status":"approved","tags":["Airflow","AWS","Business Intelligence","Data pipelines"],"type":"fulltime"},{"application_url_or_email":"https://jobs.lever.co/opendoor/7b08b7df-f2d4-4251-8dd1-36f9b230dedc?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"machinelearning","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/vhafue1wpc.webp","company_name":"Opendoor","company_slug":"opendoor","company_twitter":"Opendoor","description":"\u003cp\u003eAbout Opendoor:¬†¬†Founded in 2014, Opendoor‚Äôs mission is to empower everyone with the freedom to move. We believe the traditional real estate process is broken and our goal is simple: build a digital, end-to-end customer experience that makes buying and selling a home simple, certain and fast. We have assembled a dedicated team with diverse backgrounds to support more than 100,000 homes bought and sold with us and the customers who have selected Opendoor as a trusted partner in handling one of their largest financial transactions. But the work is far from over as we continue to grow in new markets. Transforming the real estate industry takes tenacity and dedication. It takes problem solvers and builders. It takes a tight knit community of teammates doing the best work of their lives, pushing one another to transform a complicated process into a simple one.¬†¬†So where do you fit in? Whether you‚Äôre passionate about real estate, people, numbers, words, code, or strategy -- we have a place for you. Real estate is broken. Come help us fix it.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eAbout the Role:¬†We are looking for an Engineer with an expertise in Machine Learning or Data Science to join our Pricing Team. In this role, you will use your experience to develop a deep understanding of our AI-driven pricing strategy at Opendoor, and to drive the implementation of our algorithms and experiments while adhering to engineering best practices and keeping an eye towards quality as we scale. You will design and develop platforms, services, and tools to tackle a variety of challenges related to price optimization, inventory management, forecasting, workflow automation, and more. You will collaborate closely with Data Scientists and Analysts on our pricing team to influence our pricing strategy at Opendoor and deliver highly scalable services and products that enable delightful customer experiences. We are looking for engineers with proven ability to deliver results, a passion to learn, and expertise in service oriented architectures, distributed systems, algorithms, analytics, databases, and front-end technologies.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eIn this role, you will be responsible for:\u003c/h3\u003e\u003cul\u003e\u003cli\u003eWorking with product, engineers, and data scientists to contribute to all phases of software development including ideation, prototyping, design, and production.\u003c/li\u003e\u003cli\u003eBuilding products and services from scratch, as well as evolving existing systems using Spark, AWS, Databricks, and python.\u003c/li\u003e\u003cli\u003eDeveloping tools to support the unique challenges of pricing homes at Opendoor, such as custom human data labeling tools or a workflow orchestrator.\u003c/li\u003e\u003cli\u003eApplying your technical and quantitative expertise to guide the team in making intelligent, scalable, and pragmatic design decisions.\u003c/li\u003e\u003cli\u003eInfluencing the technology and architectural roadmap of the engineering teams.\u003c/li\u003e\u003cli\u003ePlaying an active role in hiring and mentoring other engineers.\u003c/li\u003e\u003cli\u003eBuilding deep domain expertise in pricing and real estate.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eWe‚Äôre looking for teammates who have:\u003c/h3\u003e\u003cul\u003e\u003cli\u003eBS or higher degree in Computer Science, Engineering, or a related technical field.\u003c/li\u003e\u003cli\u003eQuantitative experience, either via previous job experience or a degree in Mathematics, Statistics, or a related field, or continuing studies, such as online courses and certifications.\u003c/li\u003e\u003cli\u003eProven ability to design and build production-quality software systems.\u003c/li\u003e\u003cli\u003eExcellent programming skills in Python.\u003c/li\u003e\u003cli\u003eExperience developing models in a deep learning framework such as pytorch or tensorflow, or with SparkML or SageMaker.\u003c/li\u003e\u003cli\u003eExperience in different phases of the ML project lifecycle, including experimentation, EDA, model training, model deployment (batch and/or real time ), AB testing, and monitoring model quality in production over time.\u003c/li\u003e\u003cli\u003eProven ability to use data and metrics to drive decisions.\u003c/li\u003e\u003cli\u003eHistory of independently leading cross-functional projects and prioritizing work based on business impact.\u003c/li\u003e\u003cli\u003eAbility to understand the needs of stakeholders, define business requirements, and architect systems that will scale and extend to accommodate them over time.\u003c/li\u003e\u003cli\u003eExpertise breaking down complex problems, documenting solutions, and sequencing work to make iterative improvements.\u003c/li\u003e\u003cli\u003eA sense of ownership and a passion for delighting customers through innovation and creative solutions to complex problems.\u003c/li\u003e\u003cli\u003eExcellent communication skills and high attention to detail.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eNice To Have:\u003c/h3\u003e\u003cul\u003e\u003cli\u003eExperience in Go/Java/C++ is a plus.\u003c/li\u003e\u003cli\u003eExperience working closely to support data science or analytics teams is a plusExperience in web development (e.g. React, API design, Rails, Postgres) is a plus.\u003c/li\u003e\u003cli\u003ePrior experience with data processing technology (e.g. Spark, Hadoop, SQL) and workflow management tools (e.g. Airflow, dbt) is a plus.\u003c/li\u003e\u003cli\u003eExperience with a cloud computing platform such as AWS or GPC is a plus.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eMore About Us: Want to learn more about us and how we are revolutionizing the home buying and selling process? Learn more \u003ca href=\"https://www.opendoor.com/w/about\"\u003eabout us\u003c/a\u003e on our website, check out our profile on \u003ca href=\"https://www.themuse.com/profiles/opendoor\"\u003eThe Muse\u003c/a\u003e to learn more about our culture from our team members, or read our \u003ca href=\"https://www.opendoor.com/w/blog\"\u003eblog posts\u003c/a\u003e to hear about the work we are doing.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWe Offer the Following Benefits and Perks:\u003c/p\u003e\u003cul\u003e\u003cli\u003eFull medical, dental, and vision with optional 85% coverage for dependents\u003c/li\u003e\u003cli\u003eFlexible vacation policy\u003c/li\u003e\u003cli\u003eGenerous parental leave\u003c/li\u003e\u003cli\u003ePaid time off to volunteer\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003ePlease note that these benefits and perks are available only to Full Time team members and do not apply to contract roles.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eOpendoor Values Openness:\u003c/p\u003e\u003cp\u003eOur team celebrates our diverse backgrounds. We believe that being open about who we are and what we do allows us to be better. Individuals seeking employment at Opendoor are considered without regards to race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, veteran status, sexual orientation, gender identity or other protected status under all applicable laws, regulations, and ordinances. For California residents: for more information about the categories of personal information that we collect for recruiting purposes, please see our personnel¬†\u003ca href=\"https://www.opendoor.com/w/ccpa-personnel-privacy-policy\"\u003ePrivacy Policy\u003c/a\u003e.\u003c/p\u003e","id":17330,"location":"Worldwide","location_type":"remote","position":"Sr Machine Learning Platform Engineer","published_at":"2022-02-04T18:42:22Z","slug":"vhafue1wpc-sr-machine-learning-platform-engineer","status":"approved","tags":["Airflow","AWS","Deep Learning","Distributed Systems"],"type":"fulltime"},{"application_url_or_email":"https://boards.greenhouse.io/doma/jobs/3834841?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"datascience","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/akmffrpcy4.webp","company_name":"Doma","company_slug":"doma","company_twitter":"DomaHQtweets","description":"\u003ch2\u003eBuild the solution that transforms the real estate industry!¬†\u003c/h2\u003e\u003cp\u003eWant to infuse a $34B sector of the insurance and real estate industry with predictive analytics and a tech-forward customer experience? Yearning for a startup culture within a profitable nationwide company? Join Doma and send an entirely new type of real estate model into the wild.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eAbout Us¬†\u003c/h3\u003e\u003cp\u003eDoma and its family of brands - States Title, North American Title Company (NATC) and North American Title Insurance Company (NATIC) - offer solutions for lenders, real estate professionals, title agents, and homeowners that make closings vastly more simple and efficient, reducing cost and increasing customer satisfaction.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eOur Values¬†\u003c/h3\u003e\u003cul\u003e\u003cli\u003eCustomer Obsessed ‚Äì We always put our customers first.¬†\u003c/li\u003e\u003cli\u003eSolution Driven ‚Äì We solve problems that other people are afraid to.¬†\u003c/li\u003e\u003cli\u003ePeople leaders ‚Äì We grow all of our people into leaders.¬†\u003c/li\u003e\u003cli\u003eOne Team ‚Äì We believe inclusion and teamwork produce the best results.¬†\u003c/li\u003e\u003cli\u003eDirect with Respect ‚Äì We communicate with honesty and respect to our colleagues, customers, and partners.¬†\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat You‚Äôll Do\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eShape the technical direction of the data science function for our line of business\u003c/li\u003e\u003cli\u003eDevelop and deploy predictive models and analytical solutions; establish best practices\u003c/li\u003e\u003cli\u003eGrow into our go-to-expert¬†in pricing, risk, and forecasting\u003c/li\u003e\u003cli\u003eResearch new data sources, vetting for efficacy and applicability\u003c/li\u003e\u003cli\u003eArchitect and build a platform for our algorithmic engines to run at scale\u003c/li\u003e\u003cli\u003eWork with business and engineering partners to influence product direction and business strategy\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat You‚Äôll Need\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eAdvanced degree (Masters or PhD) in Mathematics, Statistics, Economics, Data Science or another quantitative field, or actuarial training (ACAS/FCAS/ASA/SOA) preferred\u003c/li\u003e\u003cli\u003e6+ years of hands-on experience utilizing data science (AI/ML) to develop models and deploy solutions to solve complex business problems\u003c/li\u003e\u003cli\u003eStrong experience in SQL and programming in Python\u003c/li\u003e\u003cli\u003eStrong organizational, interpersonal, and communication skills (both written and verbal)\u003c/li\u003e\u003cli\u003eA bias towards solving problems from a customer-centric lens and an intuitive sense for how the work aligns closely with business objectives\u003c/li\u003e\u003cli\u003eBonus: Experience or interest in pricing and risk models\u003c/li\u003e\u003cli\u003eBonus: Experience with big data technologies such as Spark, AWS Athena, Redshift, Looker, Tableau, or others.\u003c/li\u003e\u003cli\u003eBonus: Experience with Azure, Airflow, and containerization (Docker)\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch2\u003eWe want the work you do here to be the best work of your life.¬†¬†\u003c/h2\u003e\u003cp\u003eWe believe the most valuable investment we can make - and the greatest boost we can give to your career - is to build an outstanding team of colleagues who are passionate about our mission.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWe currently offer the following benefits and will continually evolve them with the goal of efficiently attracting, retaining, and leveraging the very highest quality talent.¬†\u003c/p\u003e\u003cul\u003e\u003cli\u003eOur passionate,¬†capable team will always be our #1 benefit¬†\u003c/li\u003e\u003cli\u003eWe are proud of the team we have built so far, and we are excited about the team we have yet to add¬†\u003c/li\u003e\u003cli\u003eLearn something new every day¬†\u003c/li\u003e\u003cli\u003eGet more done than you would anywhere else¬†\u003c/li\u003e\u003cli\u003eCompetitive salaries¬†\u003c/li\u003e\u003cli\u003eTop-of-the-line computer equipment¬†\u003c/li\u003e\u003cli\u003eMultiple Medical, Dental, and Vision Benefits options to allow you to customize to your and your Family‚Äôs needs¬†\u003c/li\u003e\u003cli\u003ePaid Time Off¬†¬†\u003c/li\u003e\u003cli\u003eHealth \u0026amp; Dependent Care Flexible Spending Accounts (FSA)¬†\u003c/li\u003e\u003cli\u003eShort Term \u0026amp;¬†Long Term¬†Disability¬†\u003c/li\u003e\u003cli\u003eCommuter Flexible Spending Account (i.e.¬†Transit or Parking)¬†\u003c/li\u003e\u003cli\u003eSupplemental Life and AD\u0026amp;D Insurance¬†\u003c/li\u003e\u003cli\u003eAuto \u0026amp; Home Insurance Group Life Insurance¬†\u003c/li\u003e\u003cli\u003ePet Insurance¬†\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eWe believe in Equal Opportunity¬†\u003c/h3\u003e\u003cp\u003eWe are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.¬†\u003c/p\u003e","id":17327,"location":"USA","location_type":"remote","position":"Founding Staff Data Scientist","published_at":"2022-02-04T18:37:51Z","slug":"akmffrpcy4-founding-staff-data-scientist","status":"approved","tags":["Airflow","AWS","Azure","Big Data"],"type":"fulltime"},{"application_url_or_email":"https://boards.greenhouse.io/janetechnologies/jobs/5876997002?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"dataengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/swcngss38o.webp","company_name":"Jane Technologies","company_slug":"jane-technologies","company_twitter":null,"description":"\u003cp\u003eJane Technologies, Inc. is an MIT-founded technology company in the cannabis industry, and we are growing extremely quickly. Our technology digitizes dispensary inventories and creates virtual menus to allow users to explore, purchase, and review products. Our secret sauce is a clean product catalogue with rich content, which we use to map inventory across thousands of stores to a single product. For this reason, we have some of the cleanest transactional, browsing, and product data in the industry. And we‚Äôre looking for a passionate, personable, creative, and entrepreneurial Data Analyst to join the team.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eThe Data Engineer¬†is responsible for developing and maintaining data pipelines, storage, and integrations. Their duties include coordinating with data scientists and software engineers to create unique data infrastructure, running tests on their designs, monitoring data quality, and updating systems to accommodate changes in company needs.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eCulture is the single most important component of Jane‚Äôs success to date. A successful candidate will thrive in our environment of mutual support, relentless pursuit of excellence, creativity, and complete lack of ego. We believe in the cannabis industry's ability to bring well-being, health, and love into this world, and it is our mission to bring confidence to the online cannabis shopping experience. To learn more about who we are, our culture, and whether this is the right place for you, read our Key Values profile:\u003ca href=\"https://www.keyvalues.com/jane\"\u003e https://www.keyvalues.com/jane\u003c/a\u003e.¬†Check out our product at:\u003ca href=\"https://www.iheartjane.com/\"\u003e https://www.iheartjane.com/.\u003c/a\u003e\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eResponsibilities:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eBuild data pipelines (ETL) on complex datasets to assist analyses done by data scientists, analysts, and machine learning engineers.\u003c/li\u003e\u003cli\u003eIdentifying, designing, and implementing internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes.\u003c/li\u003e\u003cli\u003eImplementing tooling for monitoring and maintaining data pipelines.\u003c/li\u003e\u003cli\u003eWorking with stakeholders including data, design, product and executive teams and assisting them with data-related technical issues.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eMinimum qualifications:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e1+ years experience in a Data Engineer related role\u003c/li\u003e\u003cli\u003eSQL (PostgreSQL preferred, but any variation will suffice)\u003c/li\u003e\u003cli\u003ePython\u003c/li\u003e\u003cli\u003eExperience retrieving data from API endpoints\u003c/li\u003e\u003cli\u003eAWS (S3, IAM, and other related tools)\u003c/li\u003e\u003cli\u003eEffective communication/presentation\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eNice to haves:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eSalesforce API\u003c/li\u003e\u003cli\u003eLooker\u003c/li\u003e\u003cli\u003eSnowflake\u003c/li\u003e\u003cli\u003eFeature store for ML jobs\u003c/li\u003e\u003cli\u003eAWS Jobs/Airflow\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eJane Technologies is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification, in accordance with applicable federal, state, and local laws. EOE, including disability/vets.\u003c/p\u003e","id":17227,"location":"Worldwide","location_type":"remote","position":"Senior Data Engineer","published_at":"2022-02-03T17:11:41Z","slug":"swcngss38o-senior-data-engineer","status":"approved","tags":["Airflow","AWS","Classification","Data pipelines"],"type":"fulltime"},{"application_url_or_email":"https://apply.workable.com/j/17EDDC4009/apply?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"dataengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/1ljwy3gxbl.webp","company_name":"BrainPOP","company_slug":"brainpop","company_twitter":"brainpop","description":"\u003cp\u003e\u003cem\u003eBrainPOP is an online K-12 educational solution that makes rigorous learning experiences accessible and engaging for all. Proven to raise academic achievement, BrainPOP has been a trusted resource to more than six million educators, and engages the hearts and challenges the minds of over 300 million learners worldwide. \u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eBrainPOP provides endless opportunities for kids to take agency over their learning through playful, knowledge-building content and learner-driven projects, preparing them for success in the classroom and beyond. \u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWe are seeking a Senior Data Engineer to join our growing team. In this role, you will focus on building new data pipelines and refactoring existing ones that ingest and transform data from a wide array of sources. You will be part of a team responsible for delivering reliable, accurate and timely data to our stakeholders. The data that you provide will be consumed by data scientists, machine learning experts, executives, stakeholders across the company and our most important stakeholders: the districts, schools and teachers that rely on BrainPOP. You will be working collaboratively alongside other passionate Data Engineers, Data Analysts, and Software Engineers to support and maintain our data infrastructure.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eIn this role, you will:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eIdentify and implement improvements to our data ecosystem based on industry best practices.\u003c/li\u003e\u003cli\u003eBuild, refactor and maintain data pipelines that ingest data from multiple sources.\u003c/li\u003e\u003cli\u003eTransform and model datasets for myriad business use cases.\u003c/li\u003e\u003cli\u003eBuild and support the tools we use for monitoring data hygiene and the health of our pipelines.\u003c/li\u003e\u003cli\u003eSupport data discovery, certification and governance initiatives in partnership with our Data Science peers\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eOn your resume:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e4+ years experience working in a modern data engineering environment, including workflow orchestration, pipeline monitoring, warehouse health, etc.\u003c/li\u003e\u003cli\u003e3+ years of experience modeling data in a warehouse setting.\u003c/li\u003e\u003cli\u003eDemonstrated mastery of SQL and fluency in one or more programming languages, python strongly preferred.\u003c/li\u003e\u003cli\u003eExcellent understanding of data structures and algorithms.\u003c/li\u003e\u003cli\u003eFamiliarity with analytics and data science.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAbout our ideal candidate:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003ePassionate about improving education.\u003c/li\u003e\u003cli\u003eSelf-starting and interested in building a modern, best-in-class data platform.\u003c/li\u003e\u003cli\u003eExperience working in our data stack: AWS, Airflow, Snowflake, dbt, Looker, Docker\u003c/li\u003e\u003cli\u003eExcellent organizational skills.\u003c/li\u003e\u003cli\u003eBS, BA, MS, MA, or PhD in Information Science, Computer Science, Mathematics, or a related technical field.\u003c/li\u003e\u003cli\u003e5+ years of work experience in data-centric roles.\u003c/li\u003e\u003cli\u003eFamiliarity with data science concepts and statistics.\u003c/li\u003e\u003cli\u003eExperience using CDC, Kinesis or other streaming technologies.\u003c/li\u003e\u003cli\u003eExperience administering Airflow and/or Snowflake.\u003c/li\u003e\u003cli\u003eExperience with data discovery tools such as Amundsen.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eLife at BrainPOP\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eOur commitment to supporting and empowering teachers and students is reflected in our dedication to enhancing the lives of our employees‚Äîin and out of the office.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eOur team is made up of educators, data scientists, published authors, engineers, artists, bakers, film buffs, cyclists, dual-citizens, and so much more. We value Diversity \u0026amp; Inclusion, collaboration and learning from multiple perspectives, and encourage people to bring their most authentic selves to work.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eBesides offering a comprehensive benefits package and putting an emphasis on work-life balance, we make it a point to integrate fun and play into the workplace.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWe offer:\u003c/p\u003e\u003cul\u003e\u003cli\u003eCorporate Donation Matching\u003c/li\u003e\u003cli\u003eMedical, Dental, Vision and Paid Life Insurance\u003c/li\u003e\u003cli\u003e401K with a company match\u003c/li\u003e\u003cli\u003eFriends \u0026amp; Family BrainPOP Subscription\u003c/li\u003e\u003cli\u003eLearning \u0026amp; Development Stipend\u003c/li\u003e\u003cli\u003eWellness Activities (ClassPass Membership)\u003c/li\u003e\u003cli\u003eAnnual Performance Bonus \u0026amp; Equity Appreciation Plan\u003c/li\u003e\u003cli\u003eCompany Events (happy hours, volunteering opportunities, trivia nights and monthly Town Halls)\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWhat we do today directly impacts how teachers teach, and students learn. We continue to be inspired because we can see the difference we‚Äôre making and we‚Äôre proud to be a creative, collaborative, always-teaching and always-learning community.\u003c/p\u003e\u003cp\u003eBrainPOP is a hybrid work environment, allowing employees to self-select where they work‚Äìwhether fully remote in approved states or in-office in our New York headquarters.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWe are able to employ remotely out of the following approved hiring states:\u003c/p\u003e\u003cul\u003e\u003cli\u003eCalifornia\u003c/li\u003e\u003cli\u003ePennsylvania\u003c/li\u003e\u003cli\u003eTexas\u003c/li\u003e\u003cli\u003eFlorida\u003c/li\u003e\u003cli\u003eGeorgia\u003c/li\u003e\u003cli\u003eOregon\u003c/li\u003e\u003cli\u003eNorth Carolina\u003c/li\u003e\u003cli\u003eNew York (we have our HQ office in this state but candidates may choose to work fully remote in NY if so desired)\u003c/li\u003e\u003cli\u003eNew Jersey\u003c/li\u003e\u003cli\u003eConnecticut\u003c/li\u003e\u003cli\u003eMassachusetts\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eWe believe that a diverse organization is a more effective organization. BrainPOP is an Equal Opportunity/Affirmative Action Employer. \u003c/em\u003e\u003c/p\u003e","id":17226,"location":"United States","location_type":"remote","position":"Senior Data Engineer","published_at":"2022-02-03T17:10:21Z","slug":"1ljwy3gxbl-senior-data-engineer","status":"approved","tags":["Airflow","AWS","Data pipelines","Engineering"],"type":"fulltime"},{"application_url_or_email":"https://boards.greenhouse.io/samsara/jobs/3320963?gh_jid=3320963\u0026ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"softwareengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/fchbtuibaq.webp","company_name":"Samsara","company_slug":"samsara","company_twitter":"Samsara","description":"\u003cp\u003e\u003cstrong\u003eWho We Are\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eSamsara is the pioneer of the Connected Operations Cloud, which allows businesses and organizations that depend on physical operations to harness IoT (Internet of Things) data to develop actionable business insights and improve their operations. Samsara operates in North America and Europe and serves more than 20,000 customers across a wide range of industries including transportation, wholesale and retail trade, construction, field services, logistics, utilities and energy, government, healthcare and education, manufacturing and food and beverage. Learn more about Samsara's mission to increase the efficiency, safety, and sustainability of the operations that power the global economy at \u003ca href=\"http://www.samsara.com\"\u003ewww.samsara.com\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAbout the role:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eThe Senior Data Engineer will be a core technical contributor to Samsara‚Äôs data engineering team with deep expertise in creating and manipulating large, complex datasets that feed central data warehouses for Samsara‚Äôs data science, product, and engineering teams. The Data Engineer will be responsible for standing up and maintaining data pipelines, building computed tables and database structures, identifying data integrity issues, and data management at Samsara. The Data Engineer will also work closely with Samsara data analysts, data scientists, and ML Engineers to help prep data for models and dashboards.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch4\u003e\u003cstrong\u003eIn this role, you will:\u003c/strong\u003e¬†\u003c/h4\u003e\u003cul\u003e\u003cli\u003eBuild highly reliable computed tables (including unstructured data like video and audio) combining and transforming data across multiple sources, including Samsara sensor data, customer metadata, and financial data\u003c/li\u003e\u003cli\u003eUse Python to access, manipulate, and join external datasets to internal data (e.g., via REST APIs, Pyspark, SparkSQL)\u003c/li\u003e\u003cli\u003eEnsure very large databases and compute clusters operate optimally and enable Data Science, ML, and software engineering teams\u003c/li\u003e\u003cli\u003eImplement and maintain database structures and governance\u003c/li\u003e\u003cli\u003eDevelop / maintain data management at Samsara (including scalable systems to document metadata)\u003c/li\u003e\u003cli\u003eWork closely with stakeholders across the company from product engineers, data scientists, customer support, finance, and more, to build data pipelines that solve business needs\u003c/li\u003e\u003cli\u003eAssist our machine learning and data science team by building robust data annotation, training, and inference pipelines\u003c/li\u003e\u003cli\u003eChampion, role model, and embed Samsara‚Äôs cultural principles (Focus on Customer Success, Build for the Long Term, Adopt a Growth Mindset, Be Inclusive, Win as a Team) as we scale globally and across new offices\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eMinimum requirements for this role:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eBA / MS degree in Computer Science, Statistics, or related discipline\u003c/li\u003e\u003cli\u003eExperience in data engineering focused on ML / data science and ML operations\u003c/li\u003e\u003cli\u003eExperience with standing up ETL pipelines to handle massive volumes of data\u003c/li\u003e\u003cli\u003eExperience working with Hadoop or Spark-based data platforms\u003c/li\u003e\u003cli\u003eExperience processing and manipulating data very large data, preferably in Python (e.g., with PySpark)\u003c/li\u003e\u003cli\u003eStrong proficiency in SQL, Python, and working with REST APIs\u003c/li\u003e\u003cli\u003eKnowledge of software engineering fundamentals; high level of comfort reading and understanding full-stack / backend development code (e.g., our Go code base)\u003c/li\u003e\u003cli\u003eFamiliarity managing code via GitHub or other code versioning tool\u003c/li\u003e\u003cli\u003e4+ years experience as a data engineer or data-focused Software Engineer\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAn ideal candidate also has:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eSome experience with data visualization, preferably in Tableau\u003c/li\u003e\u003cli\u003eExperience with distributed machine learning\u003c/li\u003e\u003cli\u003eSome experience with time series based data\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eAt Samsara, we welcome all. All sizes, colors, cultures, sexes, beliefs, religions, ages, people. We depend on the unique approaches of our team members to help us solve complex problems. We are committed to increasing diversity across our team and ensuring that Samsara is a place where people from all backgrounds can make an impact.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAccommodations\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eSamsara is an inclusive work environment, and we are committed to ensuring equal opportunity in employment for qualified persons with disabilities. Please email \u003c/em\u003e\u003ca href=\"mailto:accessibleinterviewing@samsara.com\"\u003e\u003cem\u003eaccessibleinterviewing@samsara.com\u003c/em\u003e\u003c/a\u003e\u003cem\u003e or \u003c/em\u003e\u003ca href=\"https://form.asana.com/?k=dcecpJYeVpOJt1RCCU7Hdg\u0026amp;d=182866037607514\"\u003e\u003cem\u003eclick here\u003c/em\u003e\u003c/a\u003e\u003cem\u003e if you require any reasonable accommodations throughout the recruiting process.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eUS Only:\u003c/em\u003e\u003c/strong\u003e\u003cem\u003e Please note that Samsara‚Äôs COVID-19 vaccination policy requires all team members who will be meeting in person for business or working from one of our offices to be fully vaccinated against COVID-19. People who cannot be vaccinated for qualifying medical conditions, sincerely held religious beliefs, and other legally protected categories, may request an accommodation.¬†\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eBenefits\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eWorking at Samsara has its perks: for all global full-time employees, we provide private medical and dental insurance, growth and development opportunities, regular virtual team and company events, and other location-based perks. Review all of Samsara's current benefit offerings at \u003ca href=\"https://www.rewards.samsara.com/\"\u003erewards.samsara.com.\u003c/a\u003e\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eFlexible Work\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eAt Samsara, we have adopted a flexible way of working, enabling teams and individuals to do their best work. We value in person collaboration and know a change of scenery and quiet space to work is welcomed from time to time. Our offices remain open for those who prefer to collaborate or work in-office. We also offer a co-working support program for employees who are not located near a Samsara office. For more information about our Flexible Work model, please see our blog post \u003ca href=\"https://www.samsara.com/blog/the-future-of-work-at-samsara/\"\u003ehere\u003c/a\u003e.\u003c/p\u003e","id":16924,"location":"USA","location_type":"remote","position":"Senior Data Engineer","published_at":"2022-01-31T19:12:16Z","slug":"fchbtuibaq-senior-data-engineer","status":"approved","tags":["Data pipelines","Engineering","ETL","Finance"],"type":"fulltime"},{"application_url_or_email":"https://boards.greenhouse.io/samsara/jobs/3853047?gh_jid=3853047\u0026ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"dataengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/tcqcxesng3.webp","company_name":"Samsara","company_slug":"samsara","company_twitter":"Samsara","description":"\u003cp\u003e\u003cstrong\u003eWho We Are\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eSamsara is the pioneer of the Connected Operations Cloud, which allows businesses and organizations that depend on physical operations to harness IoT (Internet of Things) data to develop actionable business insights and improve their operations. Samsara operates in North America and Europe and serves more than 20,000 customers across a wide range of industries including transportation, wholesale and retail trade, construction, field services, logistics, utilities and energy, government, healthcare and education, manufacturing and food and beverage. Learn more about Samsara's mission to increase the efficiency, safety, and sustainability of the operations that power the global economy at \u003ca href=\"http://www.samsara.com\"\u003ewww.samsara.com\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAbout the role:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eData and Analytics is a critical team within Marketing. Our mission is to enable revenue performance by providing marketing and sales teams with the insights, tools, infrastructure and consultation to make data driven decisions. We are a scrappy and growing team that loves all things data! The team will be composed of data engineers, analytics managers and data scientists. We are passionate about leveraging world class data and analytics to deliver a great customer experience.¬†¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eOur team promotes an agile, collaborative, supportive environment where diverse thinking, innovative design, and experimentation is welcomed and encouraged.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch4\u003e\u003cstrong\u003eIn this role, you will:\u003c/strong\u003e¬†\u003c/h4\u003e\u003cul\u003e\u003cli\u003eDevelop and maintain databases, datasets, pipelines and Samsara‚Äôs Customer Data Platform (CDP) to enable advanced segmentation, targeting, automation and analytics\u003c/li\u003e\u003cli\u003eWork with data from a variety of sources including but not limited to: CRM data, Product data, Marketing data, Order flow data, Support ticket volume data\u003c/li\u003e\u003cli\u003eManage critical data pipelines to enable our growth initiatives and advanced analytics\u003c/li\u003e\u003cli\u003eFacilitate data integration and transformation requirements for moving data between applications; ensuring interoperability of applications with data mart and CDP environments\u003c/li\u003e\u003cli\u003eDevelop and improve the current data architecture, data quality, monitoring and data availability\u003c/li\u003e\u003cli\u003eWrite data transformations in SQL/Python to generate data products consumed by customer systems and Analytics, Marketing Operations, Sales Operations teams\u003c/li\u003e\u003cli\u003eChampion, role model, and embed Samsara‚Äôs cultural principles (Focus on Customer Success, Build for the Long Term, Adopt a Growth Mindset, Be Inclusive, Win as a Team) as we scale globally and across new offices\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eMinimum requirements for the role:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e2+ years of working experience in a growth, software or data engineering role\u003c/li\u003e\u003cli\u003eStrong SQL and proficient Python knowledge with hands-on data modeling experience¬†\u003c/li\u003e\u003cli\u003eExposure to data warehouse technical architectures, infrastructure components, ETL/ ELT and reporting/analytic tools\u003c/li\u003e\u003cli\u003eHands-on experience working with modern data technologies stack such as Data Bricks, Google Big Query, Redshift, RDS, Snowflake or similar solutions¬†\u003c/li\u003e\u003cli\u003eComfort in working with business customers to gather requirements and gain a deep understanding of varied datasets\u003c/li\u003e\u003cli\u003eSelf-starter, motivated, responsible, innovative and technology-driven individual who performs well both independently and as a team member\u003c/li\u003e\u003cli\u003eA proactive problem solver and have good communication as well as project management skills to relay your findings and solutions across technical and non technical audiences\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAn ideal candidate also has:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eFamiliarity with customer, marketing and/or web data¬†\u003c/li\u003e\u003cli\u003eKnowledge of Marketo, Salesforce.com and Google Analytics\u003c/li\u003e\u003cli\u003eExperience working with CDPs such as Segment, Blueshift, Lytics or Adobe Real-time CDP\u003c/li\u003e\u003cli\u003eExperience with data visualization tools and packages (e.g. Looker, Domo, Tableau, MixPanel)\u003c/li\u003e\u003cli\u003eFamiliarity with Marketing Technologies (MarTech stacks)\u003c/li\u003e\u003cli\u003eExperience coding with Scala, R or Pandas\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eAt Samsara, we welcome all. All sizes, colors, cultures, sexes, beliefs, religions, ages, people. We depend on the unique approaches of our team members to help us solve complex problems. We are committed to increasing diversity across our team and ensuring that Samsara is a place where people from all backgrounds can make an impact.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAccommodations\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eSamsara is an inclusive work environment, and we are committed to ensuring equal opportunity in employment for qualified persons with disabilities. Please email \u003c/em\u003e\u003ca href=\"mailto:accessibleinterviewing@samsara.com\"\u003e\u003cem\u003eaccessibleinterviewing@samsara.com\u003c/em\u003e\u003c/a\u003e\u003cem\u003e or \u003c/em\u003e\u003ca href=\"https://form.asana.com/?k=dcecpJYeVpOJt1RCCU7Hdg\u0026amp;d=182866037607514\"\u003e\u003cem\u003eclick here\u003c/em\u003e\u003c/a\u003e\u003cem\u003e if you require any reasonable accommodations throughout the recruiting process.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eUS Only:\u003c/em\u003e\u003c/strong\u003e\u003cem\u003e Please note that Samsara‚Äôs COVID-19 vaccination policy requires all team members who will be meeting in person for business or working from one of our offices to be fully vaccinated against COVID-19. People who cannot be vaccinated for qualifying medical conditions, sincerely held religious beliefs, and other legally protected categories, may request an accommodation.¬†\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eBenefits\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eWorking at Samsara has its perks: for all global full-time employees, we provide private medical and dental insurance, growth and development opportunities, regular virtual team and company events, and other location-based perks. Review all of Samsara's current benefit offerings at \u003ca href=\"https://www.rewards.samsara.com/\"\u003erewards.samsara.com.\u003c/a\u003e\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eFlexible Work\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eAt Samsara, we have adopted a flexible way of working, enabling teams and individuals to do their best work. We value in person collaboration and know a change of scenery and quiet space to work is welcomed from time to time. Our offices remain open for those who prefer to collaborate or work in-office. We also offer a co-working support program for employees who are not located near a Samsara office. For more information about our Flexible Work model, please see our blog post \u003ca href=\"https://www.samsara.com/blog/the-future-of-work-at-samsara/\"\u003ehere\u003c/a\u003e.\u003c/p\u003e","id":16923,"location":"USA","location_type":"remote","position":"Marketing Data Engineer","published_at":"2022-01-31T19:13:54Z","slug":"tcqcxesng3-marketing-data-engineer","status":"approved","tags":["Data pipelines","Engineering","ETL","Healthcare"],"type":"fulltime"},{"application_url_or_email":"https://boards.greenhouse.io/everfi/jobs/3352873?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"dataengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/v9ixdf791s.webp","company_name":"EVERFI","company_slug":"everfi","company_twitter":"EVERFI","description":"\u003cp\u003eEVERFI is an international technology company driving social impact through education to address the most challenging issues affecting society ranging from financial wellness to mental health to workplace conduct and other critical topics. Founded in 2008, EVERFI‚Äôs Impact-as-a-Service TM solution and digital educational content have reached more than 41 million learners globally. In 2020, the company was recognized as one of the World‚Äôs Most Innovative Companies by \u003cem\u003eFast Company\u003c/em\u003e and was featured on \u003cem\u003eFortune Magazine‚Äôs\u003c/em\u003e Impact 20 List. The company was also named to the 2021 GSV EdTech 150, a list of the most transformative growth companies in digital learning. Some of America‚Äôs leading CEOs and venture capital firms are EVERFI investors including Amazon founder and CEO Jeff Bezos, Google Chairman Eric Schmidt, Twitter founder Evan Williams, as well as Advance, Rethink Education, Rethink Impact, The Rise Fund, and TPG Growth. To learn more about EVERFI and how you can #answerthecall please visit\u003ca href=\"http://everfi.com/\"\u003e everfi.com\u003c/a\u003e or follow us on\u003ca href=\"https://c212.net/c/link/?t=0\u0026amp;l=en\u0026amp;o=2348374-1\u0026amp;h=3982107549\u0026amp;u=https%3A%2F%2Fwww.facebook.com%2Feverfi%2F\u0026amp;a=Facebook\"\u003e Facebook\u003c/a\u003e,\u003ca href=\"https://c212.net/c/link/?t=0\u0026amp;l=en\u0026amp;o=2348374-1\u0026amp;h=335111280\u0026amp;u=https%3A%2F%2Fwww.instagram.com%2Feverfi%2F\u0026amp;a=Instagram\"\u003e Instagram\u003c/a\u003e,\u003ca href=\"https://c212.net/c/link/?t=0\u0026amp;l=en\u0026amp;o=2348374-1\u0026amp;h=1526369965\u0026amp;u=https%3A%2F%2Fwww.linkedin.com%2Fcompany%2Feverfi%2F\u0026amp;a=LinkedIn\"\u003e LinkedIn\u003c/a\u003e, or\u003ca href=\"https://c212.net/c/link/?t=0\u0026amp;l=en\u0026amp;o=2348374-1\u0026amp;h=443747734\u0026amp;u=https%3A%2F%2Ftwitter.com%2FEVERFI\u0026amp;a=Twitter\"\u003e Twitter\u003c/a\u003e @EVERFI.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eThe Senior Data Engineer will design, develop, monitor and maintain a robust and scalable data platform used by other data analyst and engineering teams to deliver powerful insights to both internal and external stakeholders. This role will create abstractions to speed the platform‚Äôs adoption and build reliable pipelines to support growing data processing and analytics needs. Ideally this person will be a self-starter, detail and quality oriented, and excited about the prospects of having a big impact with data at EVERFI.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eResponsibilities¬†\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eDesign, build and maintain data infrastructure that powers both batch and realtime processing of billions of records a day.\u003c/li\u003e\u003cli\u003eImprove the data quality and reliability of data pipelines through monitoring, validation and failure detection\u003c/li\u003e\u003cli\u003eDesign, build and maintain a central data cataloging system to ease integration and discovery of datasets\u003c/li\u003e\u003cli\u003eDevelop data pipelines that provide fast, optimized, and robust end-to-end solutions\u003c/li\u003e\u003cli\u003eAutomate manual processes and create a platform in favor of self-service data consumption\u003c/li\u003e\u003cli\u003eDeploy and configure components to production environments.\u003c/li\u003e\u003cli\u003eParticipate in on-call schedule to provide emergency incident support\u003c/li\u003e\u003cli\u003eMentor and train teammates on design and operation of data platform\u003c/li\u003e\u003cli\u003eStay current with industry trends, making recommendations as needed to help the company excel¬†\u003c/li\u003e\u003cli\u003eOther job-related duties as assigned\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eSkills, Experience and Qualifications\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eBachelor‚Äôs Degree in Computer Science or Engineering a plus\u003c/li\u003e\u003cli\u003e3+ years of relevant industry experience in Data Engineering working with large scale data driven systems\u003c/li\u003e\u003cli\u003eExperience designing data schemas and fine-tuning queries around large, complex data sets\u003c/li\u003e\u003cli\u003eExtensive experience working with big data frameworks, like Hive, Spark, Presto and Airflow\u003c/li\u003e\u003cli\u003eExperience with data streaming systems such as Apache Kafka\u003c/li\u003e\u003cli\u003eDeep understanding of SQL and data warehouse systems, especially Redshift and Snowflake\u003c/li\u003e\u003cli\u003eExpertise in object-oriented and/or functional programming languages (Python preferred)\u003c/li\u003e\u003cli\u003eStrong overall programming skills, able to write modular, maintainable code\u003c/li\u003e\u003cli\u003eunderstanding of DevOps principles such as¬†automating of CI/CD pipelines and Infrastructure as code\u003c/li\u003e\u003cli\u003eUnderstanding of polyglot data persistence (relational, key/value, document, column)\u003c/li\u003e\u003cli\u003eExcellent problem-solving skills and the ability to proactively solve issues\u003c/li\u003e\u003cli\u003eExcellent communication and organizational skills and proven ability to complete tasks and meet deadlines\u003c/li\u003e\u003cli\u003eAbility to be flexible with working in tandem with a team of engineers or alone, as required\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWork-life, Culture, \u0026amp; Perks:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eCompetitive base salary and bonus potential\u003c/li\u003e\u003cli\u003e401k program and equity plan\u003c/li\u003e\u003cli\u003eComprehensive health care and excellent parental leave benefits\u003c/li\u003e\u003cli\u003eFlexible PTO and generous holiday schedule\u003c/li\u003e\u003cli\u003eCasual work environment\u003c/li\u003e\u003cli\u003eAnnual company-wide retreat\u003c/li\u003e\u003cli\u003eOpportunity to work with talented people who have fun in the workplace\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eCompany Values:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eWe‚Äôre looking for future team members who are energized and inspired by our values, as well as people who bring new backgrounds, perspectives, and experiences. At EVERFI, our eight core values are an active part of everything we do:\u003c/em\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eRelationships First\u003c/li\u003e\u003cli\u003eDemand Excellence\u003c/li\u003e\u003cli\u003eEmbrace Diversity of Thought \u0026amp; Drive Change\u003c/li\u003e\u003cli\u003eAct Like an Owner\u003c/li\u003e\u003cli\u003eAlways Show Up\u003c/li\u003e\u003cli\u003eShare the Credit\u003c/li\u003e\u003cli\u003eRequire Honest \u0026amp; Positivity\u003c/li\u003e\u003cli\u003eAlways Ask: ‚ÄúDid I Matter Today?‚Äù\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e¬†\u003c/p\u003e\u003cp\u003e\u003cem\u003eEVERFI appreciates your interest in our company as a place of employment. It is EVERFI policy to provide equal opportunity for employment to all qualified employees and applicants, regardless of race, religion, religious affiliation, ancestry, citizenship status, marital status, familial status, sexual orientation, gender identity, color, creed, national origin, sex, age, disability, or veteran status or any other characteristic protected by local, state or federal law. This policy applies to all areas of employment including recruitment, placement, training, transfer, promotion, termination, pay, and other forms of compensation and benefits. EVERFI will provide reasonable accommodations to qualified individuals with disabilities.\u003c/em\u003e\u003c/p\u003e","id":16920,"location":"USA","location_type":"remote","position":"Senior Data Engineer","published_at":"2022-01-31T19:11:01Z","slug":"v9ixdf791s-senior-data-engineer","status":"approved","tags":["Airflow","Big Data","Data pipelines","Engineering"],"type":"fulltime"},{"application_url_or_email":"https://jobs.lever.co/aquicore/0ba29491-1790-426c-9aaf-7a5580dc7c9c?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"dataengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/nbocqtriis.webp","company_name":"Aquicore","company_slug":"aquicore","company_twitter":"Aquicore","description":"\u003cp\u003e\u003cstrong\u003eWho We Are\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eAquicore was founded in 2013 in the early hours of the morning on the belief that smarter and more connected buildings will have a global impact in curbing our climate challenges and make buildings technologically ready for the next century. We create global impact by bettering the built environment every day. Our next generation of software which facilitates smarter building operations is used by the largest real estate owners and operators around the world. We are changing the industry from the ground up and we‚Äôre looking for the right people to achieve our mission!We‚Äôre amped by the work we do and driven to constantly propel our values and culture. While awards aren‚Äôt the goal, we are humbled to be recognized as one of the coolest places to work by organizations such as DC Inno. Our people come first and it‚Äôs the combination of our culture and our mission that has been our greatest differentiator. We take our core values as a company seriously and aspire to level-up our Aquicorians in their careers and professional growth.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eOur Challenge\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eWe are looking for a Data Engineer to help usher in the next generation of the Aquicore platform, working on a robust and scalable data platform and data pipelines that deliver truly unique products to market. Aquicore believes that seamless access to vast amounts of data is critical to improving the status-quo of Enterprise software. A successful Data Engineer will leverage their expertise at building data pipelines, integrating with data warehouses, and maintaining ETL products to allow Aquicore to deliver high-quality products to market much faster. We will challenge you to:Focus on solutions, share ideas, and solve problems rather than just write codeCreate design documents and construct formal documentation for cross-team educationIdentify patterns across large datasets, and translate them into heuristicsBring to life the platform that allows our customers to collect millions of data points from live sensors in commercial buildings, and utilize the information in helpful ways.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eThe Impact You‚Äôll Have\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eAs a Data Engineer, you will work as part of our Data team alongside Software Engineers and Data Scientists to create high quality deliverables that improve our ability to deliver business value to customers. You will design, construct, and maintain robust data pipelines that help power Aquicore's internal business operations, and customer platform. To do this, you will work with modern ETL/ELT systems that automate the data flow and transformation of datasets from multiple sources. You will unify structured and unstructured data from across dozens of sources. You will debug and optimize the performance of data pipelines and queries. You will have a key role in illuminating insights and products that make a difference in our world.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eThe skills we are looking for‚Ä¶\u003c/h3\u003e\u003cul\u003e\u003cli\u003eHighly responsive and able to work in a virtual environment¬†Individual contributor who works well on an agile team\u003c/li\u003e\u003cli\u003eSelf-starter with the drive, determination, and ability to take ownership of assigned tasks\u003c/li\u003e\u003cli\u003eEnjoys technology, cutting-edge software, and thrives in a small team environment\u003c/li\u003e\u003cli\u003eExperience designing, implementing, and maintaining ETL systems\u003c/li\u003e\u003cli\u003eDemonstrable experience with data pipelines in Airflow, Matillion, DBT, or similar\u003c/li\u003e\u003cli\u003eStrong software development chops to deliver unit-tested and scalable code in PythonStrong SQL knowledge and experience working with relational databases, query authoring (SQL), as well as a working familiarity with a variety of databases\u003c/li\u003e\u003cli\u003eExperience in database performance tuning\u003c/li\u003e\u003cli\u003eFamiliarity with data warehousing, modeling, and dashboarding - Redshift and Snowflake preferred\u003c/li\u003e\u003cli\u003eExperience with AWS, especially Redshift and S3Familiarity using team collaboration tools - we use GitHub, JIRA, and Confluence\u003c/li\u003e\u003cli\u003eUnderstanding of data architecture, modeling, and infrastructure concepts and patterns\u003c/li\u003e\u003cli\u003eFamiliarity with data visualizations tools (e.g. Tableau, Looker)\u003c/li\u003e\u003cli\u003eExperience with the complete SDLC and CI/CD procedures\u003c/li\u003e\u003cli\u003eAbility to give and receive constructive feedback while in code reviews and coaching sessions\u003c/li\u003e\u003cli\u003eEngaged and interested in continuous improvement \u0026amp; continuous development\u003c/li\u003e\u003cli\u003eMust-have attributes include hustle, grit, determination, courage, entrepreneurial ambition, and a deep desire to win\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eWithin 1 Month you will‚Ä¶\u003c/h3\u003e\u003cul\u003e\u003cli\u003eComplete our training \u0026amp; certification program designed to get you up to speed with our business and our customers. You‚Äôll learn about our business, product, vision, and team, and gain an understanding about how your role fits into the AQ family.\u003c/li\u003e\u003cli\u003eSpeak fluently about our customer segments and the businesses that buy and sell real estate who use our product.\u003c/li\u003e\u003cli\u003eUnderstand the fundamentals about real estate, how buildings work, and why the real estate industry buys and sells iconic skyscrapers across the cities of the US\u003c/li\u003e\u003cli\u003eParticipate in weekly team meetings, and get up to speed with our development process\u003c/li\u003e\u003cli\u003eDevelop familiarity with our current deployed data modelsDevelop familiarity with our current data pipelines, ETL/ELT processes \u0026amp; patterns, codebases, and software applications\u003c/li\u003e\u003cli\u003eDevelop familiarity with our Data Engineering frameworks and tools (Databricks, Airflow, DBT, and Snowflake)\u003c/li\u003e\u003cli\u003eEstablish a regular cadence of reporting your weekly accomplishments and challenges to your manager\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eWithin 3 Months you will‚Ä¶\u003c/h3\u003e\u003cul\u003e\u003cli\u003eDesign, launch, and measure the impact of an improvement to an existing feature.\u003c/li\u003e\u003cli\u003eYou‚Äôll understand the current state of the functionality and the unmet need; explore ways to iterate and build on what is there; and converge on the best solution given what you‚Äôve learned¬†\u003c/li\u003e\u003cli\u003eReport on the outcomes of one of your launches to the engineering \u0026amp; product teams.\u003c/li\u003e\u003cli\u003eYou will discuss how well goals and hypotheses were met, and what learnings to use in the next iteration.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eWithin 6 Months you will‚Ä¶\u003c/h3\u003e\u003cul\u003e\u003cli\u003eLaunch a feature from start to end as the primary engineering owner.\u003c/li\u003e\u003cli\u003eYou will execute the architecture and partner with engineering \u0026amp; product leadership to ensure that the right MVP is built and launched.\u003c/li\u003e\u003cli\u003eProactively identify and unblock knowledge sharing and communication challenges to unlock a scalable data engineering organization\u003c/li\u003e\u003cli\u003eEducate, mentor and train team members across the engineering teams on data engineering methodology and philosophy\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eWithin 12 Months you will‚Ä¶\u003c/h3\u003e\u003cul\u003e\u003cli\u003eForm strong opinions about our Roadmap and what we should be building based on your technical knowledge\u003c/li\u003e\u003cli\u003eBecome a critical voice and contributor to strategic discussions across Product\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eIs this role not a perfect fit?\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eSign up to stay in touch. We have new positions regularly and we‚Äôd love to reach out to you first when it opens up!\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWe are committed to equal opportunities and creating an inclusive environment for all our employees. We welcome applicants regardless of ethnic origin, national origin, gender, race, religious beliefs, disability, sexual orientation or age. Aquicore is an EEOC.\u003c/p\u003e","id":16467,"location":"USA","location_type":"remote","position":"Data Engineer","published_at":"2022-01-26T15:51:20Z","slug":"nbocqtriis-data-engineer","status":"approved","tags":["Airflow","AWS","Data pipelines","Data Warehousing"],"type":"fulltime"},{"application_url_or_email":"https://boards.greenhouse.io/flocksafety/jobs/5858180002?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"dataengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/2ol4g0m97m.webp","company_name":"Flock Safety","company_slug":"flock-safety","company_twitter":"Flock_Safety","description":"\u003cp\u003e\u003cstrong\u003eEliminate Crime. Build Community.¬†\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eFlock Safety provides a public safety operating system that empowers private communities and law enforcement to work together to eliminate crime. We are committed to protecting human privacy and mitigating bias in policing with the development of best-in-class technology rooted in ethical design, which unites civilians and public servants in pursuit of a safer, more equitable society.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eOur Safety-as-a-Service approach includes affordable devices powered by LTE and solar that can be installed anywhere.¬†Our technology detects and captures objective details, decodes evidence in real-time and delivers investigative leads into the hands of those who matter.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWhile safety is a serious business, we are a supportive team that is optimizing the remote experience to create strong and fun relationships even when we are physically apart\u003cstrong\u003e.\u003c/strong\u003e¬†Our flock of hard-working employees thrive in a positive and inclusive environment, where a bias towards action is rewarded. Flock Safety is headquartered in Atlanta and operates nationwide. We are well funded by Meritech Capital, Initialized Capital, YCombinator, Matrix Partners, BedRock Capital, and Founders Fund - and we're scaling quickly.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAbout the opportunity\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eAs a Data Engineer, you will lead the design and implementation of data solutions to enable our internal and external-facing engineering teams effectively leverage its data, better automate its processes, and monitor and react to its models‚Äô outputs.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eSome challenges you‚Äôll tackle\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eConnecting and aggregating various data sources into data warehouses\u003c/li\u003e\u003cli\u003eCreating pipelines and data stores for specific use cases\u003c/li\u003e\u003cli\u003eEvidence Search and Advanced Search\u003c/li\u003e\u003cli\u003eMachine Learning Active Learning\u003c/li\u003e\u003cli\u003eMachine Learning Quality Monitoring\u003c/li\u003e\u003cli\u003eAggregating Company Operational Metrics\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAbout You\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eExperience with¬†\u003c/li\u003e\u003cli\u003eData Storage (e.g. RDBMS, RedShift, Druid, Elastic, HDFS, Hudi, InfluxDB, Cassandra, Neo4j)\u003c/li\u003e\u003cli\u003eStream Processing (e.g. Kinesis, Kafka, Storm, Flink, Spark)\u003c/li\u003e\u003cli\u003eTask Schedulers (e.g. Airflow, Prefect, Luigi)\u003c/li\u003e\u003cli\u003eMonitoring (e.g. Grafana, Prometheus)\u003c/li\u003e\u003cli\u003eExperience is Data Engineering AWS services\u003c/li\u003e\u003cli\u003eBasic git knowledge\u003c/li\u003e\u003cli\u003eAble to take on complex problems, learn quickly, iterate, and persist towards a good solution\u003c/li\u003e\u003cli\u003eEffectively communicate, at the level of your audience, and seek to understand and be understood\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy join the Flock?¬†\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eWhen you join the Flock, you are joining a diverse team of passionate, ambitious, intelligent people that put the team over self. We offer competitive salary, benefits, and the opportunity to grow your career at a fast-paced, high growth start up. We genuinely care about the well-being of our employees both in and out of the office and understand the importance of work/life balance. We‚Äôd love for you to join us in the fight to eliminate non-violent crime, one neighborhood at a time.\u003c/p\u003e","id":16453,"location":"Worldwide","location_type":"remote","position":"Data Engineer","published_at":"2022-01-26T15:52:17Z","slug":"2ol4g0m97m-data-engineer","status":"approved","tags":["Airflow","AWS","Cassandra","Engineering"],"type":"fulltime"},{"application_url_or_email":"https://boards.greenhouse.io/paddle/jobs/5816986002?gh_jid=5816986002\u0026ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"dataengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/ky7mcc3xto.webp","company_name":"Paddle","company_slug":"paddle","company_twitter":"PaddleHQ","description":"\u003ch3\u003e\u003cstrong\u003eWhat do we do?\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eAs the SaaS space expands, there‚Äôs more potential than ever for growing software companies.¬†¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eHaving a great product is only part of the journey. B2B SaaS companies today face endless competition, live or die by customer acquisition costs, have to earn customer loyalty every day, need to operate across borders, and must navigate increasingly complex regulations.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eOur all-in-one platform is purpose-built for modern SaaS execution and already powers growth for over 2000 software companies, globally. Our Revenue Delivery Platform integrates checkout, payment, and subscription management, making it easy for businesses to activate new business models, enter new markets, turn on new offerings, and renew subscriptions without friction and we handle compliance globally, so our Sellers always operate with full integrity.¬†¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003e\u003cstrong\u003eThe role:¬†¬†\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eReporting into the Data Engineering Team Lead, you will be responsible for the delivery of technical solutions to implement Paddle‚Äôs data systems. You will collaborate with the wider engineering team and support analysts decentralized across the organization.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat you'll do:¬†\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eLeverage your experience and skills to establish the best architecture.\u003c/li\u003e\u003cli\u003eWork closely with decentralized analysts (Commercial, Finance, etc.) to identify requirements and develop the necessary data solutions to deliver against those requirements.\u003c/li\u003e\u003cli\u003eBuild, maintain and run efficient data pipelines.\u003c/li\u003e\u003cli\u003eApply data transformation logic including advanced aggregations and data wrangling techniques.\u003c/li\u003e\u003cli\u003ePractise DevOps, you‚Äôre responsible for getting your code to production and maintaining it.\u003c/li\u003e\u003cli\u003eExplore and use the right tools for the job, backing your choices constructively.\u003c/li\u003e\u003cli\u003eHelp design a stable platform to support phenomenal growth.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003e\u003cstrong\u003eWe'd love to hear from you if you are:¬†\u003c/strong\u003e\u003c/h3\u003e\u003cul\u003e\u003cli\u003eYou are a skilled Data or Software Engineer with significant proven experience working in a fast paced growing company and with a passion for Data.\u003c/li\u003e\u003cli\u003eSolid development background with Python.\u003c/li\u003e\u003cli\u003eGood experience working with IaC tools (we use Terraform).\u003c/li\u003e\u003cli\u003eExperienced leading data engineering projects in a high velocity product driven environment\u003c/li\u003e\u003cli\u003eYou champion designing and building systems to handle high traffic at scale in a cloud-based environment in AWS. Experience with Jenkins, Kibana, Grafana \u0026amp; Prometheus highly desirable.\u003c/li\u003e\u003cli\u003eGood understanding of data modelling. Experience with Redshift and/or Snowflake is a plus.\u003c/li\u003e\u003cli\u003eExperience with batch processing frameworks,\u003cstrong\u003e preferably familiarity with DBT\u003c/strong\u003e, Apache Airflow, or similar a plus.\u003c/li\u003e\u003cli\u003eExperience with Fivetran, Matillion, Stitch, or similar (we use Fivetran) a plus.\u003c/li\u003e\u003cli\u003eExperience with message brokers and stream processing technologies e.g. Kinesis\u003c/li\u003e\u003cli\u003eFamiliarity with BI tools such as Looker, Tableau, Sisense or similar\u003c/li\u003e\u003cli\u003eStrong attention to detail to highlight and address data quality issues\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003e\u003cstrong\u003eWhy you‚Äôll love working at Paddle\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eWe are a diverse team of 200 and growing people. We care deeply about enabling a great culture which is inclusive no matter your background. We celebrate our diverse group of talented employees and we pride ourselves on our transparent, collaborative, friendly and respectful culture.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWe live and breathe our values, which are:\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eExceptional Together\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eSolve for the Customer\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eExecute with impact\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eBetter than Yesterday\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWe offer a full suite of benefits, including attractive salaries, stock options, pension plans, private healthcare, a health \u0026amp; wellbeing platform and coaching sessions.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWe are a ‚Äòdigital-first‚Äô company, which means \u003cstrong\u003eyou can work remotely or from our amazing office\u003c/strong\u003e if you prefer, or even a bit of both! We offer all team members unlimited holidays. We love our casual dress code, annual company retreats and much more. We truly invest in learning and will help you with your personal development, from constant exposure to new challenges, an annual learning stipend to regular internal and external training.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003e\u003cstrong\u003eOur Mission\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eOur mission is to help software companies succeed ‚Äî enabling them to focus on creating products the world loves. Hundreds of companies rely on our e-commerce platform to sell their software products globally, as well as our powerful analytics and marketing tools to understand and grow their businesses.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eOur vision is to become the platform that all software companies use to run and grow their business. We aim to replace a fragmented ecosystem of specialised tools with a unified platform that removes the complex burden that comes with running a software business, whilst also providing unparalleled insight to help them grow faster.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eDeloitte Fast 50 named us amongst the fastest growing software companies in the UK four years running, and we‚Äôve raised over $93m in funding from incredible investors such as FTV Capital, Kindred, Notion, and 83North.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003e\u003cstrong\u003eEqual opportunities\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eWe believe in having diverse teams in which everyone can be their authentic self is key to our success. We encourage people from underrepresented backgrounds to apply and we don't discriminate based on race, colour, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, marital status, disability or age. ‚ÄãOur office is wheelchair friendly and we are a family-friendly employer‚Äã.\u003c/p\u003e","id":16450,"location":"London or Remote","location_type":"flexible","position":"Staff Data Engineer","published_at":"2022-01-26T15:53:47Z","slug":"ky7mcc3xto-staff-data-engineer","status":"approved","tags":["Airflow","AWS","Data pipelines","Engineering"],"type":"fulltime"},{"application_url_or_email":"https://boards.greenhouse.io/jasper/jobs/5855655002?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"softwareengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/ioxpumdpes.webp","company_name":"Jasper","company_slug":"jasper","company_twitter":"jasperhealthinc","description":"\u003cp\u003e\u003ca href=\"https://www.hellojasper.com/\"\u003eJasper Health\u003c/a\u003e is a fast-paced company with a noble mission to provide a digital experience to improve the lives of cancer patients and their caregivers throughout their treatment and remission journeys.¬†The company announced its¬†\u003ca href=\"https://www.businesswire.com/news/home/20210512005663/en/Jasper-Health-Launches-Comprehensive-Support-Platform-for-Individuals-With-Cancer-and-Their-Caregivers\"\u003eofficial launch\u003c/a\u003e¬†and was covered by high impact media outlets including¬†\u003ca href=\"https://www.usatoday.com/story/tech/2021/05/12/cancer-care-website-managing-chemo-side-effects-caregivers/5037814001/\"\u003eUSA Today\u003c/a\u003e, and \u003ca href=\"https://hitconsultant.net/2021/05/12/jasper-health-cancer-care-platform-launch/#.YKQk0JNKg3g\"\u003eHIT Consultant\u003c/a\u003e. A few months later, Jasper announced its first large-scale client with \u003ca href=\"https://www.prnewswire.com/news-releases/employer-direct-healthcare-and-jasper-health-to-partner-on-groundbreaking-oncology-solution-301376300.html\"\u003eEmployer Direct Healthcare\u003c/a\u003e which covers over 2MM lives across hundreds of employers.¬†Jasper Health is funded and supported by¬†\u003ca href=\"https://redesignhealth.com/\"\u003eRedesign Health\u003c/a\u003e, with a recent round of funding led by¬†\u003ca href=\"https://www.7wireventures.com/\"\u003e7wire Ventures\u003c/a\u003e, known for such digital health stand outs as Livongo, which merged in an $18.5 billion transaction with Teladoc late last year.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWe are currently focused on the 100M+ patients living with cancer, as well as their loved ones who provide care and support throughout treatment and recovery.¬†38% of people will be diagnosed with cancer in their lifetime, yet no one plans for it. Of those, 65% don‚Äôt know what to expect, leading them to feel overwhelmed and out of control‚Äîultimately affecting both their quality of care and quality of life.\u003c/p\u003e\u003cp\u003e¬†\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat We‚Äôre Building\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eIn late 2020 we launched our first product, the Jasper Smart Planner which enables patients to organize their care and track daily symptoms and side effects. This year, we followed these initial features with medication tracking, biometric tracking (including a Fitbit integration), a tailored content library, and we recently launched Recommendations‚Äîproviding patients with personalized suggestions for clinical and care-based actions. We are seeing incredibly strong early traction with both consumers and the B2B marketplace, and Jasper recently passed 11,000 registered members.\u003c/p\u003e\u003cp\u003e¬†\u003c/p\u003e\u003cp\u003eReporting to the Chief Data Scientist, the Sr. Data Architect is responsible for the strategic direction and leadership for the overall data operations, which includes architecting and building the Jasper Data Warehouse, ETL processes and framework and the BI environment. This role is to effectively and efficiently manage the architecture of Jasper‚Äôs data operations to enable Jasper to deliver data driven experiences for our members. As the personalized data driven experiences increase, so too will the enrollment into and engagement with Jasper increase. This crucial role allows Jasper to fulfill the mission of helping and improving the lives of cancer patients and their loved ones.\u003c/p\u003e\u003cp\u003e¬†\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eRole and Responsibilities\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eUnderstand the data needs of stakeholders across the business\u003c/li\u003e\u003cli\u003eResponsible for the design of scalable \u0026amp; fault tolerant data applications on Cloud Platforms to store \u0026amp; process terabytes of data from upstream sources with high availability\u003c/li\u003e\u003cli\u003ePartner with information architects, platform architects, data scientists and product management on solution requirements to design solutions\u003c/li\u003e\u003cli\u003eWork with the quantitative teams to understand data requirements\u003c/li\u003e\u003cli\u003eDesign solutions that enable the efficient and reliable extraction of insight from all captured healthcare, device and behavior data\u003c/li\u003e\u003cli\u003eDesign processes that ingest, transform, enrich and store a combination of structured (healthcare data, EHR, PROs, Device etc.) and unstructured data (e.g. Notes, Radiology Images etc.), guaranteeing data quality and availability\u003c/li\u003e\u003cli\u003eContinuously evaluate external data sources to make sure that we have the most accurate data available, backfilling historically when required\u003c/li\u003e\u003cli\u003eParticipate in product design, implementation, and quality assurance\u003c/li\u003e\u003cli\u003eRecommend improvements to the process both in terms of data collection, data consumption and storage\u003c/li\u003e\u003cli\u003eResolve high impact problems/projects through in-depth evaluation of complex business processes, system processes, enterprise standards \u0026amp; procedures\u003c/li\u003e\u003cli\u003eEnforce data management standards and procedures\u003c/li\u003e\u003cli\u003eResponsible for design, testing oversight and production implementation using BigQuery, Pub/Sub, Data Catalog, DataFlow and GCP\u003c/li\u003e\u003cli\u003ePartner with multiple teams to ensure appropriate data solutions to meet goals as well as identify and define necessary system and process enhancements\u003c/li\u003e\u003cli\u003eConduct personnel duties for direct reports (e.g. mentorship, performance evaluations or hiring)\u003c/li\u003e\u003cli\u003eOversee data engineering agile teams to deliver against sprint and program increment objectives\u003c/li\u003e\u003cli\u003eEngage in business partner engagement; management of relationship and inter-group planning among technology leadership/peers\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e¬†\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eCore Competencies \u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eMust have prior experience as a Data Warehouse, BI and ETL Technical Architect\u003c/li\u003e\u003cli\u003eStrong experience and deep understanding of ETL, data warehousing, data lake technologies and analytics concepts\u003c/li\u003e\u003cli\u003eExperience owning multiple mission critical applications on big data platform\u003c/li\u003e\u003cli\u003eExperience with batch and real-time data pipelines in a DevOps environment\u003c/li\u003e\u003cli\u003eWilling to work in a fast-paced environment with globally located Agile teams working in different shifts\u003c/li\u003e\u003cli\u003eAbility to develop and maintain strong collaborative relationships at all levels across Business Stakeholders\u003c/li\u003e\u003cli\u003eExcellent written and oral communication skills\u003c/li\u003e\u003cli\u003eAdept and presenting complex topics, influencing and executing with timely / actionable follow-through\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e¬†\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eQualifications and Education Requirements\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eProven track record of design of an analytical environment\u003c/li\u003e\u003cli\u003eMust have a bachelor's degree in Computer Science, Engineering, or a related field\u003c/li\u003e\u003cli\u003e4+ years of experience in a related field or role\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e¬†\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eKnowledge, Skills and Abilities Required\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003ePrior work experience in healthcare\u003c/li\u003e\u003cli\u003eExperience working with payer claims data\u003c/li\u003e\u003cli\u003eExperience working with provider EHR data\u003c/li\u003e\u003cli\u003eExperience building environments for or working with data-driven statistical models\u003c/li\u003e\u003cli\u003eExperience dealing with sensitive data in a highly regulated environment\u003c/li\u003e\u003cli\u003eDemonstrated implementation of complex and innovative solutions\u003c/li\u003e\u003cli\u003eArticles and publications in the field of data engineering\u003c/li\u003e\u003cli\u003eBe the captain of the team, lead by example, motivate, and work together as a team\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e¬†\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eBenefits Includes\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003ePaid Time Off (PTO)\u003c/li\u003e\u003cli\u003eHealth, Dental, \u0026amp; Vision Insurance\u003c/li\u003e\u003cli\u003eFlexible Spending Accounts\u003c/li\u003e\u003cli\u003eEmployee Assistance Program\u003c/li\u003e\u003cli\u003eAnd more...\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e¬†\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eConditions of Employment\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eYou must be authorized to work in the United States\u003c/li\u003e\u003cli\u003eApplicants will be required to pass a background check as a condition of employment\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e¬†\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eEqual Employment Opportunity Policy\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eJasper Health, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eThis policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.\u003c/p\u003e","id":16445,"location":"Worldwide","location_type":"remote","position":"Sr. Data Architect","published_at":"2022-01-26T15:49:03Z","slug":"ioxpumdpes-sr-data-architect","status":"approved","tags":["Big Data","BigQuery","Dataflow","Data pipelines"],"type":"fulltime"},{"application_url_or_email":"https://boards.greenhouse.io/glooko/jobs/3848717?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"softwareengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/mvu6rpdqac.webp","company_name":"Glooko","company_slug":"glooko","company_twitter":"diasend","description":"\u003cp\u003e\u003cstrong\u003eAbout the Role:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eMentor a team of engineers to design and develop Data¬†platform.\u003c/li\u003e\u003cli\u003eDesign and implement data platform architecture, data ingestion pipelines and data infrastructure.\u003c/li\u003e\u003cli\u003eCollaborate with product management and data engineering leadership to understand the requirements and design new products or extensions to existing products.\u003c/li\u003e\u003cli\u003eProvide technical oversight to the development process including code reviews and mentoring of the technical team.\u003c/li\u003e\u003cli\u003eCollaborate with engineering, data scientist,¬†cloud infrastructure¬†and security teams to understand the requirements and develop highly scalable system design and architecture.\u003c/li\u003e\u003cli\u003eDefine goals and metrics for the team and establish a process for regular assessment and improvement.\u003c/li\u003e\u003cli\u003eCommunicate effectively the status, risks and mitigation strategies to the leadership team.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e¬†\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAbout You:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eBachelor or Master Degree in Computer Science, Math, or Engineering.\u003c/li\u003e\u003cli\u003e10+ years of working experience in software development.\u003c/li\u003e\u003cli\u003e5+ years experience in designing and developing REST APIs and/or web applications.\u003c/li\u003e\u003cli\u003eExperience with development of large-scale distributed Web services Infrastructure and Microservices.\u003c/li\u003e\u003cli\u003eExperience with real-time data processing systems (e.g. Spark,, Storm, Kafka, Flink).\u003c/li\u003e\u003cli\u003eExperience with modern data platforms such as Snowflake, Spark, Hive, and Pig.\u003c/li\u003e\u003cli\u003eExperience with a variety of data stores such as¬†MongoDB, Cassandra, HBase, MySQL.\u003c/li\u003e\u003cli\u003eExperience with AWS environment e.g., Amazon Kinesis, Lamdba, DynamoDB and Redshift.\u003c/li\u003e\u003cli\u003eExperience with programming languages such as Java \u0026amp; Python.\u003c/li\u003e\u003cli\u003eExperience managing globally distributed teams.\u003c/li\u003e\u003cli\u003eExperience building multi-tenant SaaS applications\u003c/li\u003e\u003cli\u003eExperience with development of large-scale distributed Web services Infrastructure\u003c/li\u003e\u003cli\u003eExperience with development of data Infrastructure\u003c/li\u003e\u003cli\u003eExperience with containerization platforms (Docker) and container orchestration tools\u003c/li\u003e\u003cli\u003eExperience with Microservices Architectures, AWS and Lambda functions\u003c/li\u003e\u003cli\u003eHave demonstrated ability to mentor other software developers to maintain software quality and adopt right architectural principles.\u003c/li\u003e\u003cli\u003eHave a deep understanding of functional and design patterns with a focus on performance, security and scalability\u003c/li\u003e\u003cli\u003eHave experience and knowledge of Scrum and Agile tools. JIRA and Atlassian tools experience is a Plus.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e¬†\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAbout Glooko:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eThere are over 420 million people in the world with diabetes and Glooko helps those people, as well as their physicians and care team, manage the disease more easily and cost effectively. Glooko is the Unified Platform for Diabetes Management providing an FDA cleared, HIPAA compliant Web and Mobile (iOS and Android) application for people with diabetes and the clinicians who treat them. Glooko‚Äôs products seamlessly unifies data from over 200 of the leading blood glucose meters, insulin pumps, continuous glucose monitors, activity trackers, and biometric devices to deliver insights that improve personal and clinical decision support.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eGlooko‚Äôs mobile app and web dashboard enable patients to easily track and proactively manage all aspects of their diabetes care. Glooko‚Äôs Population Tracker and APIs offer diabetes-centric analytics and supply insightful reports, graphs and pattern-triggered notifications to patients, health systems, and payers. The Glooko platform also allows customers and third-party developers to create branded modules for Glooko users. The most recently created business unit is Glooko Research, which offers a clinical research platform for pharmaceutical companies, CROs, medical devices companies and other players within the industry.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eLaunched in 2010, Glooko is funded and managed by visionary technologists and leaders in healthcare.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eGlooko's Perks and Benefits Include:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eCompetitive salary based on experience\u003c/li\u003e\u003cli\u003ePre-IPO stock incentives\u003c/li\u003e\u003cli\u003eFull benefits: medical, dental, vision, and transportation incentives\u003c/li\u003e\u003cli\u003e401(k) matching program\u003c/li\u003e\u003cli\u003eHardware to get the job done\u003c/li\u003e\u003cli\u003eInternet/cell phone reimbursement\u003c/li\u003e\u003cli\u003eAnnual reimbursement for our¬†Employee Well-Being stipend¬†which encourages employees to¬†invest¬†in any combination of fitness equipment/fitness activities or home office/ergonomics related items\u003c/li\u003e\u003cli\u003eGenerous annual reimbursement for our Glooko Professional Development Program\u003c/li\u003e\u003cli\u003eHave a meaningful impact on people‚Äôs lives\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e¬†\u003c/p\u003e\u003cp\u003eGlooko provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, marital status, or disability. In addition to federal law requirements, Glooko complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003ePosted positions are not open to third party recruiters/agencies and unsolicited resume submissions will be considered free referrals.\u003c/p\u003e","id":16432,"location":"USA","location_type":"remote","position":"Software Architect (Data Engineering)","published_at":"2022-01-26T15:47:23Z","slug":"mvu6rpdqac-software-architect-data-engineering","status":"approved","tags":["AWS","Cassandra","Engineering","Healthcare"],"type":"fulltime"},{"application_url_or_email":"https://boards.greenhouse.io/beat/jobs/3832985?gh_jid=3832985\u0026ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"machinelearning","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/6buhpdbybz.webp","company_name":"Beat","company_slug":"beat","company_twitter":"thebeatapp","description":"\u003cp\u003e\u003cstrong\u003eAbout us\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eBeat is the fastest growing ride hailing app in Latin America and a part of the international FreeNow Group, the multi-service mobility joint venture backed by BMW Group and Daimler AG. One city at a time, we are on a mission to develop seamless mobility for a safe and sustainable urban life. We are proud to say we have launched Beat Tesla / Loonshot, the first and largest private all-electric vehicle service in Latin America.¬†\u003c/p\u003e\u003cp\u003eAs an organization, we are committed to our drivers with ethical practices and a safe working environment. To our customers, we differentiate ourselves from other ride-hailing apps with our super user-friendly app and excellent customer service. Last but not least, our priority is to maintain a hyperlocal approach in everything we do, from product to operations to marketing.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWe are proud to see Beat leading the FreeNow group in growth in 2021 and we have ambitious plans for 2022. But we need you to help us get closer to our vision: ‚Äã‚Äãa connected Latin America where the only question is ‚ÄúWhere Next?‚Äù\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWe are currently operating in Mexico, Argentina, Chile, Colombia, Peru and Greece and are transporting over 24 million riders with the support of more than 700,000 drivers. Our global headquarters are in Athens - where BEAT started back in 2011. We also have offices in Amsterdam.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eOur employee base is spread out even wider. We mastered the hybrid workspace with our office and remote locations even before Covid-19. So if you are interested in joining us on our mission, whether based in one of the countries we operate or elsewhere in the world, we are happy to hear from you!\u003c/p\u003e\u003cp\u003e¬†\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAbout the role\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eWe‚Äôre looking for a Senior Machine Learning Engineer to join the Machine Learning team within the Matching Domain.\u003c/p\u003e\u003cp\u003eThe domain has all necessary crafts to allow us to achieve our goals autonomously and consists of a Product team (Product Managers, Data Analysts and Designers) and Engineering (Backend, Frontend, Data and ML). The domain has the following areas of responsibility:\u003c/p\u003e\u003cul\u003e\u003cli\u003eDispatch, orchestrating the whole matching workflow between passenger and drivers\u003c/li\u003e\u003cli\u003eMatching, trying to find the optimal driver for a passenger\u003c/li\u003e\u003cli\u003eMapping, providing map-related services to all domains in the company\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eOur teams work in a virtual office setup, with overlapping hours and a mixture of sync and async communication methods. You‚Äôll be reporting to the ML team‚Äôs Engineering Manager.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat‚Äôs the day to day\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eThe ML team is working across all projects within Matching Domain. We are responsible for intelligently matching drivers to users' ride requests using driver and passenger behaviour modelling. We also estimate the total duration of rides using ML models and we apply data-driven insights and heuristics to optimally configure the Matching‚Äôs flow parameters. We are concerned with the whole lifecycle of the development of a ML/DS product as our work starts with formalizing the business requirements and follows all appropriate steps until a well performing, ML-powered solution gets into BEAT‚Äôs production flow.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eOur marketplace team work on matching drivers with passengers, focusing on the best optimisation of this, so the main challenge is the balance of dynamic pricing to keep the drivers earnings optimised and the passengers fair lower.¬†\u003c/p\u003e\u003cp\u003eIf you can help us solve these challenges, we want to hear from you!¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat you will do¬†\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eWork within a cross-functional team, highly skilled in data science, machine learning, software engineering and data engineering.\u003c/li\u003e\u003cli\u003eUnderstand product requirements and formulate suitable ML-based POCs to satisfy them.\u003c/li\u003e\u003cli\u003eConvert successful POCs to fully-fledged ML-based product features and put them in BEAT‚Äôs production flow in collaboration with Matching‚Äôs domain‚Äôs backend teams.¬†¬†\u003c/li\u003e\u003cli\u003eEvaluate ML features/models both offline and online through AB tests and online performance monitoring.\u003c/li\u003e\u003cli\u003eMaintain and improve the performance of existing solutions.¬†\u003c/li\u003e\u003cli\u003eTake full ownership of your work, being able to lead and mentor junior to mid level teammates.\u003c/li\u003e\u003cli\u003eBe part of BEAT‚Äôs ML Chapter, a community of ML engineers across the company, formed with the purpose of knowledge sharing across different teams.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e¬†\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat you need to bring¬†\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eMaster's degree in Computer Science or in a related STEM field. Higher degrees are highly appreciated.\u003c/li\u003e\u003cli\u003eSolid understanding of methods, concepts, models, evaluation schemes across the whole DS/ML landscape, eg. supervised learning, unsupervised learning, data mining etc.\u003c/li\u003e\u003cli\u003eSolid coding experience in Python.\u003c/li\u003e\u003cli\u003eSolid experience in working the full software development lifecycle using the industry‚Äôs best practices.¬†\u003c/li\u003e\u003cli\u003eKnowledge of SQL and relational databases.¬†\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch4\u003e\u003cstrong\u003eWhat is useful to have:\u003c/strong\u003e\u003c/h4\u003e\u003cul\u003e\u003cli\u003eHands-on experience with MLOPs frameworks such as Kubeflow, MLFlow, (Azure ML Studio) or Amazon Sagemaker.\u003c/li\u003e\u003cli\u003eHands-on experience with Apache Spark.\u003c/li\u003e\u003cli\u003eHands-on experience with Docker and Kubernetes.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAbout the interview process at BEAT\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eDuring our interview process, we want to learn about you but also provide you with a good understanding of what it‚Äôs like to work at Beat. We will introduce you to several team members and stakeholders to make sure you can ask all your questions.\u003c/p\u003e\u003cp\u003eHere is what you can expect:\u003c/p\u003e\u003cul\u003e\u003cli\u003eAn initial conversation with a member of the Talent Acquisition team\u003c/li\u003e\u003cli\u003eAn introductory meeting with your potential future manager\u003c/li\u003e\u003cli\u003eFor tech roles, there is a take home assignment that you will need to submit by the agreed deadline\u003c/li\u003e\u003cli\u003eThe last stage of the interview process will be meetings with the team and internal stakeholders.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThroughout the process, our Candidate Experience team will be there to support you and ensure that you have a great time interviewing with us.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e¬†What's in it for you:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eCompetitive full-time salary\u003c/li\u003e\u003cli\u003eFlexible working hours, top Line tools\u003c/li\u003e\u003cli\u003eWorking in a hyper-growth environment, you will enjoy numerous learning and career development opportunities¬†\u003c/li\u003e\u003cli\u003eA great opportunity to grow and work with the most amazing people in the industry\u003c/li\u003e\u003cli\u003eBeing part of an environment that offers challenging goals, autonomy and mentoring, which creates incredible opportunities, both for you and the company.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eAs part of our dedication to the diversity of our workforce, Beat is committed to Equal Employment Opportunity without regard for race, colour, national origin, ethnicity, gender, disability, sexual orientation, gender identity, or religion.\u003c/p\u003e","id":16248,"location":"Worldwide","location_type":"remote","position":"Senior Machine Learning Engineer","published_at":"2022-01-23T21:24:51Z","slug":"6buhpdbybz-senior-machine-learning-engineer","status":"approved","tags":["Matching","Azure","Data Mining","Kubernetes"],"type":"fulltime"},{"application_url_or_email":"https://boards.greenhouse.io/appdirect/jobs/5844384002?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"dataengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/koiidhcdzb.webp","company_name":"AppDirect","company_slug":"appdirect","company_twitter":"AppDirect","description":"\u003cp\u003e\u003cstrong\u003eAbout AppDirect\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eBecome a digital, global citizen and enable the new generation of digital entrepreneurs around the world. AppDirect offers a subscription commerce platform to sell any product, through any channel, on any device - as a service. We power millions of subscriptions worldwide for organizations. We do this by our values-driven culture - one that enables you to Be Seen, Be Yourself, and Do Your Best Work.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAbout You\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eAs a Data Engineering Team lead, you‚Äôre a highly technical, hands-on and experienced developer with the ability to manage and lead a small team. You will play a pivotal role in designing, architecting and overseeing the development of critical services while coaching and mentoring a group of developers. You are responsible for driving the vision and roadmap of the team while collaborating with other parts of the organization and cross-functioning teams.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat You‚Äôll Do and How You‚Äôll Make an Impact\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eLead, support and mentor a team made up of Data Engineers. You will own performance management for your team (i.e. objectives setting, performance reviews and career development) as well as recruitment and overall team management.\u003c/li\u003e\u003cli\u003eTechnically coach engineers by reviewing technical designs and code as well as through technical talks .\u003c/li\u003e\u003cli\u003ePartner with the Product Manager, Designer, and other Engineering Managers and Tech Leads to collaborate and build awesome reporting experience.\u003c/li\u003e\u003cli\u003eLead efforts enabling the team and our Cloud Data Pipelines to scale\u003c/li\u003e\u003cli\u003eCoach members of the team about industry-leading tools and techniques\u003c/li\u003e\u003cli\u003eModernize our Cloud Data Pipeline strategy to enable the business, engineers and customers\u003c/li\u003e\u003cli\u003eCollaborate with our reporting team to build insightful dashboards\u003c/li\u003e\u003cli\u003eWork with Engineering and Architecture teams to develop new organizational standards\u003c/li\u003e\u003cli\u003eMigrate current batch ETL to new streaming data pipelines\u003c/li\u003e\u003cli\u003eImprove efficiency by enabling internal stakeholders with self-served data solutions\u003c/li\u003e\u003cli\u003eResearch solutions to complex problems and drive proof-of-concepts\u003c/li\u003e\u003cli\u003eAuthor and maintain knowledge base through high-quality documentation\u003c/li\u003e\u003cli\u003eDeliver quality solutions/process through CICD and automation\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat You‚Äôll Need\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eYou are a technical leader with a real passion for development and with a strong product sense.\u003c/li\u003e\u003cli\u003eExperience with developing in modern programming language (e.g., Scala, Java, SQL, Python.\u003c/li\u003e\u003cli\u003eExposure to some of the following technologies: Apache Spark \u0026amp; Flink, AWS \u0026amp; Azure, Docker \u0026amp; Kubernetes, CDC\u003c/li\u003e\u003cli\u003eUnderstanding of Data Schemas (e.g. SQL, JSON, Avro, Protobuf)\u003c/li\u003e\u003cli\u003eExperience automating, producing and consuming data in real time from event driven microservices using streaming platforms like Kafka\u003c/li\u003e\u003cli\u003eProven experience building data pipelines and data solutions aligned to Business Architecture, operational and analytics use cases.\u003c/li\u003e\u003cli\u003eGood knowledge and understanding of data structures and experience handling large data sets\u003c/li\u003e\u003cli\u003eComfortable in code reviewing other engineers' code and driving/reviewing technical designs..\u003c/li\u003e\u003cli\u003eAbility to self-manage, think critically, handle multiple tasks and/or projects and deliver solutions autonomously\u003c/li\u003e\u003cli\u003eAbility to clearly communicate complex ideas to a technical and non-technical audience\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e¬†\u003c/p\u003e\u003cp\u003eAt AppDirect/AppSmart, we believe that innovation thrives in an environment that houses diversity of excellence, experience and thought. We respect each AppDirector as their own fingerprint; unique with no one alike. We foster an environment of inclusion without regard to race, religion, age, sexual orientation, or gender identity enabling AppDirectors to embrace their uniqueness to do their best work. As such, we strongly encourage applications from Indigenous peoples, racialized people, people with disabilities, people from gender and sexually diverse communities, and/or people with intersectional identities.\u003c/p\u003e","id":16237,"location":"Canada","location_type":"remote","position":"Data Engineering Team Lead","published_at":"2022-01-23T21:23:00Z","slug":"koiidhcdzb-data-engineering-team-lead","status":"approved","tags":["Avro","AWS","Azure","Data pipelines"],"type":"fulltime"},{"application_url_or_email":"https://boards.greenhouse.io/life360/jobs/5667321002?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"dataengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/dbkesybeg4.webp","company_name":"Life360","company_slug":"life360","company_twitter":"Life360","description":"\u003cp\u003e\u003cstrong\u003eLife360 is a Remote First company, which means a remote work environment will be the primary experience for all employees. All positions, unless otherwise specified, can be performed remotely (within the US) regardless of any specified location above.¬†\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eAbout Life360\u003c/h3\u003e\u003cp\u003eLife360 is on a mission to bring families closer‚Äî and that starts with ensuring that loved ones are safe and secure. That‚Äôs why millions of families across 140 countries trust Life360 to keep them connected each day, and in life‚Äôs unpredictable moments.\u003c/p\u003e\u003cp\u003eFrom real-time location sharing and notifications, to driving safety features like Crash Detection and Roadside Assistance, we create tools that remove uncertainty from modern life ‚Äî so families can feel free, together.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eAbout the Job\u003c/h3\u003e\u003cp\u003eLife360 collects and processes several hundred billion location points, over a hundred billion user events, and billions of miles driven on a monthly basis. As a Senior Data Engineer, you will contribute to enhancing and maintaining our data processing and storage pipelines/workflows for external and internal data consumers. You will be a key member of our Data Partnerships team responsible for efficient and highly resilient, high-volume data pipelines. You should have a strong engineering and support background and, more importantly, a desire to take ownership of our data systems and drive to make them world-class.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eWhat You‚Äôll Do\u003c/h3\u003e\u003cul\u003e\u003cli\u003eDesign and develop resilient data processing pipelines using a variety of open-source technologies.\u003c/li\u003e\u003cli\u003eManage data from ingestion through transformation to delivery, in batch and near real-time.¬†\u003c/li\u003e\u003cli\u003eCoordinate onboarding of new data customers and support existing data customers.¬†\u003c/li\u003e\u003cli\u003eActively monitor the health of the data pipelines and identify opportunities to add or improve automation in data handling.¬†\u003c/li\u003e\u003cli\u003eSupport business customers as they look to answer data-oriented questions in support of business growth.¬†\u003c/li\u003e\u003cli\u003eTest, harden, and automate new and existing data workflows.¬†\u003c/li\u003e\u003cli\u003eParticipate in rotational on-call support and provide ongoing maintenance of the data infrastructure.¬†\u003c/li\u003e\u003cli\u003eBe a key member of a fast-growing data team handling massive scale through sophisticated processing and automation.¬†\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eWhat We‚Äôre Looking For\u003c/h3\u003e\u003cul\u003e\u003cli\u003eMinimum 4+ years of experience developing and supporting high volume data systems.¬†\u003c/li\u003e\u003cli\u003eExtensive programming experience: Python/Java preferred.¬†\u003c/li\u003e\u003cli\u003eExperience in data modeling, writing optimized SQL, and system performance tuning.¬†\u003c/li\u003e\u003cli\u003eKnowledge and proficiency in the latest open-source data frameworks.¬†\u003c/li\u003e\u003cli\u003eExperience with AWS-based data-related services.¬†\u003c/li\u003e\u003cli\u003eExperience evaluating industry trends and technologies.\u003c/li\u003e\u003cli\u003eContinuous learning to stay up to speed in the fast-moving big data world.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eOur Benefits\u003c/h3\u003e\u003cul\u003e\u003cli\u003eCompetitive pay and benefits\u003c/li\u003e\u003cli\u003eMedical, dental, vision, life and disability insurance plans (100% paid for employees)\u003c/li\u003e\u003cli\u003e401(k) plan with company matching program\u003c/li\u003e\u003cli\u003eEmployee Assistance Program (EAP) for mental wellness.\u003c/li\u003e\u003cli\u003eFlexible PTO and 12 company wide days off throughout the year\u003c/li\u003e\u003cli\u003eLearning \u0026amp; Development programs\u003c/li\u003e\u003cli\u003eEquipment, tools, and reimbursement support for a productive remote environment\u003c/li\u003e\u003cli\u003eFree Life360 Platinum Membership for your preferred circle\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eLife360 Values\u003c/h3\u003e\u003cp\u003eOur company‚Äôs mission driven culture is guided by our shared values to create a trusted work environment where you can bring your authentic self to work and make a positive difference¬†\u003c/p\u003e\u003cul\u003e\u003cli\u003eBuild A High Performing Team ‚Äì Communicate Directly, Be a Good Person\u003c/li\u003e\u003cli\u003eMake Things Happen ‚Äì Take Ownership, Think Long Term\u003c/li\u003e\u003cli\u003eDeliver an Exceptional Experience ‚Äì Users Come First, Quality \u0026amp; Craftsmanship\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eOur Commitment to Diversity\u003c/h3\u003e\u003cp\u003eWe believe that different ideas, perspectives and backgrounds create a stronger and more creative work environment that delivers better results. Together, we continue to build an inclusive culture that encourages, supports, and celebrates the diverse voices of our employees. It fuels our innovation and connects us closer to our customers and the communities we serve. We strive to create a workplace that reflects the communities we serve and where everyone feels empowered to bring their authentic best selves to work.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eWe are an equal opportunity employer and value diversity at Life360. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status or any legally protected status.¬†¬†\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eWe encourage people of all backgrounds to apply. We believe that a diversity of perspectives and experiences create a foundation for the best ideas. Come join us in building something meaningful.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003e____________________________________________________________________________\u003c/em\u003e\u003c/p\u003e\u003cp\u003eSince the majority of our staff is located on the US West Coast, our primary working hours will be 9-4pm PST\u003c/p\u003e","id":16230,"location":"USA","location_type":"remote","position":"Senior Data Engineer, Data Partnerships","published_at":"2022-01-23T21:21:26Z","slug":"dbkesybeg4-senior-data-engineer-data-partnerships","status":"approved","tags":["AWS","Big Data","Data pipelines","Engineering"],"type":"fulltime"},{"application_url_or_email":"https://boards.greenhouse.io/celonis/jobs/4798902003?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"softwareengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/xcveig27jo.webp","company_name":"Celonis","company_slug":"celonis","company_twitter":"Celonis","description":"\u003cp\u003e\u003cstrong\u003eSenior Software Engineer (Machine Learning)\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eWelcome to Celonis, the global leading Process Mining software company and one of the world's fastest-growing SaaS firms. We believe that every company can unlock its full execution capacity and for that, we need you to join us as a Machine Learning Engineer.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eThe Team:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eFor our Applied Machine Learning Team we are looking for a Software Engineer with a Machine Learning focus, who will be part of a dynamic team that is responsible for the design and implementation of end-to end products for the currently existing and future ML pipelines/ products.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eThe Role:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eAlongside each member of the team you will be responsible for design and implementation of end-to end products. Furthermore, you will increase the software development ability within the team and ensure sustainable product life-cycles. In this role you will also have the opportunity to get involved with complex code reviews and architectural discussion with high level platform architects.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eRequirements:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eStrong engineering background with very good hands-on-experience of Python and exposure to one or more programming language (Java preferred), as well as engineering best practices (logging, monitoring and alerting)\u003c/li\u003e\u003cli\u003ePrevious experience in working with and developing Machine Learning products (to include Infrastructure, Models and Pipelines)\u003c/li\u003e\u003cli\u003eIndustry experience creating and productionising Machine Learning algorithms at scale\u003c/li\u003e\u003cli\u003eWorking knowledge of DevOps (Kubernetes and Docker key)¬†\u003c/li\u003e\u003cli\u003eHighly experienced in writing efficient, readable and testable code\u003c/li\u003e\u003cli\u003eA true problem solver and excellent team player\u003c/li\u003e\u003cli\u003eMSc / Masters in a relevant Computer Science topic\u003c/li\u003e\u003cli\u003eMust have excellent English skills, German is a plus¬†\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat Celonis can offer you:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe unique opportunity to work within a new category of technology, Execution\u003c/li\u003e\u003cli\u003eManagement\u003c/li\u003e\u003cli\u003eInvestment in your personal growth and skill development (clear career paths,\u003c/li\u003e\u003cli\u003einternal mobility opportunities, mentorships, yearly development stipend)\u003c/li\u003e\u003cli\u003eGreat compensation and benefits packages (stock options, 401(K) matching,\u003c/li\u003e\u003cli\u003egenerous time off, parental leave, and more)\u003c/li\u003e\u003cli\u003eWork from home support (mindfulness tools such as Headspace, monthly\u003c/li\u003e\u003cli\u003eremote working stipend, flexible working hours, virtual events and workshops)\u003c/li\u003e\u003cli\u003eA global and growing team of Celonauts from diverse backgrounds to learn\u003c/li\u003e\u003cli\u003efrom and work with\u003c/li\u003e\u003cli\u003eAn open-minded culture with innovative, autonomous teams\u003c/li\u003e\u003cli\u003eEmployee resource communities to help you feel connected, valued and seen (Women@Celonis, Parents@Celonis, Pride@Celonis, Resilience@Celonis, and more)\u003c/li\u003e\u003cli\u003eA clear set of company values that guide everything we do: Live for Customer\u003c/li\u003e\u003cli\u003eValue, The Best Team Wins, We Own It, and Earth Is Our Future\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAbout Us:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eCelonis believes that every company can unlock its full execution capacity. Powered by its market-leading process mining core, the Celonis Execution Management System provides a set of applications, and developer studio and platform capabilities for business executives and users to eliminate billions in corporate inefficiencies. Celonis has thousands of global customers and is headquartered in Munich, Germany and New York City, USA with 15 offices worldwide.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eCelonis is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.¬†\u003ca href=\"https://www.celonis.com/careers/diversity/\"\u003eDifferent makes us better\u003c/a\u003e.¬†\u003c/p\u003e","id":16223,"location":"Munich based OR remote in Germany","location_type":"flexible","position":"Senior Software Engineer (Machine Learning)","published_at":"2022-01-23T21:20:07Z","slug":"xcveig27jo-senior-software-engineer-machine-learning","status":"approved","tags":["Engineering","Java","Kubernetes","Machine Learning"],"type":"fulltime"},{"application_url_or_email":"https://boards.greenhouse.io/appannie/jobs/3854035?gh_jid=3854035\u0026ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"dataengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/llojfrughh.webp","company_name":"App Annie","company_slug":"app-annie","company_twitter":"appannie","description":"\u003cp\u003e\u003cstrong\u003eSomething about us...\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eApp Annie is the industry‚Äôs most trusted mobile data and analytics platform.\u003cstrong\u003e\u003cem\u003e Our mission is to help customers create winning mobile experiences and achieve excellence\u003c/em\u003e\u003c/strong\u003e. We created the mobile app data market and are committed to delivering the industry‚Äôs most complete mobile performance offering. More than 1,300 enterprise clients and 1 million registered users across the globe and spanning all industries rely on App Annie as the standard to revolutionize their mobile business. We are a global company, headquartered in San Francisco but as a ‚Äúremote‚Äù first company, we care about your results and not your location.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eAlong with a market defining product, we take great pride in our culture and values and strive to embody them daily! We set a high bar for our success and have made \u003cstrong\u003e\u003cem\u003eExcellence \u003c/em\u003e\u003c/strong\u003eas our standard, hold each other \u003cstrong\u003e\u003cem\u003eAccountable\u003c/em\u003e\u003c/strong\u003e, continuously push \u003cstrong\u003e\u003cem\u003eInnovation\u003c/em\u003e\u003c/strong\u003e and \u003cstrong\u003e\u003cem\u003eWin with Style\u003c/em\u003e\u003c/strong\u003e.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat can you tell your friends when they ask you what you do?\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eAs a Big Data Engineer, I‚Äôm a key contributor to the design, implementation and ongoing governance of App Annie‚Äôs data products. I‚Äôm responsible for expanding and optimizing our large-scale data ingestion flows and our data processing pipelines to create transparency and consistency across the entire Data Science system architecture. I work closely with Product Managers, Data Scientists, Data Analysts and other Big Data and Business Intelligence Engineers to develop and sustain the governance of our data products, including conceiving and building large-scale data integration solutions. I‚Äôm passionate about what I do and excited to do it in the context of an entrepreneurial start-¬≠up with a phenomenal team.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eYou will be responsible for and take pride in‚Ä¶.\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eAs a Big Data Engineer, you will be an integral part of a team responsible for large-scale data processing pipelines across our Intelligence Product. You will also help to expand our product governance processes and support the Data Science team in building new product features. This includes:\u003c/li\u003e\u003cli\u003eAbility to work with¬†large, complex data sets that meet function and non-functional business requirements\u003c/li\u003e\u003cli\u003eWorking as engineer in building the infrastructure required for optimal extraction, transformation and loading of data from a wide variety of data sources using SQL, Apache Spark,¬†AWS S3, Databricks, Snowflake\u003c/li\u003e\u003cli\u003eAbility to design and optimize queries, scripts and data tools to provide increased visibility into the Data Science system architecture\u003c/li\u003e\u003cli\u003eThe ability to communicate well and clearly with teams and team members across multiple time zones and countries.\u003c/li\u003e\u003cli\u003eDesigning,¬†building, and supporting large scale, fault-tolerant distributed systems that support App Annie‚Äôs data science and analytics teams\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eYou should recognize yourself in the following...\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eYou should be a strong tech lead with proven experience in distributed systems, and big data analysis.\u003c/li\u003e\u003cli\u003eBachelor‚Äôs degree in Computer Science / Engineering or equivalent experience\u003c/li\u003e\u003cli\u003eAt least 2-3 years in software development, with multiple examples of delivering innovative product ideas\u003c/li\u003e\u003cli\u003eDeep understanding of hardware and computer organization, Linux operating system, computer network and compilers etc.\u003c/li\u003e\u003cli\u003eSolid skills of big data related data structures and algorithms\u003c/li\u003e\u003cli\u003eProficient in data modeling and data warehouse design¬†\u003c/li\u003e\u003cli\u003eExperience in designing architecture is a big plus\u003c/li\u003e\u003cli\u003eProficient programming experience in SQL¬†\u003c/li\u003e\u003cli\u003eProficient programming experience in at least one mainstream language, like Python, Scala or Java¬†\u003c/li\u003e\u003cli\u003eExperienced in data processing such as ETL\u003c/li\u003e\u003cli\u003eFlexible mindset and the ability to prototype and change direction rapidly as research evolves\u003c/li\u003e\u003cli\u003eStrong problem solving, analytical and troubleshooting skills\u003c/li\u003e\u003cli\u003eA seasoned engineer with big data ecosystem (Computation: Mapreduce, Spark/Flink, Presto/Hive/Redshift/Snowflake etc.; Storage: Postgresql, Elasticsearch, HDFS, Kafka etc.), experience AWS/Google Cloud/Microsoft Azure is a big plus\u003c/li\u003e\u003cli\u003eAn excellent communicator with a knack for concisely explaining problems and solutions to multiple stakeholders, e.g. product managers, senior management, etc.\u003c/li\u003e\u003cli\u003eA strong drive to continue learning and developing\u003c/li\u003e\u003cli\u003eIndependently making decisions quickly based on your expertise¬†\u003c/li\u003e\u003cli\u003eDemonstrated ability to produce results as part of a highly distributed team that crosses cultural and country boundaries\u003c/li\u003e\u003cli\u003eEnergy and creativity are key characteristics that describe you and the projects you are involved in. You make it happen. Boom!\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eThis is what we offer...\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eWe provide a $1,000 reimbursable WFH allowance to set you up for remote work success.\u003c/li\u003e\u003cli\u003eInternet allowance for stable internet connection, so your video does not freeze on Zoom.¬†\u003c/li\u003e\u003cli\u003eFlexible working days. We love to meet, but if you need to get your kids to school-zoom, you need to leave early to get to your band rehearsal or gym classes, do your thing.¬†\u003c/li\u003e\u003cli\u003ePaid time off so you can recharge.\u003c/li\u003e\u003cli\u003eHealth and dental benefits.\u003c/li\u003e\u003cli\u003eAn international team of talented and engaged people from different cultural backgrounds and locations.\u003c/li\u003e\u003cli\u003eWellbeing allowance for any activity that matters to your wellbeing; (online) gym classes, fitness equipment, mindfulness apps or even childcare support!\u003c/li\u003e\u003cli\u003eUnlimited access to our online learning platform Udemy to help you develop your skills.\u003c/li\u003e\u003cli\u003eVirtual initiatives and events to keep you connected with your colleagues.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eYes, I want this job!\u003c/strong\u003e\u003c/p\u003e","id":16222,"location":"AMER Region","location_type":"remote","position":"Big Data Engineer","published_at":"2022-01-23T21:18:43Z","slug":"llojfrughh-big-data-engineer","status":"approved","tags":["AWS","Azure","Big Data","Business Intelligence"],"type":"fulltime"},{"application_url_or_email":"https://jobs.lever.co/treasure-data/7e24cb1f-21c8-410f-b2c1-71cbca76f49b?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"dataengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/aszhdkcr50.webp","company_name":"Treasure Data","company_slug":"treasure-data","company_twitter":"treasuredata","description":"\u003cp\u003eTreasure Data is seeking a Senior Data Engineer in the US time zone for the Data Engineering Team. Treasure Data began by offering data warehousing and processing services, since then, we‚Äôve moved further up the value chain with our Customer Data Platform application (CDP), which is seeing a lot of traction with customers new and old. Moreover, CDP is the fastest-growing offering we have and is front and center in most major initiatives across the company.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eThe ideal candidate will have the deep technical expertise and strong experience collaborating in a team-oriented environment. Together with the team, you will design, implement, enhance, and advance the data technologies that empower stakeholders to make data-informed decisions faster, with more insights in a timely manner as the Data team aims at¬†‚ÄúZero untapped opportunity with data‚Äù.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eThe Data team prepares data for various internal data stakeholders and dashboarding. Therefore, we are seeking a proven track record of success and a passion for developing data pipelines that are a central part of data engineering work. You should have knowledge of SQL.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cu\u003eThings you will do:\u003c/u\u003e¬†\u003c/p\u003e\u003cul\u003e\u003cli\u003eAnalyzing and organizing raw data; \u003c/li\u003e\u003cli\u003eBuilding data systems and pipelines; \u003c/li\u003e\u003cli\u003eEvaluating business needs and objectives; \u003c/li\u003e\u003cli\u003eBuilding reports and interpreting trends and patterns; \u003c/li\u003e\u003cli\u003ePreparing data for prescriptive and predictive modeling; \u003c/li\u003e\u003cli\u003eBuilding algorithms and prototypes; \u003c/li\u003e\u003cli\u003eKeep up to date on novel technical concepts that we should adopt (and which ones we should ignore); \u003c/li\u003e\u003cli\u003eAlong with the rest of the team, own and operate the data services that you built;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cu\u003eWhat fun stuff are we doing? \u003c/u\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eAcquisition: Sourcing the data from different systems; \u003c/li\u003e\u003cli\u003eCleansing: Detecting and correcting data errors; \u003c/li\u003e\u003cli\u003eConversion: Converting data from one format to another; \u003c/li\u003e\u003cli\u003eInquiries: Quickly responding to data inquiries from stakeholders; \u003c/li\u003e\u003cli\u003eDisambiguation: Interpreting data that has multiple meanings; \u003c/li\u003e\u003cli\u003eDeduplication: Removing duplicate copies of data; \u003c/li\u003e\u003cli\u003ePresenting: Using various BI tools to visualize data; \u003c/li\u003e\u003cli\u003eCorporate Data Strategy: Driving the Corporate Data strategy initiatives;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cu\u003eYour background and skills include: \u003c/u\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eExperience building, expanding \u0026amp; improving, and maintaining the data systems; \u003c/li\u003e\u003cli\u003eExtensive experience on SQL and working with and maintaining Relational Databases in a production environment; \u003c/li\u003e\u003cli\u003eExperience in writing Python code; \u003c/li\u003e\u003cli\u003eDesigning and building data pipelines with reliability and operations in mind;\u003c/li\u003e\u003cli\u003eStrong sense of project ownership and responsibility;\u003c/li\u003e\u003cli\u003eFamiliar with cloud technologies (AWS) and development/deployment in cloud infrastructure; \u003c/li\u003e\u003cli\u003eStrong communication skills with a remote team across time zones; \u003c/li\u003e\u003cli\u003eA demonstrated initiative to stay abreast of technology advancements;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cu\u003eWe would be thrilled if you: \u003c/u\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eHave previous experience working with data; \u003c/li\u003e\u003cli\u003eHave contributed to a production level code; \u003c/li\u003e\u003cli\u003eHave experience in developing a fully managed cloud service; \u003c/li\u003e\u003cli\u003eHave experience with integrating BI tool; \u003c/li\u003e\u003cli\u003eHave made open source contributions;\u003c/li\u003e\u003cli\u003eHave experience with agile development; \u003c/li\u003e\u003cli\u003eAre more importantly willing to take challenges for growth; \u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cu\u003eWho we are:¬†\u003c/u\u003e\u003c/p\u003e\u003cp\u003eTreasure Data employees are enthusiastic, data-driven and customer-obsessed. Our actions reflect our values of honesty, reliability, openness and humility. Treasure Data moved to remote-based work in March 2020 and is committed to ensuring it remains agile to accommodate shifting preferences of its workforce. While we are not working shoulder-to-shoulder, we still work side-by-side, finding unique ways to connect and create together while also respecting each other‚Äôs life priorities outside of work. We offer competitive salary and benefits and named one of the 2021 Best Places to Work. Treasure Data is an equal opportunity employer dedicated to building an inclusive and diverse workforce. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cu\u003eWhat we do:¬†\u003c/u\u003e\u003c/p\u003e\u003cp\u003eTreasure Data is the only enterprise Customer Data Platform (CDP) that harmonizes an organization‚Äôs data, insights, and engagement technology stacks to drive relevant, real-time customer experiences throughout the entire customer journey. Treasure Data helps brands give millions of customers and prospects the feeling that each is the one and only. With its ability to create true, unified views of each individual, Treasure Data CDP is central for enterprises who want to know who is ready to buy, plus when and how to drive them to convert. Flexible, tech-agnostic and infinitely scalable, Treasure Data provides fast time to value even in the most complex environments.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eAgencies and Recruiters: We cannot consider your candidate(s) without a contract in place. Any resumes received without having an active agreement will be considered gratis referrals to us. Thank you for your understanding and cooperation!\u003c/p\u003e","id":16011,"location":"North America","location_type":"remote","position":"Senior Data Engineer","published_at":"2022-01-20T22:09:38Z","slug":"aszhdkcr50-senior-data-engineer","status":"approved","tags":["AWS","Data pipelines","Data Warehousing","Engineering"],"type":"fulltime"},{"application_url_or_email":"https://boards.greenhouse.io/recur/jobs/4303469004?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"dataengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/mnay3mmpla.webp","company_name":"RECUR","company_slug":"recur","company_twitter":"RecurForever","description":"\u003cp\u003eRECUR needs a Senior Data Engineer to join our team full time. This is an exciting opportunity to join a fast-growing organization, where you will be designing and building data pipelines for analytics, forecasting and finance activities.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat do we at RECUR believe makes a great engineering team?¬†\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHere are our core beliefs:¬†¬†¬†\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eIt‚Äôs important to have team members that care about the team‚Äôs results more than their own individual achievements\u003c/li\u003e\u003cli\u003eIt‚Äôs important for leadership to be tolerant of making mistakes\u003c/li\u003e\u003cli\u003eIt‚Äôs important that the team members help, teach, and mentor one another\u003c/li\u003e\u003cli\u003eIt‚Äôs important not to place blame on individuals when things go bad but instead to evaluate as a team how we do it better the next time\u003c/li\u003e\u003cli\u003eIt‚Äôs important to be clear on what that mission is and minimize the distractions on the teams executing on that mission\u003c/li\u003e\u003cli\u003eSmall teams execute better than big ones, empower small teams with ownership and minimize the dependencies between them\u003c/li\u003e\u003cli\u003eIt‚Äôs important to encourage self-directed innovation\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat you will do at RECUR\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eCollaborate with a distributed team of developers and business stakeholders on a wide variety of data engineering, data integration and business intelligence projects.\u003c/li\u003e\u003cli\u003eExplore, document and present new technologies and approaches to the team.\u003c/li\u003e\u003cli\u003eDevelop and maintain data pipelines and integrations using AWS cloud services and best-in-class tools from the modern data stack.\u003c/li\u003e\u003cli\u003eDevelop high quality and maintainable software.\u003c/li\u003e\u003cli\u003eTest your code using modern automated testing frameworks and practices.\u003c/li\u003e\u003cli\u003e‚ÄúOwn‚Äù your code throughout the full product life cycle, including production deployment and support, including participation in on-call rotations and critical issue escalations.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat you will bring to RECUR\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eYou have 5+ years of experience developing data pipelines, data-integrations and/or other data-centric applications.\u003c/li\u003e\u003cli\u003eYou have advanced, extensive working SQL knowledge and practical experience with relational databases and concepts.\u003c/li\u003e\u003cli\u003eYou have familiarity with cloud-based databases such as Redshift or Snowflake.\u003c/li\u003e\u003cli\u003eYou have familiarity with ETL/ELT, BI and orchestration tools and frameworks like Fivetran, DBT, AWS Glue, Tableau, Superset, etc.\u003c/li\u003e\u003cli\u003eYou are comfortable with applying SDLC process concepts to data pipelines and infrastructure, such as source-control, automated testing, CICD, promotion through multiple environments, etc.\u003c/li\u003e\u003cli\u003eYou have a passion for leveraging the latest technologies and innovations while still following a rigorous software development life cycle.\u003c/li\u003e\u003cli\u003eYou learn quickly, are flexible, and do whatever it takes for the team to be successful\u003c/li\u003e\u003cli\u003eYou have an interest in blockchain, cryptocurrency, and NFTs\u003c/li\u003e\u003cli\u003eYou are legally eligible to work in the United States or Canada.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eBenefits \u0026amp; Perks\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eCommitment to being a remote-first company\u003c/li\u003e\u003cli\u003eCompany sponsored Health, Dental and Vision Benefits\u003c/li\u003e\u003cli\u003e401k with no waiting period for vesting\u003c/li\u003e\u003cli\u003e3 weeks paid vacation and 10 paid company holidays\u003c/li\u003e\u003cli\u003eIndustry focused lunch and learns\u003c/li\u003e\u003cli\u003eCompany swag\u003c/li\u003e\u003cli\u003eFlexibility to get the tooling you need to do your best work¬†\u003c/li\u003e\u003cli\u003eThe chance to work with incredibly passionate people on a mission to shape an industry!\u003c/li\u003e\u003c/ul\u003e","id":15986,"location":"North America","location_type":"remote","position":"Senior Data Engineer","published_at":"2022-01-20T22:03:47Z","slug":"mnay3mmpla-senior-data-engineer","status":"approved","tags":["AWS","Blockchain","Business Intelligence","Data pipelines"],"type":"fulltime"},{"application_url_or_email":"https://boards.greenhouse.io/beat/jobs/3832985?gh_jid=3832985\u0026ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"machinelearning","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/di5wu0xfxn.webp","company_name":"Beat","company_slug":"beat","company_twitter":"thebeatapp","description":"\u003cp\u003e\u003cstrong\u003eAbout us\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eBeat is the fastest growing ride hailing app in Latin America and a part of the international FreeNow Group, the multi-service mobility joint venture backed by BMW Group and Daimler AG. One city at a time, we are on a mission to develop seamless mobility for a safe and sustainable urban life. We are proud to say we have launched Beat Tesla / Loonshot, the first and largest private all-electric vehicle service in Latin America.¬†\u003c/p\u003e\u003cp\u003eAs an organization, we are committed to our drivers with ethical practices and a safe working environment. To our customers, we differentiate ourselves from other ride-hailing apps with our super user-friendly app and excellent customer service. Last but not least, our priority is to maintain a hyperlocal approach in everything we do, from product to operations to marketing.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWe are proud to see Beat leading the FreeNow group in growth in 2021 and we have ambitious plans for 2022. But we need you to help us get closer to our vision: ‚Äã‚Äãa connected Latin America where the only question is ‚ÄúWhere Next?‚Äù\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWe are currently operating in Mexico, Argentina, Chile, Colombia, Peru and Greece and are transporting over 24 million riders with the support of more than 700,000 drivers. Our global headquarters are in Athens - where BEAT started back in 2011. We also have offices in Amsterdam.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eOur employee base is spread out even wider. We mastered the hybrid workspace with our office and remote locations even before Covid-19. So if you are interested in joining us on our mission, whether based in one of the countries we operate or elsewhere in the world, we are happy to hear from you!\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAbout the role\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eWe‚Äôre looking for a Senior Machine Learning Engineer to join the Machine Learning team within the Matching Domain.\u003c/p\u003e\u003cp\u003eThe domain has all necessary crafts to allow us to achieve our goals autonomously and consists of a Product team (Product Managers, Data Analysts and Designers) and Engineering (Backend, Frontend, Data and ML). The domain has the following areas of responsibility:\u003c/p\u003e\u003cul\u003e\u003cli\u003eDispatch, orchestrating the whole matching workflow between passenger and drivers\u003c/li\u003e\u003cli\u003eMatching, trying to find the optimal driver for a passenger\u003c/li\u003e\u003cli\u003eMapping, providing map-related services to all domains in the company\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eOur teams work in a virtual office setup, with overlapping hours and a mixture of sync and async communication methods. You‚Äôll be reporting to the ML team‚Äôs Engineering Manager.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat‚Äôs the day to day\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eThe ML team is working across all projects within Matching Domain. We are responsible for intelligently matching drivers to users' ride requests using driver and passenger behaviour modelling. We also estimate the total duration of rides using ML models and we apply data-driven insights and heuristics to optimally configure the Matching‚Äôs flow parameters. We are concerned with the whole lifecycle of the development of a ML/DS product as our work starts with formalizing the business requirements and follows all appropriate steps until a well performing, ML-powered solution gets into BEAT‚Äôs production flow.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eOur marketplace team work on matching drivers with passengers, focusing on the best optimisation of this, so the main challenge is the balance of dynamic pricing to keep the drivers earnings optimised and the passengers fair lower.¬†\u003c/p\u003e\u003cp\u003eIf you can help us solve these challenges, we want to hear from you!¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat you will do¬†\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eWork within a cross-functional team, highly skilled in data science, machine learning, software engineering and data engineering.\u003c/li\u003e\u003cli\u003eUnderstand product requirements and formulate suitable ML-based POCs to satisfy them.\u003c/li\u003e\u003cli\u003eConvert successful POCs to fully-fledged ML-based product features and put them in BEAT‚Äôs production flow in collaboration with Matching‚Äôs domain‚Äôs backend teams.¬†¬†\u003c/li\u003e\u003cli\u003eEvaluate ML features/models both offline and online through AB tests and online performance monitoring.\u003c/li\u003e\u003cli\u003eMaintain and improve the performance of existing solutions.¬†\u003c/li\u003e\u003cli\u003eTake full ownership of your work, being able to lead and mentor junior to mid level teammates.\u003c/li\u003e\u003cli\u003eBe part of BEAT‚Äôs ML Chapter, a community of ML engineers across the company, formed with the purpose of knowledge sharing across different teams.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e¬†\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat you need to bring¬†\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eMaster's degree in Computer Science or in a related STEM field. Higher degrees are highly appreciated.\u003c/li\u003e\u003cli\u003eSolid understanding of methods, concepts, models, evaluation schemes across the whole DS/ML landscape, eg. supervised learning, unsupervised learning, data mining etc.\u003c/li\u003e\u003cli\u003eSolid coding experience in Python.\u003c/li\u003e\u003cli\u003eSolid experience in working the full software development lifecycle using the industry‚Äôs best practices.¬†\u003c/li\u003e\u003cli\u003eKnowledge of SQL and relational databases.¬†\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch4\u003e\u003cstrong\u003eWhat is useful to have:\u003c/strong\u003e\u003c/h4\u003e\u003cul\u003e\u003cli\u003eHands-on experience with MLOPs frameworks such as Kubeflow, MLFlow, (Azure ML Studio) or Amazon Sagemaker.\u003c/li\u003e\u003cli\u003eHands-on experience with Apache Spark.\u003c/li\u003e\u003cli\u003eHands-on experience with Docker and Kubernetes.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAbout the interview process at BEAT\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eDuring our interview process, we want to learn about you but also provide you with a good understanding of what it‚Äôs like to work at Beat. We will introduce you to several team members and stakeholders to make sure you can ask all your questions.\u003c/p\u003e\u003cp\u003eHere is what you can expect:\u003c/p\u003e\u003cul\u003e\u003cli\u003eAn initial conversation with a member of the Talent Acquisition team\u003c/li\u003e\u003cli\u003eAn introductory meeting with your potential future manager\u003c/li\u003e\u003cli\u003eFor tech roles, there is a take home assignment that you will need to submit by the agreed deadline\u003c/li\u003e\u003cli\u003eThe last stage of the interview process will be meetings with the team and internal stakeholders.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eThroughout the process, our Candidate Experience team will be there to support you and ensure that you have a great time interviewing with us.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat's in it for you:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eCompetitive full-time salary\u003c/li\u003e\u003cli\u003eFlexible working hours, top Line tools\u003c/li\u003e\u003cli\u003eWorking in a hyper-growth environment, you will enjoy numerous learning and career development opportunities¬†\u003c/li\u003e\u003cli\u003eA great opportunity to grow and work with the most amazing people in the industry\u003c/li\u003e\u003cli\u003eBeing part of an environment that offers challenging goals, autonomy and mentoring, which creates incredible opportunities, both for you and the company.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eAs part of our dedication to the diversity of our workforce, Beat is committed to Equal Employment Opportunity without regard for race, colour, national origin, ethnicity, gender, disability, sexual orientation, gender identity, or religion.\u003c/p\u003e","id":15978,"location":"Worldwide","location_type":"remote","position":"Machine Learning Engineer","published_at":"2022-01-20T22:02:03Z","slug":"di5wu0xfxn-machine-learning-engineer","status":"approved","tags":["Azure","Data Mining","Engineering","Kubernetes"],"type":"fulltime"},{"application_url_or_email":"https://jobs.lever.co/sensortower/f0fdd10d-2fb1-435b-995b-6273c07c43fe?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"datascience","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/j3bdjnckkd.webp","company_name":"Sensor Tower","company_slug":"sensor-tower","company_twitter":"SensorTower","description":"\u003cp\u003e\u003cstrong\u003eQuick Intro to Sensor Tower\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://sensortower.com/\"\u003eSensor Tower\u003c/a\u003e is a high-growth SaaS company that provides accurate, comprehensive, and customizable mobile market economy analytics to app developers, marketers, and industry analysts across gaming, travel \u0026amp; hospitality, music, finance, broadcast entertainment. We serve a wide range of clients from early-stage mobile innovators to industry-leading Fortune 500 companies.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eAs a high-integrity source of industry insight, Sensor Tower is regularly cited by the world‚Äôs leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.¬†¬†Founded in 2013, Sensor Tower has grown from a $1M seed investment to being profitable and in 2020 we received a $42M growth investment from Riverwood Capital.\u003c/p\u003e\u003cp\u003eRole Summary:Data Scientists at Sensor Tower are hybrid data scientists and software engineers. You would take data all the way from doing initial analysis to building data pipelines to final model implementation and monitoring. Data Scientists take full ownership of the back-end of the products they‚Äôre working on.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWe are looking for a hands-on thinker to help harvest new insights from our constantly growing foundation of quantitative information collected from the mobile app ecosystem.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eResponsibilities\u003c/h3\u003e\u003cul\u003e\u003cli\u003ePrototype machine learning models in Python or Ruby\u003c/li\u003e\u003cli\u003eWork with MongoDB and analyze query performance to ensure calculation efficiency\u003c/li\u003e\u003cli\u003eWrite tests for the implementation of machine learning models\u003c/li\u003e\u003cli\u003eCollaborate with back-end engineers to understand the raw data being collected\u003c/li\u003e\u003cli\u003eCollaborate with front-end engineers to create data visualizations for both external and internal customers\u003c/li\u003e\u003cli\u003eConduct ad-hoc data analysis based on requests from the Sales, CSM or Contents team\u003c/li\u003e\u003cli\u003ePresent results of various data analysis\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eRequirements\u003c/h3\u003e\u003cul\u003e\u003cli\u003eMaster‚Äôs degree or above in mathematics, statistics, or computer science\u003c/li\u003e\u003cli\u003e3+ years applied experience in business intelligence, data mining, analytics, or statistical modeling in technology or mobile industries OR 2+ years applied experience in data science in mobile market intelligence\u003c/li\u003e\u003cli\u003eAbility to write code that is ready for production (Python and Ruby preferred)\u003c/li\u003e\u003cli\u003eExperience with adjusting data for bias\u003c/li\u003e\u003cli\u003eSubstantial experience with databases, querying data, and data structure manipulation\u003c/li\u003e\u003cli\u003eAbility to communicate effectively with technical developers and non-technical marketing business partners\u003c/li\u003e\u003cli\u003eAbility to produce rough timelines for deliveries plus solid understanding of steps necessary to complete a project\u003c/li\u003e\u003cli\u003eAbility to come up with a rough project structure from scratch\u003c/li\u003e\u003cli\u003eAbility to critically analyse given data, ask probing questions, and perform own research\u003c/li\u003e\u003cli\u003eSubstantial knowledge of statistical modeling techniques\u003c/li\u003e\u003cli\u003eMastery of one or more statistical visualization or graphing toolkits such as Excel, Jupyter Notebooks, or Google Spreadsheets\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat is it like working at Sensor Tower?\u003c/strong\u003e¬†¬†\u003c/p\u003e\u003cp\u003eSensor Tower‚Äôs flexible work environment allows employees to choose how much they want to work remotely or in an office. We offer flexible time off so employees can shape their time away from the office. Our model allows employees to live in greater connection with the people, traditions, places, and activities they love while contributing to their team!¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eSensor Tower provides fair and competitive compensation packages that honor the investment our team members make each day. To support health and wellbeing, we offer industry-standard benefits and additional perks that our employees love. This includes stipends for office and/or gym setup, home internet, and daily meal delivery.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWe are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, and veteran status. In support of the San Francisco Fair Chance Ordinance, we will consider qualified applicants with arrest and conviction records. If you have a disability or special need, please do not hesitate to let us know and we'll do our best to accommodate.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eInterested in learning more? Submit your info and let's get a conversation going!\u003c/p\u003e","id":15977,"location":"Europe","location_type":"remote","position":"Senior Data Scientist","published_at":"2022-01-20T21:59:17Z","slug":"j3bdjnckkd-senior-data-scientist","status":"approved","tags":["Business Intelligence","Data Mining","Data pipelines","Finance"],"type":"fulltime"},{"application_url_or_email":"https://boards.greenhouse.io/digit/jobs/3289203?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"dataengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/fviqfy4gvp.webp","company_name":"Digit","company_slug":"digit","company_twitter":"hellodigit","description":"\u003cp\u003e\u003cstrong\u003eThe Challenge\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eAt Digit, we are on a mission to make financial health effortless for everyone. We are building the world‚Äôs first intelligent bank account to help millions of American consumers become financially healthy. Our challenge is clear: managing personal finances is hard. As of 2019, 70% of Americans struggle with at least one aspect of financial stability and over 40% don‚Äôt have $400 in their savings account. We believe automation is our path to delivering our mission, and we are working towards it every day.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWe have a collaborative, diverse, and supportive culture and we look for people who are curious, ambitious, and mission-driven. If you‚Äôre passionate about building something that‚Äôs never been built before and helping real people every day we‚Äôre excited to meet you!\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eThe Role\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eWe are looking for a Senior Data Engineer who is passionate about all things data to come help us build Digit‚Äôs data platform. In this role you will work on our Data Engineering team to own and build our data infrastructure to make Digit more data driven as we build an intelligent bank account. While Digit is headquartered in SF, this role is open to anyone, anywhere in the US and reports to the Engineering Manager of our Data Engineering team.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat You‚Äôll Do:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eBuild, scale and manage Digit‚Äôs data platform including but not limited to our Kafka pipelines, Redshift and Delta Lake setups, and our Airflow and DBT deployments.\u003c/li\u003e\u003cli\u003eCollaborate with our data science and machine learning teams to power the ‚Äòbrains‚Äô of our bank account and product teams to enable data driven product development.\u003c/li\u003e\u003cli\u003eImplement and control data access, governance and cataloging solutions for Digit‚Äôs data.\u003c/li\u003e\u003cli\u003eBrainstorm, plan and iterate on Digit‚Äôs data platform roadmap.\u003c/li\u003e\u003cli\u003eAdvocate for industry standard data engineering practices for Digit‚Äôs data platform and products and champion their implementation and adoption.\u003c/li\u003e\u003cli\u003eParticipate in team oncall and bug rotations.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWho You Are:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eYou have 2+ years of dedicated data engineering experience at scale.\u003c/li\u003e\u003cli\u003eYou have experience building and working with both real-time and batch data pipelines. You can design and develop scalable data solutions with a long-term and growth mindset.\u003c/li\u003e\u003cli\u003eYou have recent accomplishments working closely with relational as well as No-SQL data stores. You‚Äôre familiar with extracting data from different data stores and making it available for analytical and machine learning use cases in data lakes and warehouses.\u003c/li\u003e\u003cli\u003eYou get excited to try out new technologies. You like to produce proof-of-concepts leveraging them to demonstrate if they can improve existing processes or systems.\u003c/li\u003e\u003cli\u003eYou aren‚Äôt afraid to get deep into the weeds to manage, deploy and improve low level data infrastructure.\u003c/li\u003e\u003cli\u003eYou operate with empathy when working with your stakeholders. You listen to them, speak your mind, ask the right questions and come up with optimal solutions for them.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eBonus Points If:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eYou have familiarity with the AWS ecosystem.\u003c/li\u003e\u003cli\u003eYou are well-versed with Kafka and it‚Äôs stream processing frameworks.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWho We Are:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eWe want to eliminate the stress and anxiety people feel about their finances so they can focus on what‚Äôs most important in their lives. We first mastered saving for near-term goals, helping members automatically save over $6B in cumulative savings and prevented $170M in overdraft fees. Today, we are harnessing machine learning technology to give our members the first intelligent bank account that manages all of their personal finances.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWe‚Äôre committed to doing the best work of our lives together. Come see if Digit is right for you.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat We Offer You:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eCompetitive salary and RSUs\u003c/li\u003e\u003cli\u003e100% paid medical, dental, \u0026amp; vision benefits\u003c/li\u003e\u003cli\u003e100% paid life \u0026amp; disability insurance\u003c/li\u003e\u003cli\u003eFertility reimbursement\u003c/li\u003e\u003cli\u003eDaily lunch stipend\u003c/li\u003e\u003cli\u003eInternet, commuter, and wellness benefits\u003c/li\u003e\u003cli\u003eTake what you need PTO policy\u003c/li\u003e\u003cli\u003e401k plan\u003c/li\u003e\u003cli\u003eFlexible, hybrid work environment\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eDigit is a proud equal opportunity employer and we believe that a diverse and inclusive workforce is an imperative. We welcome people of different backgrounds, genders, races, ethnicities, abilities, sexual orientations, and perspectives. We don‚Äôt discriminate based upon any protected class and we encourage candidates of all identities and backgrounds to apply. Digit considers qualified applicants regardless of criminal histories in accordance with the \u003ca href=\"http://sfgsa.org/modules/showdocument.aspx?documentid=11600\"\u003eSan Francisco Fair Chance Ordinance.\u003c/a\u003e\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eDigit is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at \u003ca href=\"mailto:recruiting@digit.co\"\u003e\u003cu\u003erecruiting@digit.co\u003c/u\u003e\u003c/a\u003e.\u003c/p\u003e","id":15976,"location":"USA","location_type":"remote","position":"Senior Data Engineer","published_at":"2022-01-20T21:57:00Z","slug":"fviqfy4gvp-senior-data-engineer","status":"approved","tags":["Airflow","AWS","Data pipelines","Engineering"],"type":"fulltime"},{"application_url_or_email":"https://boards.greenhouse.io/figure/jobs/5829529002?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"machinelearning","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/x2rlhlnxdn.webp","company_name":"Figure","company_slug":"figure","company_twitter":"Figure","description":"\u003cp\u003e\u003cstrong\u003eAbout Figure\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eFigure is transforming the trillion dollar financial services industry using blockchain technology.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eIn three short years, Figure has unveiled a series of fintech firsts using the Provenance blockchain for loan origination, equity management, private fund services, banking and payments sectors - bringing speed, efficiency and savings to both consumers and institutions. Today, Figure is one of less than a thousand companies considered a unicorn, globally.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eOur mission requires us to have a creative, team-oriented, and supportive environment where everyone can do their absolute best. The team is composed of driven, innovative, collaborative, and curious people who love architecting ground-breaking technologies. We value individuals who bring an entrepreneurial mindset to every task and will embrace our culture of innovation.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eEvery day at Figure is a journey in continuous learning yet a daily focus on getting work done that makes a difference. Join a team of proven leaders who have already created billions of dollars in value in the FinTech space!\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://www.forbes.com/americas-best-startup-employers/#6535f31b6527\"\u003eForbes America‚Äôs Best Startup Employers\u003c/a\u003e\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://www.forbes.com/sites/michaeldelcastillo/2020/02/19/blockchain-50/?sh=60e7347c7553\"\u003eForbes Top 50 Blockchain Companies\u003c/a\u003e\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://www.businesswire.com/news/home/20210520005738/en/Figure-Raises-200-Million-Series-D-Co-Led-by-10T-Holdings-and-Morgan-Creek-Digital\"\u003eFigure Series D Announcement\u003c/a\u003e\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAbout the Role\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eEach member of the Data Science team plays an integral part of what we are building at Figure.¬†We rely on advanced techniques in machine learning, cloud platforms and big data to drive decisions across the organization. If you are interested in working with an impressive team of Data pros who collaborate and challenge each other, and want to solve interesting problems to propel the company‚Äôs growth, apply now!¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eIn this role, you'll be embedded with a team of machine learning developers. You'll be expected to help conceive, code, and deploy machine learning models at scale using the latest industry tools. Important skills include machine learning workflow automation and ML Ops.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat You‚Äôll get to do\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eSupport Figure in building a machine learning platform to serve multiple lines of business and data science personas.¬†\u003c/li\u003e\u003cli\u003eWork with data scientists to refine workflow automation and increase productivity.¬†\u003c/li\u003e\u003cli\u003ePartner with data scientists to understand, implement, refine, and design machine learning and other algorithms.\u003c/li\u003e\u003cli\u003ePerform regular A/B tests, gather data, perform analyses, and draw conclusions about model performance.¬†\u003c/li\u003e\u003cli\u003eWork cross-functionally with product managers, data scientists, engineers, and communicate results to peers and leaders.¬†\u003c/li\u003e\u003cli\u003eExplore new technology to determine how they might connect with the customer benefits we wish to deliver.¬†\u003c/li\u003e\u003cli\u003eBuild tools to monitor data pipeline performance, data quality, and models in production.¬†\u003c/li\u003e\u003cli\u003eEstablish best practices with coding standards, workflows, tools, and product automation.¬†\u003c/li\u003e\u003cli\u003eReview and maintain existing codebase (pipelines, models, algorithms), continue to improve existing tools and create new ones.\u003c/li\u003e\u003cli\u003eBuild fundamentally sound, production-ready software and data products using modern development lifecycle methodologies: CI/CD, QA, and Agile Methodologies and deploy highly scalable software\u003c/li\u003e\u003cli\u003eWork as part of a data team working with mature data science products.\u003c/li\u003e\u003cli\u003eIntegrate applications and platforms with cloud technologies (e.g., AWS and GCP)\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat We Look For\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eBS, MS, or PhD in Computer Science or a related field, or equivalent practical experience.¬†\u003c/li\u003e\u003cli\u003e5+ years of experience and a passion for designing, analyzing, and deploying machine learning-based solutions.\u003c/li\u003e\u003cli\u003eApplied experience designing, building, and optimizing data pipelines, architectures, and data sets.¬†\u003c/li\u003e\u003cli\u003eGood understanding of machine learning methods and statistics, including ML project lifecycle and associated challenges at each stage of development.¬†\u003c/li\u003e\u003cli\u003eKnowledgeable about machine learning frameworks (e.g. PyTorch, Tensorflow, XGBoost, etc)¬†\u003c/li\u003e\u003cli\u003eExpert-level knowledge of setup and use of data processing tools (e.g. Spark, Dask, etc) and distributed computing frameworks (e.g. Ray, Dask, etc)\u003c/li\u003e\u003cli\u003eComputer science fundamentals: data structures, algorithms, performance complexity, and implications of computer architecture on software performance such as I/O and memory tuning.\u003c/li\u003e\u003cli\u003eExperience with GPU acceleration (i.e. CUDA and cuDNN)\u003c/li\u003e\u003cli\u003eExperience with tools like MLFlow, Airflow, Prefect, Docker, and Kubernetes is ideal.¬†\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eBenefits and Perks\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eCompetitive salary and growth opportunities¬†\u003c/li\u003e\u003cli\u003eCompany quarterly performance based bonus\u003c/li\u003e\u003cli\u003eEquity stock options package\u003c/li\u003e\u003cli\u003eEmployer funded comprehensive health, vision, dental insurance and wellness program for employees and their dependents\u003c/li\u003e\u003cli\u003eEmployer funded life and disability insurance coverage\u003c/li\u003e\u003cli\u003eCompany HSA, FSA, Dependent Care, 401k, and commuter benefits\u003c/li\u003e\u003cli\u003eUp to 12 weeks paid family leave¬†\u003c/li\u003e\u003cli\u003eIn office, remote, and hybrid work location options\u003c/li\u003e\u003cli\u003eHome office and technology stipend for those working outside of a traditional office more than 75% of the time\u003c/li\u003e\u003cli\u003eFlexible time-off plan to empower employees to take the time off that they want and need\u003c/li\u003e\u003cli\u003eContinuing education reimbursement\u003c/li\u003e\u003cli\u003eRoutine Team swag deliveries!\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eDepending on your residential location certain laws might regulate the way Figure manages applicant data. California Residents, please review our \u003ca href=\"https://drive.google.com/file/d/1eDhTkvbpFETeAvGpsB8e6KzaXES4BWNB/view?usp=sharing\"\u003eCalifornia Employee and Prospective Employee Privacy Notice\u003c/a\u003e for further information. By submitting your application, you are agreeing¬†and acknowledging that you have read and understand the above notice.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eFigure is unfortunately unable to provide sponsorship for this position. In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire.\u003c/p\u003e","id":15934,"location":"United States","location_type":"remote","position":"Machine Learning Engineer","published_at":"2022-01-19T20:05:28Z","slug":"x2rlhlnxdn-machine-learning-engineer","status":"approved","tags":["Airflow","AWS","Banking","Big Data"],"type":"fulltime"},{"application_url_or_email":"https://apply.workable.com/j/8F40C1DD9B/apply?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"dataengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/65mhjxbhkk.webp","company_name":"Netguru","company_slug":"netguru","company_twitter":"netguru","description":"\u003cp\u003eJoin\u003ca href=\"https://www.netguru.com/talent/marketplace\"\u003e Netguru Talent Marketplace\u003c/a\u003e, a proven partner for tech-minded freelancers and experts. Thanks to us, you will have access to various project-based opportunities and can collaborate with different companies and industries. As a result, you will not only gain more experience but also develop a variety of skills you didn‚Äôt even know you had. Work the way you like, on your terms, with no strings attached.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eOver the past ten years, Netguru has changed the way people bank, listen to music, learn languages, and rent bicycles. Some of our clients include Fortune 500 companies and startups like Shine, Countr, Petro Niche, and more. Netguru works with the largest brands in the world, such as Volkswagen, IKEA, and Keller Williams.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eOur team of 650+ allows us to deliver well-designed and optimized custom mobile app development solutions for both iOS and Android mobile platforms, in turn, increasing the productivity of a business enterprise. The main reason behind custom mobile apps is that they not only help business owners transform their unique ideas into reality, but also help them deliver personalized UX.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eJoining Netguru's project means:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eWorking with the Data Engineering and Machine Learning team to build custom data pipelines.\u003c/li\u003e\u003cli\u003eWorking with external clients, teams, data owners, and solution architects to build data flows in a reliable way.\u003c/li\u003e\u003cli\u003eBuilding transformations, scripts, and migrations to multiple specifications and standards.\u003c/li\u003e\u003cli\u003eData-driven mindset - our clients require PoCs, data exploration/normalization, and expertise.\u003c/li\u003e\u003cli\u003eMonitoring data flows and making continuous improvements to data pipelines.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eRequirements\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eApply if you:\u003c/li\u003e\u003cli\u003eAre advanced in \u003cstrong\u003ePython\u003c/strong\u003e programming language (understanding: iterators, generators, exceptions, OOP, popular libraries for data engineering).\u003c/li\u003e\u003cli\u003eHave advanced \u003cstrong\u003eSQL\u003c/strong\u003e knowledge.\u003c/li\u003e\u003cli\u003eHave practical knowledge of DevOps t.j. CI, CD, terraform, observability.\u003c/li\u003e\u003cli\u003eHave experience with \u003cstrong\u003eApache Spark / AWS Glue\u003c/strong\u003e, or similar solutions.\u003c/li\u003e\u003cli\u003eHave experience with \u003cstrong\u003eETL (Airflow)\u003c/strong\u003e or other data processing automation approaches.\u003c/li\u003e\u003cli\u003eHave experience with \u003cstrong\u003eSnowflake\u003c/strong\u003e.\u003c/li\u003e\u003cli\u003eHave a very good command of written and spoken \u003cstrong\u003eEnglish (B2+)\u003c/strong\u003e. Polish is not required.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eWe'll be happy to see that you have:\u003c/h3\u003e\u003cul\u003e\u003cli\u003eExperience with AWS Redshift or GCP BigQuery.\u003c/li\u003e\u003cli\u003eExperience with coding in Scala.\u003c/li\u003e\u003cli\u003eHave hands-on experience with Hadoop technologies or equivalent in the cloud environment.\u003c/li\u003e\u003cli\u003eExperience optimizing data storage in HDFS/Parquet/Avro.\u003c/li\u003e\u003cli\u003eExperience with cloud technologies (AWS, GCP, Azure or other).\u003c/li\u003e\u003cli\u003eWorked with data (ideally TB+).\u003c/li\u003e\u003cli\u003eCan debug complex data infrastructures.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eBenefits\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cem\u003e100-percent remote work.\u003c/em\u003e\u003c/li\u003e\u003cli\u003e\u003cem\u003eWork with an experienced team of developers and continuously develop your hard and soft skills.\u003c/em\u003e\u003c/li\u003e\u003cli\u003e\u003cem\u003eA mentor who will assist you during your first days.\u003c/em\u003e\u003c/li\u003e\u003cli\u003e\u003cem\u003eDev-friendly processes such as Continuous Integration, Continuous Delivery, Code Review, and bug bashes.\u003c/em\u003e\u003c/li\u003e\u003cli\u003e\u003cem\u003eCollaboration on challenging products (FinTech, B2B software, E-commerce, and more).\u003c/em\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eLooking for a full-time job? Check out our\u003c/em\u003e\u003ca href=\"https://www.netguru.com/career\"\u003e \u003cem\u003eCareer Page\u003c/em\u003e\u003c/a\u003e\u003cem\u003e and find out more about our open recruitment processes. \u003c/em\u003e\u003c/p\u003e","id":15915,"location":"Worldwide","location_type":"remote","position":"Data Engineer","published_at":"2022-01-19T20:02:36Z","slug":"65mhjxbhkk-data-engineer","status":"approved","tags":["Airflow","Avro","AWS","Azure"],"type":"fulltime"},{"application_url_or_email":"https://boards.greenhouse.io/demandbase/jobs/3830086?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"softwareengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/trz1dxqeps.webp","company_name":"Demandbase","company_slug":"demandbase","company_twitter":"Demandbase","description":"\u003cp\u003e\u003cstrong\u003eIntroduction to Demandbase:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eThe biggest and fastest-growing companies in the world rely on Demandbase to drive their account-based strategies and maximize B2B go-to-market performance. We pioneered the ABM category nearly a decade ago, and today we lead the industry as an indispensable part of the B2B tech stack. Demandbase offers the only end-to-end Account-Based Experience (ABX) solution that helps B2B companies find, engage, and close the accounts that matter most. Our success would not be possible without the driven and collaborative teams here at Demandbase. As a company, we‚Äôre as committed to growing careers as we are to building world-class technology. We invest heavily in people, our culture, and the community around us. We have offices in the Bay Area, New York, Seattle, and a team in the UK, and allow employees to work remotely from anywhere in the US. We have also continuously been recognized as one of the best places to work in the Bay Area.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eOur success depends on our ability to create a diverse, equitable and inclusive environment. We're committed to attracting, developing, retaining and promoting a diverse workforce. By ensuring that every Demandbase employee is able to bring a diversity of talents to work, we're increasingly capable of living out our mission and providing real insight from our products to support our customers. We encourage people from underrepresented backgrounds and all walks of life to apply. Come grow with us at Demandbase!\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAbout the Role:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eIn this role, you will help build the next generation unified data platform that will combine datasets from across the Demandbase ecosystem. Using the latest open source tools, you'll solve complex data warehousing problems to ensure quality, discoverability and accessibility of data. You'll build batch and streaming data pipelines for ingestion, normalization and analysis; in addition, you'll develop standard design and access patterns that will allow these pipelines to stay flexible and grow over time as the needs of the business change. You'll be a leader in the unification of data from our multiple products as we come together as one Demandbase platform.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat you'll be doing:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eBuild out all aspects of the Demandbase Data ecosystem and move products from R\u0026amp;D into production scale\u003c/li\u003e\u003cli\u003eDesign and build data pipelines to create the next generation of Demandbase‚Äôs Unified Data Platform\u003c/li\u003e\u003cli\u003eWork across the data stack to build and productionalize data pipelines for massive amounts of data\u003c/li\u003e\u003cli\u003eBuild DAGs in Airflow for orchestration and monitoring of data pipelines\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat we're looking for:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eFour-year degree in Computer Science, or related field OR equivalent experience\u003c/li\u003e\u003cli\u003eProgressive experience in all of the following areas:\u003c/li\u003e\u003cli\u003eDesigning frameworks and writing efficient data pipelines, including batches and real time streams\u003c/li\u003e\u003cli\u003eUnderstanding of data strategies, articulate data analysis \u0026amp; data model design and evolve data products according to business requirements.\u003c/li\u003e\u003cli\u003eExperience with the Spark Ecosystem (YARN, Executors, Livy, etc)\u003c/li\u003e\u003cli\u003eExperience in large scale data streaming, particularly Kafka or similar technologies (Pulsar, Kinesis, etc)\u003c/li\u003e\u003cli\u003eExperience with data orchestration frameworks, particularly Airflow or similar\u003c/li\u003e\u003cli\u003eExperience with columnar data stores, particularly Parquet and Clickhouse\u003c/li\u003e\u003cli\u003eStrong SDLC principles (CI/CD, Unit Testing, git, etc)\u003c/li\u003e\u003cli\u003eGeneral understanding of AWS EMR, EC2, S3\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eEven better if you have‚Ä¶.\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eExperience with¬†\u003c/li\u003e\u003cli\u003e‚ÄúLakehouse‚Äù technologies, particularly Iceberg or similar (DeltaLake, Hudi, etc)\u003c/li\u003e\u003cli\u003eTerraform for AWS\u003c/li\u003e\u003cli\u003eAstronomer\u003c/li\u003e\u003cli\u003eOpen Source contribution experience\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eBenefits:¬†\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eOur benefits include options for 100% paid for Medical, Dental and Vision for you and your entire family, short-term/long-term disability, life insurance, flexible vacation policy and 401K.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eMore About Demandbase:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eDemandbase is the leader in Account-Based Experience (ABX) and an indispensable part of the B2B Go-to-Market tech stack. The company offers simply the best account-based platform to find, engage, and close the accounts that matter. The biggest and fastest-growing companies in the world, such as Accenture, Adobe, DocuSign, GE, Salesforce, and others, rely on Demandbase to drive their ABX strategy and maximize their marketing performance. Demandbase has been named to the JMP Securities list ‚ÄúThe Hot 100: The Best Privately Held Software Companies,‚Äù the Deloitte Fast 500, and named a Gartner Cool Vendor for Tech Go-To-Market.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eFor more information, please visit www.demandbase.com or follow the company on Twitter @Demandbase.¬†\u003c/p\u003e","id":15914,"location":"US","location_type":"remote","position":"Senior Data Engineer","published_at":"2022-01-19T20:00:52Z","slug":"trz1dxqeps-senior-data-engineer","status":"approved","tags":["Data Platform","Airflow","AWS","Data Warehousing"],"type":"fulltime"},{"application_url_or_email":"https://angel.co/company/ydata/jobs/683530-mlops-back-end-engineer","category":"devops","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/nzziqxbdfc.webp","company_name":"YData.ai","company_slug":"ydata-ai","company_twitter":"YData_ai","description":"\u003cp\u003eSalary Range: ‚Ç¨25k ‚Äì ‚Ç¨45k | Equity: 0.0% ‚Äì 0.1%\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWe're looking for an MLOps / Back-End Engineer who will help us shape our team, drive the company to the next level, and have the most direct influence on our success.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eYour Profile\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eExperience or interest to work with Go and/or Python languages\u003c/li\u003e\u003cli\u003eExperience with infrastructure technologies (Kubernetes and Docker)\u003c/li\u003e\u003cli\u003eExperience developing distributed systems and microservies architectures\u003c/li\u003e\u003cli\u003eUnit, integration, and end-to-end tests are an essential part of your coding style\u003c/li\u003e\u003cli\u003ePassionate about learning new tools and keeping yourself up-to-date\u003c/li\u003e\u003cli\u003eWillingness to communicate and share your knowledge with other team members\u003c/li\u003e\u003cli\u003eWillingness to work in agile processes, like Scrum or Kanban\u003c/li\u003e\u003cli\u003eFluent in English\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eYour Responsibilities\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eYou will be part of a self-organized, cross-functional team building a data platform\u003c/li\u003e\u003cli\u003eSince our team is currently being developed from scratch, we need pragmatic engineers\u003c/li\u003e\u003cli\u003eYou are not only our 'code', you take responsibility for the whole product your team delivers\u003c/li\u003e\u003cli\u003eYou are curious and figure out how things work and how they should work for your product\u003c/li\u003e\u003cli\u003eYou bring your core expertise but are open to getting your hands dirty with back-end, DevOps, QA, and customer success\u003c/li\u003e\u003cli\u003eYou have a problem-solving attitude\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eOur Perks ‚Äì More than just a job\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eHave an impact. With innovation and smart technology, we are changing the way organizations use and share data.\u003c/li\u003e\u003cli\u003eTrust-based working. We don't punch the clock ‚Äì organize your own schedule. We trust in what you do!\u003c/li\u003e\u003cli\u003eImprove yourself. We only hire the best and make them even better.\u003c/li\u003e\u003cli\u003eFeel at home. Literally! We are remote work enthusiasts!\u003c/li\u003e\u003cli\u003eFeel it‚Äôs your own company. Besides salary, we offer stock options because we want you to be part of YData.\u003c/li\u003e\u003c/ul\u003e","id":15884,"location":"Europe, Africa, North America, South America, Central America","location_type":"remote","position":"MLOps / Back-End Engineer","published_at":"2022-01-18T17:14:08Z","slug":"nzziqxbdfc-mlops-back-end-engineer","status":"approved","tags":["Go","Python","Kubernetes","Docker"],"type":"fulltime"},{"application_url_or_email":"https://boards.greenhouse.io/affirm/jobs/4857087003?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"dataengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/ecdbh7e98x.webp","company_name":"Affirm","company_slug":"affirm","company_twitter":"Affirm","description":"\u003cp\u003eAffirm is reinventing credit to make it more honest and friendly, giving consumers the flexibility to buy now and pay later without any hidden fees or compounding interest. Affirm, Inc. proudly includes Affirm, PayBright, and Returnly.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWhat you'll do\u003c/p\u003e\u003cul\u003e\u003cli\u003eHelp shape the technical direction of a domain within the Data@ organization.\u003c/li\u003e\u003cli\u003eBuild a reliable and scalable single source of truth core model data product for internal and external analytics and enable self-service.\u003c/li\u003e\u003cli\u003ePartner with product, data analyst, engineering teams and other data engineers to translate business requirements into data models with measurable transformation quality under SLA.\u003c/li\u003e\u003cli\u003eDevelop and automate large-scale, high-performance data processing systems and visualization to ensure reliability and meet critical business requirements.\u003c/li\u003e\u003cli\u003eLead data engineering projects, and overall strategy for data governance, security, privacy, quality, and retention.\u003c/li\u003e\u003cli\u003eMentor data engineers and continue promoting data engineering and analytics tooling \u0026amp; standards.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWhat we look for\u003c/p\u003e\u003cul\u003e\u003cli\u003e7+ years of experience in data modeling, data architecture, and other areas directly relevant to data engineering.\u003c/li\u003e\u003cli\u003eTechnical leadership; capable of handling mentorship, cross functional project execution, and solid individual contributions.\u003c/li\u003e\u003cli\u003eAdvanced SQL, ETL pipelines, Data modeling \u0026amp; design, SQL performance tuning in OLAP and Data Warehouse/Data Lake environments\u003c/li\u003e\u003cli\u003eProficiency with programming languages (e.g. Python) and Data Warehouse technologies (NoSQL, logging, columnar, Snowflake, etc.), Big Data technologies (e.g Hadoop, Spark, etc.), analytics (Looker, Tableau, etc.)\u003c/li\u003e\u003cli\u003eFamiliar with data governance frameworks and Agile methodology\u003c/li\u003e\u003cli\u003eExcellent written and verbal communication and interpersonal skills; able to effectively collaborate with technical and business partners.\u003c/li\u003e\u003cli\u003eEager to learn new things and have a growth mindset.\u003c/li\u003e\u003cli\u003eBS/MS degrees in Computer Science, Engineering, or a related technical field.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eLocation - Remote U.S.\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eAffirm is proud to be a \u003ca href=\"https://www.linkedin.com/pulse/new-ways-we-work-jude-komuves/?trackingId=b19Ndt4EShSxDp3fjaCHdw%3D%3D\"\u003eremote-first company\u003c/a\u003e! The majority of our roles are remote and can be located anywhere in the U.S. and Canada (with the exception of the U.S. Territories, Quebec, Yukon, Nunavut, and the Northwest Territories) unless the job indicates a different global location. We are currently building operations in Spain, Poland, and Australia.¬†¬†Employees in remote roles have the option of working remotely or from an Affirm office in their country of hire, and may occasionally travel to an Affirm office or elsewhere for required meetings or team-building events. Our offices in Chicago, New York, Pittsburgh, Salt Lake City, San Francisco and Toronto will remain operational and accessible for anyone to use on a voluntary basis, subject to local COVID-19 guidelines.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eIf you got this far, we hope you're feeling excited about this role. Even if you don't feel you meet every single requirement, we still encourage you to apply. We're eager to meet people who believe in Affirm's mission and can contribute to our team in a variety of ways‚Äînot just candidates who check all the boxes.¬†\u003cstrong\u003eInclusivity:\u003c/strong\u003eAt Affirm, People Come First is one of our core values, and that‚Äôs why diversity and inclusion are vital to our priorities as an equal opportunity employer. You can read about our D\u0026amp;I program \u003ca href=\"https://www.affirm.com/diversity-inclusion\"\u003ehere\u003c/a\u003e and our progress thus far in our \u003ca href=\"https://assets.ctfassets.net/4rc1asww3mw7/4oAgbpVaxk6UbqRnFOkASc/1e110320731c73da9350677bd8c702cf/2020_Affirm_DEI_Report.pdf\"\u003e2020 DEI Report\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eWe also believe It‚Äôs On Us to provide an inclusive interview experience for all, including people with disabilities. We are happy to provide reasonable accommodations to candidates in need of individualized support during the hiring process.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eBy clicking \"Submit Application,\" you acknowledge that you have read the \u003ca href=\"https://docs.google.com/document/d/e/2PACX-1vRSrHfbqKhhxAsI84tBH5hW85xiwEF4s8MOnfgDFJ5hl4_opeivo6dKc1kbywvVEppRe37UqYYsghB2/pub?urp=gmail_link\"\u003eAffirm Employment Privacy Policy\u003c/a\u003e, or the \u003ca href=\"https://docs.google.com/document/d/e/2PACX-1vQrsTcZOb2_liNfehZtHSHG6apQTk372vodkmNinPGNNLKnoU_YyCeEneUzsZtTdn2uiRYvE2kM3XL9/pub\"\u003eAffirm Employment Privacy Notice (EU)\u003c/a\u003e for applicants applying from the European Union, and hereby freely and unambiguously give informed consent to the collection, processing, use, and storage of your personal information as described therein.\u003c/p\u003e","id":15860,"location":"US","location_type":"remote","position":"Staff Data Engineer","published_at":"2022-01-18T17:15:37Z","slug":"ecdbh7e98x-staff-data-engineer","status":"approved","tags":["Big Data","Engineering","ETL","Hadoop"],"type":"fulltime"},{"application_url_or_email":"https://boards.greenhouse.io/dataminr/jobs/3820711?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"dataengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/cj2izg5kel.webp","company_name":"Dataminr","company_slug":"dataminr","company_twitter":"dataminr","description":"\u003cp\u003e\u003cstrong\u003e--COVID-19 Hiring Update--\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAs the health and safety of our candidates and our employees come first, we're excited to provide virtual experiences for interviews and new hire on-boarding. Currently, reopening of offices is planned for January 2022.\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWho we are:¬†\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eDataminr puts real-time AI and public data to work for our clients, generating relevant and actionable alerts for global corporations, public sector agencies, newsrooms, and NGOs. Our leading AI platform detects the earliest signals of high-impact events and emerging risks from vast amounts of publicly available information. Our real-time alerts enable tens of thousands of users at hundreds of public and private sector organizations to learn first of breaking events around the world, develop effective risk mitigation strategies, and respond with confidence as crises unfold.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eDataminr is making its mark for growth and innovation, recently earning recognition on the Deloitte Technology Fast 500, Forbes AI 50 and Forbes Cloud 100 lists. We also earned accolades for ‚ÄòMost Innovative Use of AI‚Äô from the 2020 AI \u0026amp; Machine Learning Awards.¬†\u003c/p\u003e\u003cp\u003eJoin our team and help the world manage risk in real time. You‚Äôll work with 800+ talented people across eight offices, united by our passion to collaborate, make a difference, and have fun while doing it!\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWho you are:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eYou are a highly motivated self-starter and problem solver interested in the intersection of business, technology, and current events. You are innovative and adaptable, with an ability to juggle multiple projects at one time. You have a high level of technical skill, but even more importantly have an analytical mindset and are excited to learn more about the programs and tools that make our Data Analytics team a diverse and capable component of Dataminr. You will work hand-in-hand with content experts, product managers, engineers, and other teams to solve challenging problems with your data analysis skills.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAbout the Role:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eConduct data exploration and build data ingests/models utilizing APIs and other methods\u003c/li\u003e\u003cli\u003eGuide the development of reports, dashboards, and metrics to monitor the performance of our internal products\u003c/li\u003e\u003cli\u003eEffectively translate statistical findings into actionable recommendations for senior leaders on operations, product, and engineering teams.\u003c/li\u003e\u003cli\u003eCommunicate complex ideas in a clear, precise, accessible way to operations, product, engineering, and data science teams.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eRequired Skills \u0026amp; Experience:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eAt least 2-4 years experience in Data Analytics\u003c/li\u003e\u003cli\u003eExperience in one or more object oriented programming language (Python, Java or TypeScript preferred), and ability to work on projects with minimal support\u003c/li\u003e\u003cli\u003eIntermediate knowledge of SQL\u003c/li\u003e\u003cli\u003eDemonstrated experience with analytical tools (e.g., Microsoft Excel/Google Sheet)\u003c/li\u003e\u003cli\u003eExperience with, or a willingness to explore business intelligence tools (e.g., Tableau, Looker)\u003c/li\u003e\u003cli\u003eLeveraging data to tell a story\u003c/li\u003e\u003cli\u003eExcellent attention to detail, highly organized and process oriented\u003c/li\u003e\u003cli\u003eAbility to work both independently and collaboratively within a team\u003c/li\u003e\u003cli\u003eSelf-motivated with an ability to handle multiple competing priorities in a fast-paced, entrepreneurial environment\u003c/li\u003e\u003cli\u003eExcellent verbal and written communication skills, and the ability to convey complex results to non-technical audiences\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eDesired Skills \u0026amp; Experience:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eFamiliarity with AWS services (S3, ECS, Lambda)\u003c/li\u003e\u003cli\u003eExperience with web scraping frameworks/technologies (Selenium, Scrapy, BeautifulSoup, HTML, CSS)\u003c/li\u003e\u003cli\u003eFamiliarity in machine learning frameworks (TensorFlow/Keras) or packages (scikit-learn)\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy you should work here:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eWe recognise and reward hard work with:\u003c/li\u003e\u003cli\u003ecompetitive compensation package including equity\u003c/li\u003e\u003cli\u003ecompany paid benefits for employees and their dependents such as Health and Dental insurance as well as Income Protection and Life Insurance\u003c/li\u003e\u003cli\u003epersonal retirement savings account with employer match\u003c/li\u003e\u003cli\u003eWe want you to be your best, authentic self by supporting you with:\u003c/li\u003e\u003cli\u003ea diverse, driven, and passionate team of coworkers who want you to succeed\u003c/li\u003e\u003cli\u003eindividual learning and development fund and professional training\u003c/li\u003e\u003cli\u003egenerous leave, including two additional volunteer days\u003c/li\u003e\u003cli\u003eRemote working friendly perks such as expanded telehealth options for mental and physical well-being, meditation and health and fitness app reimbursements¬†\u003c/li\u003e\u003cli\u003eDiscounted Gym Membership\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e‚Ä¶and this is just to name a few!\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eDataminr is an equal opportunity and affirmative action employer. Individuals seeking employment at Dataminr are considered without regards to race, sex, colour, creed, religion, national origin, age, disability, genetics, marital status, pregnancy, unemployment status, sexual orientation, citizenship status or veteran status.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eDataminr will collect and process your personal data. All personal data will be processed in accordance with Dataminr‚Äôs job candidate privacy notice available here: https://www.dataminr.com/irecandidatenotice.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eFor individuals applying for US-based roles:\u003c/em\u003e\u003c/strong\u003e¬†\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eDataminr is requiring that all prospective employees hired for this position present proof that they are fully vaccinated against COVID-19 prior to their first day of employment, to the extent permitted by applicable law\u003c/strong\u003e.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eDataminr is an equal opportunity employer. Candidates who are unable to be vaccinated due to a sincerely held religious belief, medical reasons, or other legally protected reasons, should contact their recruiting representative as soon as possible following any conditional offer of employment to explore what, if any, reasonable accommodations Dataminr is able to offer.\u003c/p\u003e","id":15796,"location":"Dublin, Ireland","location_type":"onsite","position":"Senior Data Analytics Developer","published_at":"2022-01-16T20:35:12Z","slug":"cj2izg5kel-senior-data-analytics-developer","status":"approved","tags":["AWS","Business Intelligence","Data Analytics","Engineering"],"type":"fulltime"},{"application_url_or_email":"https://www.transferwise.jobs/role/3818448?gh_jid=3818448\u0026ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"datascience","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/r98pqk6xmc.webp","company_name":"Wise","company_slug":"wise","company_twitter":"wise","description":"\u003cp\u003eWise is \u003ca href=\"https://www.ft.com/content/cf0c5fce-3112-11e8-b5bf-23cb17fd1498\"\u003eone of the fastest growing companies in Europe\u003c/a\u003e.¬†\u003c/p\u003e\u003cp\u003e¬†\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eCurrent banking systems don't let us send, spend or receive money\u003c/strong\u003e across borders easily. Or quickly. Or cheaply.¬†\u003c/p\u003e\u003cp\u003eSo, \u003cstrong\u003ewe‚Äôre building a new one.\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe‚Äôre on a mission: \u003c/strong\u003eto make money without borders the new norm. We‚Äôve got \u003cstrong\u003e11 million customers\u003c/strong\u003e across the globe and we‚Äôre growing. Fast.\u003c/p\u003e\u003cp\u003eWe‚Äôre creating a scalable, high performing platform for our customers. And we need Data Science Interns to join us in our mission. This is a¬†\u003cstrong\u003epaid internship\u003c/strong\u003e¬†that will run throughout the summer.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eAt Wise you‚Äôll work on challenging technical problems across the full product life-cycle and you‚Äôll help us gain the understanding necessary to give our customers a great experience.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003e\u003cstrong\u003eHow you‚Äôll contribute to our team of data scientists:¬†\u003c/strong\u003e\u003c/h3\u003e\u003cul\u003e\u003cli\u003eYou‚Äôll work on a real data science project that matters to us, using up-to-date machine learning techniques. We can‚Äôt say what project yet, but your internship will be centred around this.\u003c/li\u003e\u003cli\u003eYou will help analysing data that will help us prioritise the most customer significant changes in the product\u003c/li\u003e\u003cli\u003eParticipate in building the most advanced machine learning based solutions to help us scale\u003c/li\u003e\u003cli\u003eHelp take Wise to the next level as we scale to impact 100‚Äôs of millions more customers\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003e\u003cstrong\u003eThis role will give you the opportunity to:\u003c/strong\u003e\u003c/h3\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eLearn and develop\u003c/strong\u003e professionally. You‚Äôll work closely with your Wise team. You‚Äôll learn by doing. And you‚Äôll be guided and supported along the way\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eUnderstand the Wise way \u003c/strong\u003ethrough lots of opportunities to learn about our business and how it works\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eBroaden your network. \u003c/strong\u003eThere are a LOT of experienced people here at Wise who are keen to share their experience and knowledge with you. They‚Äôll want to learn from you and get your perspective on things too\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eChoose your path to impact\u003c/strong\u003e. We believe people do great things when they can act autonomously. So, instead of being told what to do, you‚Äôll work with your team to create a vision of your own. You can always gather feedback from smart, curious people across Wise, but you‚Äôll have the freedom to make your own calls\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eBe flexible\u003c/strong\u003e in how and where you work. We understand everyone needs a little something different - so we‚Äôll do our best to make it happen\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eInspire teams \u003c/strong\u003ewith your ideas, knowledge and self-starting attitude¬†\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat does it take? These things are a must:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eYou are a student studying a Bachelors, Masters, or PhD degree. This might be in \u003cstrong\u003eComputer Science, Mathematics, Engineering or any other STEM subject\u003c/strong\u003e\u003c/li\u003e\u003cli\u003eYou are able to start a full time graduate job in September 2023\u003c/li\u003e\u003cli\u003eKnowledge of computer science and machine learning fundamentals including \u003cstrong\u003edata structures, algorithms, data analysis, linear algebra and statistics\u003c/strong\u003e\u003c/li\u003e\u003cli\u003eUnderstanding principles of \u003cstrong\u003emachine learning\u003c/strong\u003e\u003c/li\u003e\u003cli\u003eYou should have a good command of \u003cstrong\u003ePython 3\u003c/strong\u003e and be familiar with major data analysis and ML frameworks\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eA self-started side project\u003c/strong\u003e(s) that you are proud to talk about\u003c/li\u003e\u003cli\u003eGreat communication skills and the ability to \u003cstrong\u003earticulate complex, technical concepts\u003c/strong\u003e to a non-technical audience\u003c/li\u003e\u003cli\u003eCurious, keen to learn and \u003cstrong\u003eproactive\u003c/strong\u003e by nature\u003c/li\u003e\u003cli\u003eYou are open to and \u003cstrong\u003evalue feedback \u003c/strong\u003ein order to improve\u003c/li\u003e\u003cli\u003eEligible to work in Tallinn or London (\u003cstrong\u003eYou can work from anywhere in the country you're hired!\u003c/strong\u003e)\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAnd these would be great, but aren‚Äôt essential:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eExperience in applying \u003cstrong\u003ecausal inference\u003c/strong\u003e and/or \u003cstrong\u003euplift modeling\u003c/strong\u003e techniques, for example with DoWhy and EconML\u003c/li\u003e\u003cli\u003eExperience in designing and training \u003cstrong\u003edeep neural networks\u003c/strong\u003e\u003c/li\u003e\u003cli\u003eExperience in applying machine learning methods to\u003cstrong\u003e real-world problems\u003c/strong\u003e\u003c/li\u003e\u003cli\u003eFamiliarity with \u003cstrong\u003eTensorFlow 2 \u003c/strong\u003eand/or\u003cstrong\u003e PyTorch\u003c/strong\u003e\u003c/li\u003e\u003cli\u003eFamiliarity with \u003cstrong\u003eAutoML \u003c/strong\u003eframeworks, especially FLAML\u003c/li\u003e\u003cli\u003eFamiliarity with \u003cstrong\u003eBayesian methods\u003c/strong\u003e in machine learning\u003c/li\u003e\u003cli\u003eExperience in \u003cstrong\u003eweb development\u003c/strong\u003e, from a \u003cstrong\u003eprevious internship\u003c/strong\u003e¬†\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e...Don‚Äôt worry we don‚Äôt expect you to know everything!\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003e\u003cstrong\u003eWhat you get back:\u003c/strong\u003e\u003c/h3\u003e\u003cul\u003e\u003cli\u003eüöÄ Experience working in \u003ca href=\"https://www.wise.jobs/2021/04/08/the-growth-of-wise-and-whats-next-for-us/\"\u003eone of the fastest growing\u003c/a\u003e European FinTechs\u003c/li\u003e\u003cli\u003eüèÉ‚Äç‚ôÄÔ∏è Lots of team activities\u003c/li\u003e\u003cli\u003eüìà Solve real customer problems with data\u003c/li\u003e\u003cli\u003eüôåFun offices with social activities - have \u003ca href=\"https://youtu.be/-Amc0Fcu40U\"\u003ea sneak peak\u003c/a\u003e of life in our Singaporean office!\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWe‚Äôre people without borders ‚Äî without judgement or prejudice, too. We want to work with the best people, no matter their background. So if you‚Äôre passionate about learning new things and keen to join our mission, you‚Äôll fit right in.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eAnd because we believe that diverse teams build better products, we‚Äôd especially love to hear from you if you‚Äôre from an under-represented demographic.\u003c/p\u003e","id":15769,"location":"Tallinn or London","location_type":"onsite","position":"Data Science Internship","published_at":"2022-01-16T20:46:29Z","slug":"r98pqk6xmc-data-science-internship","status":"approved","tags":["Banking","Engineering","Machine Learning","ML"],"type":"fulltime"},{"application_url_or_email":"https://discord.com/jobs/5664098002?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"softwareengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/eyiizrzf6l.webp","company_name":"Discord","company_slug":"discord","company_twitter":"discordapp","description":"\u003cp\u003e\u003cstrong\u003eDiscord is about creating a space for everyone to find belonging in their lives. Hundreds of millions of people use Discord everyday to have meaningful interactions.\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eThe mission of the Discovery \u0026amp; Notifications team at Discord is to help users connect and engage with the online communities to create this belonging. We are working on enabling our users‚Äô experiences with search, recommendations, and smart notifications. We are just starting to build these ML driven user experiences and if you are someone who is passionate about building things from scratch, this could be a great opportunity for you!\u003c/strong\u003e\u003c/p\u003e\u003ch4\u003e¬†\u003c/h4\u003e\u003ch4\u003eWhat you'll be doing\u003c/h4\u003e\u003cul\u003e\u003cli\u003eDesign and build machine learning systems for retrieval, ranking and personalization.\u003c/li\u003e\u003cli\u003eCollaborate with stakeholders throughout the company such as, leaders in product, data science, and engineering\u003c/li\u003e\u003cli\u003eBuild generalizable infrastructure for NLP, retrieval and ranking, especially using MLOps stack like TFX.\u003c/li\u003e\u003c/ul\u003e\u003ch4\u003e\u003cbr /\u003e\u003c/h4\u003e\u003ch4\u003eWhat you should have\u003c/h4\u003e\u003cul\u003e\u003cli\u003eBachelor‚Äôs degree or higher in a quantitative field including Computer Science, Physics, Applied Math, Statistics or other quantitative fields.\u003c/li\u003e\u003cli\u003e2+ years experience in one or more of the following areas: recommendation systems, search, adsML, natural language processing, knowledge graphs.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eBenefits And Perks\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eComprehensive medical insurance including Health, Dental and Vision (plus up to $20,000 for gender affirmation procedures)\u003c/li\u003e\u003cli\u003eMental health resources and quarterly wellness stipends\u003c/li\u003e\u003cli\u003e16 paid holidays, 4 weeks of PTO, use-what-you-need sick days and volunteer time off\u003c/li\u003e\u003cli\u003ePaid parental leave (plus fertility, adoption and other family planning benefits)\u003c/li\u003e\u003cli\u003eGenerous stipends for headphones, your remote work setup, and lunch on a daily basis (while we‚Äôre all remote)\u003c/li\u003e\u003cli\u003eFlexible long-term work options (remote and hybrid)\u003c/li\u003e\u003cli\u003eA diverse slate of Employee Resource Groups\u003c/li\u003e\u003cli\u003ePlus commuter contributions and other perks for office-based employees\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAbout Us\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eDiscord is a voice, video and text app that helps friends and communities come together to hang out and explore their interests ‚Äî from artists and activists, to study groups, sneakerheads, plant parents, and more. With 150 million monthly users across 19 million active communities, called servers, Discord has grown to become one of the most popular communications services in the world. Discord was built without selling ads or user data and instead, offers a premium subscription called Nitro that gives users special perks like higher quality streams and fun customizations.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eIn a world of polarization, social curation, and loneliness, Discord is working toward an inclusive world where no one feels like an outsider. We believe in the value of genuine human connection, which can so easily be lost online. So we‚Äôre building a space where everyone can find belonging from the inside out.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eIf this strikes a chord with you, come build belonging with us!\u003c/strong\u003e\u003c/p\u003e","id":15766,"location":"San Francisco, CA or Remote","location_type":"flexible","position":"Software Engineer, Machine Learning","published_at":"2022-01-16T20:40:29Z","slug":"eyiizrzf6l-software-engineer-machine-learning","status":"approved","tags":["Search","Recommendations","Notifications"],"type":"fulltime"},{"application_url_or_email":"https://jobs.lever.co/safe/266c3cff-d7bf-4b99-bd21-d41b4b0a562e?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"machinelearning","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/tbt87dznfc.webp","company_name":"Safe Security","company_slug":"safe-security","company_twitter":"itssafesecurity","description":"\u003cp\u003eOur vision is to be the Champions of a Safer Digital Future and be the Champions of Change. We believe in empowering individuals and teams with freedom and responsibility to align their goals such that we all row in the same direction. We are uncomfortably transparent, autonomous \u0026amp; accountable, we have zero tolerance for brilliant jerks, we have unlimited vacation policy and more. For us our Culture Is Our Strategy - check out our \u003ca href=\"https://jobs.safe.security/culture/\"\u003eCulture Memo\u003c/a\u003e for more details and surprises.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eAt the core, we are a data science company. We take different data points from a company's cyber environment, and apply statistics / ML to give actionable insights to our customers. We are looking for a Senior ML Engineer who can take our models to the next level.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eKey responsibilities include:\u003c/h3\u003e\u003cul\u003e\u003cli\u003eBuild production level ML/ statistics code for our cyber quantification algorithms;\u003c/li\u003e\u003cli\u003eLay down the foundation for our future data architecture - plan the right way to collect data in the product (telemetry), prepare data for aggregate analysis in the future; ‚ÄòPreparation‚Äô might include labeling, cleaning and streaming data.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003ch3\u003eIdeal experience\u003c/h3\u003e\u003cul\u003e\u003cli\u003e5+ years of experience in building scalable production level Python based models\u003c/li\u003e\u003cli\u003e2+ years of experience in MLOps architecture and building / or working on data lakes / data warehouse ‚Äì preparing infrastructure to run analytics at scale\u003c/li\u003e\u003cli\u003eGood understanding of different statistical and ML techniques\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eJoin our rocket ship if you want to learn, make your mark and work with incredible talent!\u003c/p\u003e","id":15764,"location":"Worldwide","location_type":"remote","position":"Senior ML Engineer","published_at":"2022-01-16T20:37:27Z","slug":"tbt87dznfc-senior-ml-engineer","status":"approved","tags":["ML","MLOps","Python"],"type":"fulltime"},{"application_url_or_email":"https://boards.greenhouse.io/andela/jobs/3805528?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"dataengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/wnnyq2wi9m.webp","company_name":"Andela","company_slug":"andela","company_twitter":"Andela","description":"\u003cp\u003e\u003cstrong\u003eAbout Andela:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eAndela exists to connect brilliance and opportunity. Since 2014, we have been dedicated to breaking down global barriers and accelerating the future of work for both technologists and organizations around the world.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eFor technologists, Andela offers competitive long term career opportunities with leading organizations, access to a global community of professionals, and education opportunities with leading technology providers.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eFor companies, Andela provides access to a global network of fully integrated team members that unlock their business‚Äô innovation and growth potential.¬†\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eAt Andela, we are deeply passionate about creating long-lasting and transformative growth opportunities for all and doing it in an \u003ca href=\"andela.com/careers\"\u003eE.P.I.C.\u003c/a\u003e¬†way.\u003c/p\u003e\u003cp\u003eWe are excited to continue building our team with incredible people like you!\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat you‚Äôll do:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eUnderstand Andela‚Äôs platform, value proposition, and roadmap by working with Data Engineering leadership.\u003c/li\u003e\u003cli\u003eTake ownership of sprint work to help create innovative solutions for a category-defining platform\u003c/li\u003e\u003cli\u003eThis role is founded in data engineering technology solutions to drive efficiencies here at scale.\u003c/li\u003e\u003cli\u003eOwn the excitement of entropy! Our platform, products, and offerings are constantly changing and expanding. We encourage and enable each individual at Andela to drive a commercial idea when they identify one, which creates an ever-changing data landscape.¬†\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWho you are:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eAt home in an environment where you are responsible for delivering data solutions to drive change!\u003c/li\u003e\u003cli\u003e1+ years experience working in data intensive environments and platforms.\u003c/li\u003e\u003cli\u003eAbility to work in an agile team environment and collaborate effectively.\u003c/li\u003e\u003cli\u003eBasic understanding of data structures, data in transit, and data at rest.\u003c/li\u003e\u003cli\u003eAbility to thrive in a fast moving and challenging environment.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003ePreferred Qualifications\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003ePython and SQL¬†\u003c/li\u003e\u003cli\u003eExperience working with a modern SaaS tool¬†\u003c/li\u003e\u003cli\u003eExperience in data modeling¬†\u003c/li\u003e\u003cli\u003eKubernetes, Docker or a comparable system\u003c/li\u003e\u003cli\u003ebasic knowledge of shell scripting\u003c/li\u003e\u003cli\u003eExperience with a cloud platform (GCP is a plus)\u003c/li\u003e\u003cli\u003eExperience with Agile/Scrum\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eBenefits:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eFully Remote work culture\u003c/li\u003e\u003cli\u003eA fair and competitive salary\u003c/li\u003e\u003cli\u003eBring your own device stipend - buy your own laptop with funds from Andela\u003c/li\u003e\u003cli\u003eQuarterly work from home stipends\u003c/li\u003e\u003cli\u003eGenerous paid time off\u003c/li\u003e\u003cli\u003eAdditional paid holidays\u003c/li\u003e\u003cli\u003eFlexible working hours\u003c/li\u003e\u003cli\u003eHealth insurance (country-specific)\u003c/li\u003e\u003cli\u003eEquity\u003c/li\u003e\u003cli\u003e401k (US only)\u003c/li\u003e\u003cli\u003eAndela Affinity Groups\u003c/li\u003e\u003cli\u003eAnd more!\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eAt Andela, we outcompete through diversity. We know that our strengths lies in the multiplicity of talents, perspectives, backgrounds \u0026amp; orientations resident in our community and we take pride in that. Andela is committed to a work environment in which all individuals are treated with respect and dignity. Each individual has the right to work in a professional atmosphere that promotes equal employment opportunities and prohibits discriminatory practices. Andela provides equal employment opportunities and workplace to all employees and applicants without regard to factors including but not limited to race, color, religion, gender, sexual orientation, gender identity, national origin, age, disability, pregnancy (including breastfeeding), genetic information, HIV/AIDS or any other medical status, family or parental status, marital status, amnesty or status as a covered veteran in accordance with applicable federal, state and local laws. This commitment applies to all terms and conditions of employment, including but not limited to hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Our policies expressly prohibit any form of harassment and/or discrimination as stated above.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eAndela is home for all, come as you are.\u003c/em\u003e\u003c/p\u003e","id":15620,"location":"Worldwide","location_type":"remote","position":"Data Engineer","published_at":"2022-01-13T17:25:50Z","slug":"wnnyq2wi9m-data-engineer","status":"approved","tags":["Engineering","GCP","Kubernetes","Python"],"type":"fulltime"},{"application_url_or_email":"https://boards.greenhouse.io/evenresponsiblefinance/jobs/4289815004?ref=datastackjobs.com\u0026utm_source=datastackjobs.com","category":"dataengineering","company_logo_url":"https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/h10gyqtkka.webp","company_name":"Even","company_slug":"even","company_twitter":"makethingseven","description":"\u003cp\u003e\u003cstrong\u003eCOVID Update¬†-\u003c/strong\u003e Even has begun to re-open its offices. Office use is available to anyone who the CDC has cleared to gather safely indoors without masks or social distancing. Employees may continue working from home indefinitely. Even is a Remote-Equal company. The experience of working 100% remotely¬†feels¬†the same as working from the office in all of the ways that matter: camaraderie, engagement, and opportunity.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eThe problem\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eMore than half of American workers live paycheck-to-paycheck. Stuck in this cycle, they collectively lose over $120 billion each year on payday loans, bank overdrafts, and fees. We‚Äôre trying to fix that by building new financial services that make it easier to plan ahead, pay down debt, and save. And we‚Äôre doing it as a transparent, straightforward business that only profits when our members do.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eThe role\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eData Engineers at Even build the data transformation pipelines \u0026amp; reporting infrastructure that serve our members and run our company. Besides writing, reviewing, and shipping code, engineers collaborate with others across the company, from product, design, and data to sales, compliance, and customer support. Data Engineers at Even are highly technical, communicative and emotionally intelligent.\u003c/p\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat you'll do:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eBuilding and maintain Even's data infrastructure\u003c/li\u003e\u003cli\u003eDevelop and own Even's streaming data transformation pipeline\u003c/li\u003e\u003cli\u003eManage our reporting tools\u003c/li\u003e\u003cli\u003eCollaborate closely with our Data Analysts\u003c/li\u003e\u003cli\u003eTracking and defining metrics around performance\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat you'll need:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e4+ years of related experience\u003c/li\u003e\u003cli\u003eSelf-motivated\u003c/li\u003e\u003cli\u003eLove working with new tech\u003c/li\u003e\u003cli\u003ePassion for building stable and scalable solutions\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eTools we use:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eLanguages: Python, Golang, Typescript\u003c/li\u003e\u003cli\u003eData: DBT, Fivetran, Redshift, PostgreSQL\u003c/li\u003e\u003cli\u003eInfra: GitHub, Bazel, Docker\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat you'll get from us:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe chance to work on a serious problem that affects more than half the U.S. population.\u003c/li\u003e\u003cli\u003eA culture that gives you the time and space required to build great things.\u003c/li\u003e\u003cli\u003eCompetitive compensation, equity, and healthcare packages.\u003c/li\u003e\u003cli\u003e401(k) with 50% match from Even on up to 6% of your salary.\u003c/li\u003e\u003cli\u003eA $5,000 annual educational stipend to invest in your learning and development.\u003c/li\u003e\u003cli\u003eA $500 annual stipend to use towards personal financial advice.\u003c/li\u003e\u003cli\u003eA $100 monthly stipend for health and wellness expenses.\u003c/li\u003e\u003cli\u003eA 5-year exercise window on stock options after 2 years at Even.\u003c/li\u003e\u003cli\u003eA flexible vacation policy and a team that understands building a company is a marathon, not a sprint.¬†\u003c/li\u003e\u003cli\u003e3 months bonding leave for both birthing and non-birthing parents. An additional 1.5 months of fully paid leave for pregnancy disability.\u003c/li\u003e\u003cli\u003eA culture that gives you the autonomy you need to do great work, and the transparency you need to make good decisions.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\u003cp\u003eWant to learn more about what we look for in a team mate? Check out this¬†\u003ca href=\"https://www.even.com/blog/what-we-value-2\"\u003eblog post\u003c/a\u003e¬†written by our cofounder, Quinten Farmer.\u003c/p\u003e\u003cp\u003eEven is used by people of all backgrounds, and we believe the best products are built by teams that represent their users. We value unique contributions and actively welcome people of all backgrounds, experiences, and perspectives to join us at Even. We are committed to working with and providing access and reasonable accommodation to applicants with mental and/or physical disabilities. If you think you may require an accommodation for any part of the recruitment process, please send a request to: \u003ca href=\"mailto:accommodations@even.com\"\u003eaccommodations@even.com\u003c/a\u003e. All requests for accommodations are treated discreetly and confidentially, as practical and permitted by law.\u003c/p\u003e","id":15611,"location":"USA","location_type":"remote","position":"Senior Data Engineer","published_at":"2022-01-13T17:28:25Z","slug":"h10gyqtkka-senior-data-engineer","status":"approved","tags":["FiveTran","Healthcare","PostgreSQL","Python"],"type":"fulltime"}],"meta":{"after":"g3QAAAACZAACaWRiAAA8-2QAC2luc2VydGVkX2F0dAAAAA1kAApfX3N0cnVjdF9fZAAPRWxpeGlyLkRhdGVUaW1lZAAIY2FsZW5kYXJkABNFbGl4aXIuQ2FsZW5kYXIuSVNPZAADZGF5YQ1kAARob3VyYQhkAAttaWNyb3NlY29uZGgCYQBhAGQABm1pbnV0ZWEBZAAFbW9udGhhAWQABnNlY29uZGEPZAAKc3RkX29mZnNldGEAZAAJdGltZV96b25lbQAAAAdFdGMvVVRDZAAKdXRjX29mZnNldGEAZAAEeWVhcmIAAAfmZAAJem9uZV9hYmJybQAAAANVVEM=","before":null,"limit":50,"total_count":null,"total_count_cap_exceeded":null},"errors":null},"__N_SSP":true},"page":"/","query":{},"buildId":"L_5NvepYBqv7HYqcZeqGq","runtimeConfig":{},"nextExport":false,"isFallback":false,"gssp":true}</script><script nomodule="" src="/_next/static/chunks/polyfills-f4a1f2beb5f7f31e58c2.js"></script><script src="/_next/static/chunks/main-37a0a2fb90fe69f579f6.js" async=""></script><script src="/_next/static/chunks/webpack-7c235c8ce7ccfa45f08f.js" async=""></script><script src="/_next/static/chunks/framework.b65b242e921c3051fc8d.js" async=""></script><script src="/_next/static/chunks/05d954cf.a3f8b867f1dbe44b7882.js" async=""></script><script src="/_next/static/chunks/4296f879d6b162ad77a114aee20f2c73f8dc7680.653f9837c77c5e3b046b.js" async=""></script><script src="/_next/static/chunks/f9a9a75c5535d85502ab3f331daa705d124c96c6.68b683f2c546ffb2b0d8.js" async=""></script><script src="/_next/static/chunks/d0c17572a3857dce9cf74013cc89c84125388fe3.82188d4076cfb3b74167.js" async=""></script><script src="/_next/static/chunks/03ec6ed75970ab1694e01a1a684a9ea9e9646f9b.5233c31b312fc59f720f.js" async=""></script><script src="/_next/static/chunks/595d727c72955f0f005e25ae2b877b935dbda26c.cf9726d83c89faf02456.js" async=""></script><script src="/_next/static/chunks/8814d774837182f5c1c54848fa045f1174ac4c9d.349409635e9e8c2b394e.js" async=""></script><script src="/_next/static/chunks/pages/_app-0f4c5fbaf03871fb8f24.js" async=""></script><script src="/_next/static/chunks/0241f7f89381f731fab5b7171dd2b104ca613c07.f559ffbe49985b322adc.js" async=""></script><script src="/_next/static/chunks/b1fb4e262511cc3c03ae0b9b0b1e8f1fd2cee287.24676c3ea77d1431450a.js" async=""></script><script src="/_next/static/chunks/c9f5bf9e85f5de6ea89f38460a9150a45b3bb2fc.fa497414ff23c3c76a97.js" async=""></script><script src="/_next/static/chunks/pages/index-15728d2ef6fc668f0aac.js" async=""></script><script src="/_next/static/L_5NvepYBqv7HYqcZeqGq/_buildManifest.js" async=""></script><script src="/_next/static/L_5NvepYBqv7HYqcZeqGq/_ssgManifest.js" async=""></script></body></html>